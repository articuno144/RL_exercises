{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import random as rd\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.concatenate([np.load(\"train_x_1.npy\"),np.load(\"train_x_2.npy\")],axis=0)\n",
    "train_y = np.load(\"train_y.npy\")\n",
    "n_sample = train_x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = None\n",
    "train_y = None\n",
    "n_sample = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKkAAAD8CAYAAAAMloRrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5zFJDecxSQ3nMUkN5/l/RRWNm1EJddgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fea401c7d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "im = plt.imshow(train_x[8200,:,:,:].reshape(183,103))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "swipe_x1, swipe_y1, swipe_x2, swipe_y2 = 320, 1000, 320, 1000\n",
    "mistrust = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img():\n",
    "    os.system('adb shell screencap -p /sdcard/1.png')\n",
    "    os.system('adb pull /sdcard/1.png .')\n",
    "    img = cv2.imread('1.png')\n",
    "    img = img[::7,::7,1].reshape(1,183,103,1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKkAAAD8CAYAAAAMloRrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fea5764c668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(183, 103, 1)\n",
      "(183, 103)\n"
     ]
    }
   ],
   "source": [
    "img = get_img()\n",
    "im = plt.imshow(img.reshape(183,103))\n",
    "plt.show()\n",
    "input_shape = img.shape[1:]\n",
    "img_dim = img.shape[1:3]\n",
    "print(input_shape)\n",
    "print(img_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (183,103,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[247],\n",
       "         [247],\n",
       "         [247],\n",
       "         ..., \n",
       "         [247],\n",
       "         [247],\n",
       "         [247]],\n",
       "\n",
       "        [[247],\n",
       "         [247],\n",
       "         [247],\n",
       "         ..., \n",
       "         [247],\n",
       "         [247],\n",
       "         [247]],\n",
       "\n",
       "        [[247],\n",
       "         [247],\n",
       "         [247],\n",
       "         ..., \n",
       "         [247],\n",
       "         [247],\n",
       "         [247]],\n",
       "\n",
       "        ..., \n",
       "        [[245],\n",
       "         [245],\n",
       "         [245],\n",
       "         ..., \n",
       "         [245],\n",
       "         [245],\n",
       "         [245]],\n",
       "\n",
       "        [[245],\n",
       "         [245],\n",
       "         [245],\n",
       "         ..., \n",
       "         [245],\n",
       "         [245],\n",
       "         [245]],\n",
       "\n",
       "        [[245],\n",
       "         [245],\n",
       "         [245],\n",
       "         ..., \n",
       "         [245],\n",
       "         [245],\n",
       "         [245]]]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.amax(img[:50,:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jump(press_time):\n",
    "    cmd = 'adb shell input swipe {} {} {} {} {}'.format(swipe_x1, swipe_y1, swipe_x2, swipe_y2, math.ceil(max(press_time,200)))\n",
    "    os.system(cmd)\n",
    "    print(press_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def success(img_new,img):\n",
    "    if np.amax(np.absolute(img_new.reshape(img_dim)[:25,:25]-img.reshape(img_dim)[:25,:25]))>50:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fail(img_new):\n",
    "    if np.amax(img_new.reshape(img_dim)[:25,:25])>50:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=keras.optimizers.Adadelta())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=keras.optimizers.Nadam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network(model,img,confidence):\n",
    "    if rd.uniform(0,1)<confidence:\n",
    "        return model.predict(img)\n",
    "    else:\n",
    "        return np.array(rd.randint(40,90)).reshape(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(rd.randint(20,120)).reshape(1,1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mistrust = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,img,press_time):\n",
    "    model.fit(img,np.array([press_time]).reshape(1,1),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    img = get_img()\n",
    "    while(True):\n",
    "        press_time = network(model,img,1)[0][0]\n",
    "        jump(press_time*10)\n",
    "        time.sleep(2.3+press_time/200)\n",
    "        img_new = get_img()\n",
    "        if fail(img_new):\n",
    "            jump(2)\n",
    "            time.sleep(0.8)\n",
    "            img_new = get_img()\n",
    "        img = img_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.load(\"train_x.npy\")\n",
    "train_y = np.load(\"train_y.npy\")\n",
    "n_sample = train_x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "561.977920532\n",
      "496.441726685\n",
      "537.21660614\n",
      "565.479507446\n",
      "534.708786011\n",
      "532.336959839\n",
      "2\n",
      "534.773406982\n",
      "2\n",
      "570.860939026\n",
      "505.284347534\n",
      "606.732406616\n",
      "2\n",
      "572.868537903\n",
      "1\n",
      "Epoch 1/1\n",
      "2432/2432 [==============================] - 8s 3ms/step - loss: 196.1244\n",
      "680\n",
      "670\n",
      "2\n",
      "700\n",
      "490\n",
      "2\n",
      "560\n",
      "590\n",
      "880\n",
      "2\n",
      "600\n",
      "660\n",
      "440\n",
      "2\n",
      "510\n",
      "2\n",
      "650\n",
      "570\n",
      "440\n",
      "2\n",
      "810\n",
      "660\n",
      "2\n",
      "630\n",
      "860\n",
      "2\n",
      "850\n",
      "552.56439209\n",
      "850\n",
      "2\n",
      "520\n",
      "2\n",
      "591.102867126\n",
      "870\n",
      "2\n",
      "700\n",
      "450\n",
      "2\n",
      "400\n",
      "2\n",
      "760\n",
      "540\n",
      "2\n",
      "640\n",
      "480\n",
      "604.461021423\n",
      "2\n",
      "450\n",
      "2\n",
      "570\n",
      "470\n",
      "2\n",
      "595.936660767\n",
      "600\n",
      "2\n",
      "510\n",
      "2\n",
      "690\n",
      "570\n",
      "810\n",
      "560\n",
      "638.537940979\n",
      "880\n",
      "2\n",
      "820\n",
      "540\n",
      "626.992263794\n",
      "2\n",
      "582.399559021\n",
      "420\n",
      "2\n",
      "510\n",
      "2\n",
      "800\n",
      "554.128303528\n",
      "2\n",
      "608.67603302\n",
      "790\n",
      "890\n",
      "880\n",
      "2\n",
      "880\n",
      "670\n",
      "540\n",
      "820\n",
      "2\n",
      "590\n",
      "589.078369141\n",
      "2\n",
      "569.823608398\n",
      "549.119529724\n",
      "2\n",
      "720\n",
      "527.97454834\n",
      "690\n",
      "582.043609619\n",
      "2\n",
      "670\n",
      "539.744300842\n",
      "2\n",
      "573.479537964\n",
      "670\n",
      "2\n",
      "620\n",
      "535.15171051\n",
      "589.204139709\n",
      "602.420310974\n",
      "790\n",
      "2\n",
      "700\n",
      "567.752952576\n",
      "2\n",
      "573.479537964\n",
      "780\n",
      "550\n",
      "500\n",
      "2\n",
      "570\n",
      "516.60774231\n",
      "490\n",
      "592.855072021\n",
      "590\n",
      "680\n",
      "2\n",
      "604.697036743\n",
      "740\n",
      "531.304626465\n",
      "610\n",
      "586.280784607\n",
      "2\n",
      "830\n",
      "900\n",
      "2\n",
      "420\n",
      "2\n",
      "568.633575439\n",
      "622.595214844\n",
      "2\n",
      "750\n",
      "570\n",
      "602.650718689\n",
      "2\n",
      "595.874633789\n",
      "563.473396301\n",
      "450\n",
      "2\n",
      "595.410041809\n",
      "585.807418823\n",
      "2\n",
      "480\n",
      "2\n",
      "605.838775635\n",
      "589.638938904\n",
      "494.741096497\n",
      "550.713005066\n",
      "600.640144348\n",
      "2\n",
      "599.897956848\n",
      "890\n",
      "2\n",
      "600.108413696\n",
      "577.277374268\n",
      "556.612052917\n",
      "520\n",
      "2\n",
      "585.360221863\n",
      "602.729148865\n",
      "2\n",
      "594.634132385\n",
      "603.74294281\n",
      "2\n",
      "569.823608398\n",
      "710\n",
      "2\n",
      "571.55002594\n",
      "577.975120544\n",
      "2\n",
      "890\n",
      "2\n",
      "720\n",
      "582.258605957\n",
      "2\n",
      "605.838775635\n",
      "580\n",
      "580\n",
      "2\n",
      "575.550842285\n",
      "549.121131897\n",
      "2\n",
      "602.159042358\n",
      "594.233894348\n",
      "2\n",
      "560\n",
      "553.72428894\n",
      "2\n",
      "599.539031982\n",
      "573.597564697\n",
      "2\n",
      "595.410041809\n",
      "500\n",
      "625.595855713\n",
      "2\n",
      "601.683349609\n",
      "595.171203613\n",
      "2\n",
      "520\n",
      "2\n",
      "590\n",
      "541.174316406\n",
      "620.636138916\n",
      "2\n",
      "581.623954773\n",
      "503.469543457\n",
      "512.308807373\n",
      "591.704902649\n",
      "2\n",
      "596.678009033\n",
      "576.095199585\n",
      "2\n",
      "582.399559021\n",
      "588.549118042\n",
      "547.417945862\n",
      "2\n",
      "575.958900452\n",
      "497.51209259\n",
      "569.03175354\n",
      "2\n",
      "589.689483643\n",
      "610.975646973\n",
      "2\n",
      "604.697036743\n",
      "609.251327515\n",
      "2\n",
      "576.264152527\n",
      "580\n",
      "562.182159424\n",
      "517.356491089\n",
      "611.029701233\n",
      "820\n",
      "2\n",
      "680\n",
      "548.06728363\n",
      "582.245903015\n",
      "2\n",
      "600.34236908\n",
      "582.713317871\n",
      "2\n",
      "594.606742859\n",
      "450\n",
      "2\n",
      "400\n",
      "2\n",
      "595.86479187\n",
      "570.11592865\n",
      "586.959686279\n",
      "2\n",
      "599.539031982\n",
      "556.568412781\n",
      "570.027427673\n",
      "2\n",
      "670\n",
      "541.002082825\n",
      "2\n",
      "593.830718994\n",
      "420\n",
      "2\n",
      "581.686172485\n",
      "601.406440735\n",
      "598.706855774\n",
      "2\n",
      "605.838775635\n",
      "519.95475769\n",
      "583.938217163\n",
      "591.005630493\n",
      "2\n",
      "561.882324219\n",
      "2\n",
      "594.606742859\n",
      "539.440040588\n",
      "543.188934326\n",
      "577.536010742\n",
      "2\n",
      "575.958900452\n",
      "620\n",
      "2\n",
      "596.678009033\n",
      "556.494216919\n",
      "577.240905762\n",
      "2\n",
      "602.174415588\n",
      "890\n",
      "528.143463135\n",
      "584.093170166\n",
      "575.177497864\n",
      "561.064796448\n",
      "561.978416443\n",
      "2\n",
      "599.539031982\n",
      "573.340377808\n",
      "2\n",
      "595.372009277\n",
      "564.963264465\n",
      "2\n",
      "594.606742859\n",
      "470\n",
      "2\n",
      "600.34236908\n",
      "613.652687073\n",
      "2\n",
      "591.102867126\n",
      "565.564079285\n",
      "2\n",
      "593.830718994\n",
      "583.882446289\n",
      "1\n",
      "Epoch 1/1\n",
      "2560/2560 [==============================] - 8s 3ms/step - loss: 212.4503\n",
      "650\n",
      "2\n",
      "430\n",
      "2\n",
      "890\n",
      "2\n",
      "750\n",
      "500\n",
      "2\n",
      "590\n",
      "900\n",
      "850\n",
      "2\n",
      "621.068000793\n",
      "410\n",
      "2\n",
      "480\n",
      "2\n",
      "640\n",
      "810\n",
      "2\n",
      "530\n",
      "2\n",
      "710\n",
      "670\n",
      "2\n",
      "730\n",
      "710\n",
      "830\n",
      "619.570922852\n",
      "2\n",
      "490\n",
      "2\n",
      "710\n",
      "730\n",
      "2\n",
      "630.382881165\n",
      "645.563049316\n",
      "860\n",
      "2\n",
      "616.014328003\n",
      "605.224304199\n",
      "580\n",
      "2\n",
      "641.398620605\n",
      "640\n",
      "2\n",
      "580\n",
      "410\n",
      "2\n",
      "720\n",
      "605.070228577\n",
      "580\n",
      "480\n",
      "440\n",
      "643.823471069\n",
      "2\n",
      "770\n",
      "870\n",
      "2\n",
      "700\n",
      "610\n",
      "730\n",
      "720\n",
      "790\n",
      "566.745300293\n",
      "430\n",
      "2\n",
      "760\n",
      "596.977920532\n",
      "2\n",
      "647.024154663\n",
      "581.098937988\n",
      "890\n",
      "2\n",
      "600\n",
      "586.632003784\n",
      "599.75730896\n",
      "628.265914917\n",
      "520\n",
      "589.898147583\n",
      "2\n",
      "600\n",
      "611.939659119\n",
      "652.937393188\n",
      "840\n",
      "2\n",
      "810\n",
      "594.493942261\n",
      "612.208786011\n",
      "710\n",
      "2\n",
      "580\n",
      "850\n",
      "584.248695374\n",
      "619.577903748\n",
      "577.238044739\n",
      "2\n",
      "635.615348816\n",
      "440\n",
      "2\n",
      "470\n",
      "2\n",
      "840\n",
      "604.712791443\n",
      "637.140045166\n",
      "2\n",
      "648.653640747\n",
      "680\n",
      "631.587333679\n",
      "635.446281433\n",
      "500\n",
      "693.44367981\n",
      "2\n",
      "632.999725342\n",
      "450\n",
      "2\n",
      "420\n",
      "2\n",
      "629.92401123\n",
      "690\n",
      "2\n",
      "633.459510803\n",
      "770\n",
      "2\n",
      "632.358703613\n",
      "634.020614624\n",
      "530\n",
      "600\n",
      "584.306907654\n",
      "2\n",
      "635.219535828\n",
      "574.266242981\n",
      "569.194068909\n",
      "602.517814636\n",
      "642.767410278\n",
      "2\n",
      "660\n",
      "540.796966553\n",
      "608.772506714\n",
      "2\n",
      "630\n",
      "632.436447144\n",
      "2\n",
      "650\n",
      "613.433952332\n",
      "2\n",
      "629.92401123\n",
      "640\n",
      "624.110794067\n",
      "2\n",
      "890\n",
      "2\n",
      "647.244033813\n",
      "520\n",
      "599.785766602\n",
      "595.708503723\n",
      "2\n",
      "430\n",
      "2\n",
      "644.082717896\n",
      "656.209716797\n",
      "623.019332886\n",
      "600.929260254\n",
      "614.872283936\n",
      "2\n",
      "615.664978027\n",
      "549.856948853\n",
      "2\n",
      "625.335159302\n",
      "820\n",
      "2\n",
      "633.459510803\n",
      "500\n",
      "555.097045898\n",
      "674.580307007\n",
      "659.141616821\n",
      "2\n",
      "658.467941284\n",
      "616.559371948\n",
      "613.2654953\n",
      "612.200546265\n",
      "2\n",
      "605.303421021\n",
      "652.562026978\n",
      "2\n",
      "617.1900177\n",
      "602.414283752\n",
      "601.284179688\n",
      "576.343650818\n",
      "618.18271637\n",
      "590.587310791\n",
      "634.488868713\n",
      "640\n",
      "660\n",
      "571.162452698\n",
      "649.589157104\n",
      "657.937240601\n",
      "2\n",
      "626.036262512\n",
      "820\n",
      "2\n",
      "611.688232422\n",
      "606.717643738\n",
      "2\n",
      "600\n",
      "577.766494751\n",
      "2\n",
      "622.062721252\n",
      "549.641418457\n",
      "555.44670105\n",
      "584.264030457\n",
      "2\n",
      "602.013969421\n",
      "410\n",
      "2\n",
      "629.92401123\n",
      "660\n",
      "2\n",
      "440\n",
      "2\n",
      "644.082717896\n",
      "618.236961365\n",
      "632.158317566\n",
      "687.695846558\n",
      "562.12600708\n",
      "2\n",
      "627.403106689\n",
      "860\n",
      "604.407844543\n",
      "646.522064209\n",
      "712.056274414\n",
      "2\n",
      "627.403106689\n",
      "627.672042847\n",
      "2\n",
      "637.867355347\n",
      "625.89263916\n",
      "830\n",
      "2\n",
      "611.164321899\n",
      "653.230895996\n",
      "2\n",
      "617.121658325\n",
      "644.345703125\n",
      "2\n",
      "629.92401123\n",
      "830\n",
      "633.933372498\n",
      "571.868247986\n",
      "2\n",
      "617.1900177\n",
      "655.059814453\n",
      "2\n",
      "658.467941284\n",
      "591.039733887\n",
      "606.326904297\n",
      "2\n",
      "618.062057495\n",
      "510\n",
      "2\n",
      "639.301681519\n",
      "595.780601501\n",
      "592.525596619\n",
      "2\n",
      "616.612281799\n",
      "569.189987183\n",
      "2\n",
      "617.1900177\n",
      "568.11958313\n",
      "2\n",
      "639.301681519\n",
      "549.809646606\n",
      "601.066360474\n",
      "2\n",
      "600\n",
      "598.775672913\n",
      "586.486473083\n",
      "605.962791443\n",
      "2\n",
      "648.955917358\n",
      "563.452377319\n",
      "625.715065002\n",
      "2\n",
      "638.783073425\n",
      "860\n",
      "645.031661987\n",
      "666.800994873\n",
      "2\n",
      "627.403106689\n",
      "608.641624451\n",
      "640.21522522\n",
      "1\n",
      "Epoch 1/1\n",
      "2688/2688 [==============================] - 8s 3ms/step - loss: 213.5345\n",
      "820\n",
      "720\n",
      "2\n",
      "540\n",
      "2\n",
      "900\n",
      "2\n",
      "410\n",
      "2\n",
      "730\n",
      "601.973304749\n",
      "2\n",
      "637.110557556\n",
      "800\n",
      "610\n",
      "2\n",
      "640\n",
      "470\n",
      "780\n",
      "880\n",
      "2\n",
      "550\n",
      "640\n",
      "700\n",
      "750\n",
      "600\n",
      "2\n",
      "720\n",
      "510\n",
      "620\n",
      "760\n",
      "2\n",
      "820\n",
      "570\n",
      "2\n",
      "590\n",
      "690\n",
      "770\n",
      "900\n",
      "750\n",
      "2\n",
      "500\n",
      "2\n",
      "596.316299438\n",
      "555.673370361\n",
      "840\n",
      "2\n",
      "608.199653625\n",
      "622.691879272\n",
      "2\n",
      "680\n",
      "601.752090454\n",
      "572.440605164\n",
      "540\n",
      "2\n",
      "634.023017883\n",
      "590\n",
      "670\n",
      "611.262741089\n",
      "430\n",
      "450\n",
      "2\n",
      "900\n",
      "2\n",
      "615.289993286\n",
      "490\n",
      "2\n",
      "633.390007019\n",
      "622.137451172\n",
      "2\n",
      "800\n",
      "810\n",
      "590\n",
      "780\n",
      "860\n",
      "657.771606445\n",
      "2\n",
      "890\n",
      "2\n",
      "641.194534302\n",
      "840\n",
      "2\n",
      "615.309944153\n",
      "649.239578247\n",
      "2\n",
      "589.235038757\n",
      "590.650482178\n",
      "850\n",
      "2\n",
      "637.110557556\n",
      "410\n",
      "2\n",
      "594.133338928\n",
      "592.113418579\n",
      "581.36390686\n",
      "633.480567932\n",
      "550\n",
      "620.945396423\n",
      "600.372924805\n",
      "770\n",
      "730\n",
      "870\n",
      "2\n",
      "618.854637146\n",
      "730\n",
      "624.078712463\n",
      "600\n",
      "592.890777588\n",
      "678.503646851\n",
      "2\n",
      "770\n",
      "600.61630249\n",
      "2\n",
      "614.143333435\n",
      "633.433494568\n",
      "634.264984131\n",
      "577.581481934\n",
      "2\n",
      "640\n",
      "590\n",
      "2\n",
      "700\n",
      "566.956596375\n",
      "570.443649292\n",
      "2\n",
      "603.508529663\n",
      "626.606559753\n",
      "2\n",
      "613.807754517\n",
      "614.729881287\n",
      "2\n",
      "720\n",
      "587.380943298\n",
      "578.779067993\n",
      "2\n",
      "780\n",
      "670\n",
      "2\n",
      "629.451713562\n",
      "661.901702881\n",
      "2\n",
      "600\n",
      "490\n",
      "2\n",
      "595.53401947\n",
      "632.133789062\n",
      "2\n",
      "607.42023468\n",
      "820\n",
      "820\n",
      "633.151016235\n",
      "624.325447083\n",
      "609.001960754\n",
      "2\n",
      "860\n",
      "572.738037109\n",
      "559.439086914\n",
      "800\n",
      "571.017112732\n",
      "605.773620605\n",
      "580\n",
      "560\n",
      "608.388977051\n",
      "2\n",
      "440\n",
      "2\n",
      "618.529548645\n",
      "562.113876343\n",
      "2\n",
      "638.066101074\n",
      "608.344116211\n",
      "631.978225708\n",
      "2\n",
      "800\n",
      "586.461906433\n",
      "2\n",
      "611.955413818\n",
      "519.719696045\n",
      "586.09413147\n",
      "610.647125244\n",
      "740\n",
      "2\n",
      "597.176818848\n",
      "664.781112671\n",
      "2\n",
      "614.974327087\n",
      "480\n",
      "410\n",
      "607.474327087\n",
      "600.083198547\n",
      "2\n",
      "618.854637146\n",
      "662.27432251\n",
      "2\n",
      "608.231925964\n",
      "400\n",
      "2\n",
      "619.324302673\n",
      "400\n",
      "2\n",
      "611.955413818\n",
      "520.160217285\n",
      "598.45954895\n",
      "2\n",
      "592.799720764\n",
      "571.459884644\n",
      "2\n",
      "632.698402405\n",
      "680\n",
      "578.567237854\n",
      "2\n",
      "611.955413818\n",
      "596.313323975\n",
      "637.884902954\n",
      "2\n",
      "638.066101074\n",
      "613.156814575\n",
      "688.41835022\n",
      "2\n",
      "621.503868103\n",
      "700\n",
      "639.294815063\n",
      "621.975975037\n",
      "2\n",
      "615.289993286\n",
      "545.400733948\n",
      "650.983352661\n",
      "634.693527222\n",
      "2\n",
      "618.343009949\n",
      "632.566566467\n",
      "597.977867126\n",
      "2\n",
      "615.289993286\n",
      "582.22984314\n",
      "2\n",
      "629.451713562\n",
      "480\n",
      "2\n",
      "606.447906494\n",
      "565.634384155\n",
      "2\n",
      "608.586883545\n",
      "626.065750122\n",
      "600.986747742\n",
      "2\n",
      "638.066101074\n",
      "628.30997467\n",
      "2\n",
      "628.022155762\n",
      "576.287956238\n",
      "602.62588501\n",
      "2\n",
      "632.698402405\n",
      "563.964767456\n",
      "622.915534973\n",
      "460\n",
      "2\n",
      "613.120689392\n",
      "598.607330322\n",
      "2\n",
      "636.518325806\n",
      "630\n",
      "2\n",
      "615.289993286\n",
      "550.169639587\n",
      "750\n",
      "2\n",
      "633.390007019\n",
      "574.258499146\n",
      "575.522499084\n",
      "770\n",
      "650.271835327\n",
      "530\n",
      "2\n",
      "613.807754517\n",
      "600.401992798\n",
      "1\n",
      "Epoch 1/1\n",
      "2816/2816 [==============================] - 9s 3ms/step - loss: 218.2801\n",
      "750\n",
      "610\n",
      "890\n",
      "585.909576416\n",
      "2\n",
      "800\n",
      "400\n",
      "520\n",
      "2\n",
      "820\n",
      "420\n",
      "2\n",
      "520\n",
      "2\n",
      "595.960159302\n",
      "430\n",
      "560\n",
      "621.87210083\n",
      "460\n",
      "2\n",
      "500\n",
      "2\n",
      "480\n",
      "2\n",
      "606.359176636\n",
      "560.17414093\n",
      "470\n",
      "790\n",
      "2\n",
      "550\n",
      "2\n",
      "850\n",
      "430\n",
      "565.996170044\n",
      "550\n",
      "603.988113403\n",
      "830\n",
      "562.308692932\n",
      "557.64503479\n",
      "2\n",
      "790\n",
      "880\n",
      "2\n",
      "510\n",
      "2\n",
      "490\n",
      "2\n",
      "616.839294434\n",
      "440\n",
      "2\n",
      "600.105934143\n",
      "610.767784119\n",
      "2\n",
      "440\n",
      "2\n",
      "620.288467407\n",
      "600\n",
      "2\n",
      "620.288467407\n",
      "550.454330444\n",
      "600\n",
      "810\n",
      "900\n",
      "557.814788818\n",
      "2\n",
      "780\n",
      "520\n",
      "2\n",
      "680\n",
      "450\n",
      "900\n",
      "2\n",
      "760\n",
      "598.072624207\n",
      "2\n",
      "606.258621216\n",
      "570.9815979\n",
      "560\n",
      "591.073188782\n",
      "480\n",
      "430\n",
      "870\n",
      "2\n",
      "613.250617981\n",
      "595.98526001\n",
      "620\n",
      "780\n",
      "2\n",
      "410\n",
      "2\n",
      "609.346694946\n",
      "593.046112061\n",
      "2\n",
      "410\n",
      "2\n",
      "577.171173096\n",
      "530\n",
      "2\n",
      "614.955978394\n",
      "610.871353149\n",
      "582.25933075\n",
      "630\n",
      "596.290359497\n",
      "2\n",
      "650\n",
      "450\n",
      "2\n",
      "609.672889709\n",
      "636.94065094\n",
      "596.983947754\n",
      "611.21723175\n",
      "2\n",
      "614.645576477\n",
      "610.303268433\n",
      "585.704498291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "610.707168579\n",
      "560.015296936\n",
      "608.151016235\n",
      "2\n",
      "598.312110901\n",
      "529.471130371\n",
      "610\n",
      "2\n",
      "500\n",
      "2\n",
      "599.153747559\n",
      "840\n",
      "2\n",
      "880\n",
      "599.297027588\n",
      "633.768959045\n",
      "2\n",
      "616.64680481\n",
      "589.946632385\n",
      "530.402412415\n",
      "584.336013794\n",
      "606.471862793\n",
      "577.2996521\n",
      "2\n",
      "760\n",
      "571.298522949\n",
      "2\n",
      "615.251922607\n",
      "596.968002319\n",
      "2\n",
      "589.164810181\n",
      "620.721054077\n",
      "580.526008606\n",
      "850\n",
      "2\n",
      "616.64680481\n",
      "633.417625427\n",
      "619.466056824\n",
      "2\n",
      "680\n",
      "582.328529358\n",
      "583.421592712\n",
      "595.67199707\n",
      "2\n",
      "591.891441345\n",
      "572.664070129\n",
      "2\n",
      "710\n",
      "542.392959595\n",
      "460\n",
      "2\n",
      "610\n",
      "553.348846436\n",
      "830\n",
      "2\n",
      "430\n",
      "2\n",
      "582.587356567\n",
      "680\n",
      "621.097946167\n",
      "2\n",
      "595.960159302\n",
      "556.952667236\n",
      "760\n",
      "584.345626831\n",
      "607.555809021\n",
      "615.375785828\n",
      "2\n",
      "592.961120605\n",
      "564.504890442\n",
      "2\n",
      "770\n",
      "800\n",
      "2\n",
      "595.960159302\n",
      "579.143371582\n",
      "548.529815674\n",
      "611.132354736\n",
      "599.740486145\n",
      "609.671630859\n",
      "2\n",
      "609.716377258\n",
      "593.874206543\n",
      "589.255409241\n",
      "606.042785645\n",
      "2\n",
      "607.87902832\n",
      "596.609725952\n",
      "598.359527588\n",
      "420\n",
      "2\n",
      "579.86076355\n",
      "740\n",
      "2\n",
      "618.287124634\n",
      "564.904251099\n",
      "592.351417542\n",
      "606.509017944\n",
      "619.600982666\n",
      "613.287506104\n",
      "586.66557312\n",
      "581.79599762\n",
      "2\n",
      "616.64680481\n",
      "730\n",
      "770\n",
      "2\n",
      "611.286468506\n",
      "400\n",
      "2\n",
      "800\n",
      "587.908744812\n",
      "646.835784912\n",
      "602.665557861\n",
      "592.190933228\n",
      "605.618400574\n",
      "2\n",
      "613.250617981\n",
      "530\n",
      "631.803092957\n",
      "2\n",
      "611.243019104\n",
      "613.0701828\n",
      "820\n",
      "2\n",
      "615.10974884\n",
      "607.806739807\n",
      "611.138076782\n",
      "619.115142822\n",
      "2\n",
      "589.164810181\n",
      "579.718513489\n",
      "609.719924927\n",
      "840\n",
      "593.82938385\n",
      "550.607337952\n",
      "2\n",
      "550\n",
      "637.89855957\n",
      "2\n",
      "810\n",
      "579.262504578\n",
      "562.499656677\n",
      "612.002372742\n",
      "2\n",
      "582.193870544\n",
      "571.521759033\n",
      "2\n",
      "606.810455322\n",
      "604.401283264\n",
      "2\n",
      "592.119064331\n",
      "591.239280701\n",
      "2\n",
      "591.891441345\n",
      "568.755912781\n",
      "2\n",
      "582.193870544\n",
      "576.399459839\n",
      "533.303794861\n",
      "2\n",
      "610.651855469\n",
      "625.122261047\n",
      "2\n",
      "574.243965149\n",
      "551.229362488\n",
      "2\n",
      "580\n",
      "597.57019043\n",
      "2\n",
      "593.243141174\n",
      "619.218521118\n",
      "2\n",
      "600\n",
      "1\n",
      "Epoch 1/1\n",
      "2944/2944 [==============================] - 9s 3ms/step - loss: 206.9501\n",
      "900\n",
      "2\n",
      "440\n",
      "2\n",
      "510\n",
      "2\n",
      "590\n",
      "490\n",
      "820\n",
      "420\n",
      "2\n",
      "820\n",
      "770\n",
      "2\n",
      "450\n",
      "2\n",
      "720\n",
      "630\n",
      "2\n",
      "490\n",
      "2\n",
      "620\n",
      "515.688591003\n",
      "810\n",
      "2\n",
      "640.280990601\n",
      "690\n",
      "880\n",
      "540\n",
      "790\n",
      "490\n",
      "550\n",
      "2\n",
      "627.117080688\n",
      "570\n",
      "2\n",
      "820\n",
      "670\n",
      "595.95703125\n",
      "607.840232849\n",
      "2\n",
      "440\n",
      "2\n",
      "540\n",
      "2\n",
      "570\n",
      "609.49634552\n",
      "670\n",
      "840\n",
      "620\n",
      "410\n",
      "2\n",
      "480\n",
      "2\n",
      "410\n",
      "2\n",
      "630\n",
      "850\n",
      "2\n",
      "631.103286743\n",
      "570\n",
      "2\n",
      "609.248657227\n",
      "510\n",
      "598.046531677\n",
      "585.24230957\n",
      "2\n",
      "620\n",
      "850\n",
      "2\n",
      "820\n",
      "622.831459045\n",
      "2\n",
      "630\n",
      "540\n",
      "760\n",
      "820\n",
      "2\n",
      "606.067504883\n",
      "510\n",
      "820\n",
      "440\n",
      "557.687187195\n",
      "530\n",
      "530\n",
      "2\n",
      "580\n",
      "661.407470703\n",
      "2\n",
      "620.861206055\n",
      "720\n",
      "740\n",
      "820\n",
      "660\n",
      "2\n",
      "628.674163818\n",
      "770\n",
      "740\n",
      "638.274688721\n",
      "2\n",
      "656.131210327\n",
      "566.212387085\n",
      "2\n",
      "622.992668152\n",
      "550\n",
      "520\n",
      "617.365150452\n",
      "880\n",
      "2\n",
      "651.98928833\n",
      "750\n",
      "2\n",
      "640.280990601\n",
      "420\n",
      "530\n",
      "574.478988647\n",
      "2\n",
      "490\n",
      "2\n",
      "624.165534973\n",
      "850\n",
      "594.172859192\n",
      "551.054725647\n",
      "740\n",
      "2\n",
      "628.356781006\n",
      "594.479103088\n",
      "639.454154968\n",
      "669.613571167\n",
      "654.881744385\n",
      "680\n",
      "610\n",
      "2\n",
      "622.992668152\n",
      "598.820838928\n",
      "670\n",
      "760\n",
      "2\n",
      "632.174339294\n",
      "623.508415222\n",
      "500\n",
      "590.796585083\n",
      "588.631324768\n",
      "2\n",
      "638.825149536\n",
      "750\n",
      "640\n",
      "2\n",
      "638.561172485\n",
      "650.396499634\n",
      "2\n",
      "600\n",
      "720\n",
      "677.950210571\n",
      "2\n",
      "642.502212524\n",
      "531.757736206\n",
      "578.418731689\n",
      "590.16002655\n",
      "2\n",
      "670\n",
      "507.602081299\n",
      "558.781852722\n",
      "597.153816223\n",
      "660\n",
      "2\n",
      "666.35635376\n",
      "529.740562439\n",
      "550\n",
      "2\n",
      "659.356307983\n",
      "630.589599609\n",
      "2\n",
      "480\n",
      "2\n",
      "646.780395508\n",
      "631.904678345\n",
      "2\n",
      "637.823410034\n",
      "544.453086853\n",
      "569.949455261\n",
      "672.107315063\n",
      "615.463256836\n",
      "599.379730225\n",
      "2\n",
      "629.578285217\n",
      "594.439048767\n",
      "2\n",
      "470\n",
      "2\n",
      "606.41368866\n",
      "502.911643982\n",
      "480\n",
      "608.892478943\n",
      "2\n",
      "647.518081665\n",
      "547.020683289\n",
      "570\n",
      "810\n",
      "529.460487366\n",
      "561.421699524\n",
      "599.932479858\n",
      "2\n",
      "632.946014404\n",
      "509.319190979\n",
      "583.169937134\n",
      "520\n",
      "2\n",
      "644.834747314\n",
      "600.311431885\n",
      "656.294555664\n",
      "603.429145813\n",
      "2\n",
      "638.825149536\n",
      "530.408058167\n",
      "2\n",
      "596.050949097\n",
      "505.720787048\n",
      "708.909835815\n",
      "2\n",
      "635.892524719\n",
      "568.507614136\n",
      "2\n",
      "638.561172485\n",
      "511.787872314\n",
      "608.95866394\n",
      "604.294586182\n",
      "2\n",
      "631.103286743\n",
      "496.286964417\n",
      "620\n",
      "579.95388031\n",
      "2\n",
      "637.823410034\n",
      "607.311553955\n",
      "602.592735291\n",
      "586.651229858\n",
      "2\n",
      "720\n",
      "641.995925903\n",
      "2\n",
      "659.364700317\n",
      "603.263206482\n",
      "666.262512207\n",
      "2\n",
      "615.274963379\n",
      "610.563011169\n",
      "2\n",
      "750\n",
      "606.530227661\n",
      "730\n",
      "602.722473145\n",
      "570.114173889\n",
      "2\n",
      "631.103286743\n",
      "545.712280273\n",
      "2\n",
      "619.179039001\n",
      "750\n",
      "556.378860474\n",
      "2\n",
      "581.257209778\n",
      "450\n",
      "2\n",
      "606.41368866\n",
      "760\n",
      "2\n",
      "629.034347534\n",
      "628.565444946\n",
      "2\n",
      "652.465057373\n",
      "608.193740845\n",
      "622.930793762\n",
      "609.696044922\n",
      "2\n",
      "621.571273804\n",
      "680\n",
      "601.009750366\n",
      "860\n",
      "558.193359375\n",
      "629.51625824\n",
      "564.162445068\n",
      "626.910667419\n",
      "639.610710144\n",
      "2\n",
      "609.743461609\n",
      "850\n",
      "2\n",
      "608.937034607\n",
      "568.751792908\n",
      "588.901977539\n",
      "527.127380371\n",
      "2\n",
      "638.561172485\n",
      "1\n",
      "Epoch 1/1\n",
      "3072/3072 [==============================] - 10s 3ms/step - loss: 201.8143\n",
      "890\n",
      "2\n",
      "400\n",
      "2\n",
      "680\n",
      "840\n",
      "2\n",
      "720\n",
      "570\n",
      "830\n",
      "2\n",
      "600.149993896\n",
      "800\n",
      "880\n",
      "2\n",
      "410\n",
      "2\n",
      "520\n",
      "2\n",
      "560\n",
      "550\n",
      "2\n",
      "609.471549988\n",
      "900\n",
      "2\n",
      "750\n",
      "550\n",
      "500\n",
      "2\n",
      "500\n",
      "2\n",
      "612.004203796\n",
      "490\n",
      "2\n",
      "440\n",
      "2\n",
      "750\n",
      "550\n",
      "580\n",
      "2\n",
      "850\n",
      "770\n",
      "2\n",
      "609.632530212\n",
      "620\n",
      "2\n",
      "634.844245911\n",
      "760\n",
      "410\n",
      "2\n",
      "860\n",
      "553.829917908\n",
      "750\n",
      "860\n",
      "900\n",
      "2\n",
      "750\n",
      "700\n",
      "850\n",
      "2\n",
      "620\n",
      "440\n",
      "2\n",
      "628.256149292\n",
      "610\n",
      "626.226997375\n",
      "450\n",
      "2\n",
      "460\n",
      "2\n",
      "840\n",
      "870\n",
      "700\n",
      "680\n",
      "2\n",
      "608.058776855\n",
      "760\n",
      "587.940979004\n",
      "570\n",
      "840\n",
      "2\n",
      "810\n",
      "630\n",
      "2\n",
      "730\n",
      "562.474975586\n",
      "646.498794556\n",
      "2\n",
      "617.501449585\n",
      "609.356079102\n",
      "2\n",
      "690\n",
      "780\n",
      "2\n",
      "450\n",
      "2\n",
      "598.412704468\n",
      "770\n",
      "2\n",
      "584.45690155\n",
      "583.360939026\n",
      "2\n",
      "625.172996521\n",
      "600\n",
      "630\n",
      "2\n",
      "590\n",
      "561.921386719\n",
      "603.250579834\n",
      "2\n",
      "440\n",
      "2\n",
      "540\n",
      "780\n",
      "580.495567322\n",
      "460\n",
      "2\n",
      "585.597572327\n",
      "566.685523987\n",
      "644.248580933\n",
      "2\n",
      "610.054473877\n",
      "626.057090759\n",
      "520\n",
      "2\n",
      "625.401649475\n",
      "420\n",
      "2\n",
      "610\n",
      "581.887626648\n",
      "597.488136292\n",
      "890\n",
      "2\n",
      "900\n",
      "2\n",
      "602.861633301\n",
      "670\n",
      "2\n",
      "490\n",
      "2\n",
      "607.473258972\n",
      "586.33972168\n",
      "2\n",
      "900\n",
      "2\n",
      "609.632530212\n",
      "567.146110535\n",
      "569.046554565\n",
      "2\n",
      "620.520133972\n",
      "517.742843628\n",
      "587.683029175\n",
      "2\n",
      "617.501449585\n",
      "690\n",
      "2\n",
      "630.439186096\n",
      "551.534614563\n",
      "650\n",
      "2\n",
      "601.289367676\n",
      "579.458885193\n",
      "2\n",
      "607.967605591\n",
      "533.02532196\n",
      "553.890419006\n",
      "605.650138855\n",
      "2\n",
      "840\n",
      "610\n",
      "590.973930359\n",
      "640\n",
      "605.427284241\n",
      "520\n",
      "624.86114502\n",
      "563.443183899\n",
      "656.886444092\n",
      "591.967887878\n",
      "2\n",
      "617.414131165\n",
      "587.153282166\n",
      "650.830154419\n",
      "659.831390381\n",
      "2\n",
      "584.511795044\n",
      "600\n",
      "592.623329163\n",
      "2\n",
      "460\n",
      "2\n",
      "600.149993896\n",
      "640\n",
      "700\n",
      "622.728919983\n",
      "534.718017578\n",
      "2\n",
      "596.224060059\n",
      "533.306999207\n",
      "560.470046997\n",
      "637.222862244\n",
      "603.44783783\n",
      "623.44833374\n",
      "2\n",
      "880\n",
      "585.502204895\n",
      "2\n",
      "604.557189941\n",
      "840\n",
      "608.337936401\n",
      "535.698280334\n",
      "661.780090332\n",
      "2\n",
      "582.005729675\n",
      "530.130767822\n",
      "527.844924927\n",
      "460\n",
      "590\n",
      "559.10369873\n",
      "571.173591614\n",
      "2\n",
      "595.463066101\n",
      "578.775787354\n",
      "2\n",
      "589.83959198\n",
      "628.276367188\n",
      "654.050140381\n",
      "2\n",
      "580.059204102\n",
      "563.601837158\n",
      "2\n",
      "584.511795044\n",
      "580.998077393\n",
      "2\n",
      "614.87361908\n",
      "639.856872559\n",
      "2\n",
      "600.149993896\n",
      "616.361045837\n",
      "2\n",
      "600.149993896\n",
      "521.680488586\n",
      "550.441360474\n",
      "648.679504395\n",
      "2\n",
      "616.917419434\n",
      "585.492782593\n",
      "710\n",
      "2\n",
      "601.289367676\n",
      "631.683349609\n",
      "2\n",
      "820\n",
      "810\n",
      "2\n",
      "600.149993896\n",
      "631.201095581\n",
      "2\n",
      "627.108154297\n",
      "602.358283997\n",
      "2\n",
      "604.557189941\n",
      "547.315406799\n",
      "574.657554626\n",
      "2\n",
      "628.256149292\n",
      "603.087730408\n",
      "635.561294556\n",
      "2\n",
      "630.439186096\n",
      "641.110992432\n",
      "2\n",
      "400\n",
      "2\n",
      "440\n",
      "2\n",
      "615.707626343\n",
      "509.804153442\n",
      "546.164779663\n",
      "651.031646729\n",
      "2\n",
      "420\n",
      "2\n",
      "598.021736145\n",
      "644.906997681\n",
      "2\n",
      "600.149993896\n",
      "556.169281006\n",
      "537.771911621\n",
      "480\n",
      "2\n",
      "609.765472412\n",
      "569.315071106\n",
      "810\n",
      "621.60282135\n",
      "400\n",
      "2\n",
      "600.149993896\n",
      "637.455711365\n",
      "2\n",
      "830\n",
      "564.183578491\n",
      "566.832466125\n",
      "594.110374451\n",
      "514.253311157\n",
      "651.723175049\n",
      "639.171524048\n",
      "636.271438599\n",
      "598.833732605\n",
      "588.504600525\n",
      "2\n",
      "820\n",
      "1\n",
      "Epoch 1/1\n",
      "3200/3200 [==============================] - 10s 3ms/step - loss: 221.4506\n",
      "840\n",
      "500\n",
      "800\n",
      "2\n",
      "420\n",
      "2\n",
      "510\n",
      "2\n",
      "630\n",
      "600\n",
      "2\n",
      "470\n",
      "2\n",
      "740\n",
      "440\n",
      "2\n",
      "500\n",
      "2\n",
      "440\n",
      "2\n",
      "890\n",
      "2\n",
      "880\n",
      "710\n",
      "730\n",
      "690\n",
      "690\n",
      "720\n",
      "890\n",
      "2\n",
      "640\n",
      "550\n",
      "2\n",
      "530\n",
      "2\n",
      "420\n",
      "2\n",
      "617.572021484\n",
      "680\n",
      "450\n",
      "640\n",
      "680\n",
      "770\n",
      "2\n",
      "790\n",
      "790\n",
      "900\n",
      "2\n",
      "880\n",
      "2\n",
      "593.615379333\n",
      "560.827674866\n",
      "555.657539368\n",
      "520\n",
      "500\n",
      "2\n",
      "605.83896637\n",
      "860\n",
      "780\n",
      "595.264816284\n",
      "2\n",
      "615.977973938\n",
      "560\n",
      "633.261070251\n",
      "2\n",
      "582.620353699\n",
      "600\n",
      "2\n",
      "592.383995056\n",
      "490\n",
      "400\n",
      "580\n",
      "2\n",
      "588.996009827\n",
      "622.656326294\n",
      "2\n",
      "590.911369324\n",
      "571.860771179\n",
      "550\n",
      "820\n",
      "2\n",
      "450.669059753\n",
      "2\n",
      "860\n",
      "730\n",
      "830\n",
      "770\n",
      "680\n",
      "2\n",
      "650\n",
      "780\n",
      "2\n",
      "420\n",
      "2\n",
      "870\n",
      "605.876541138\n",
      "900\n",
      "557.963485718\n",
      "820\n",
      "2\n",
      "603.00907135\n",
      "574.736061096\n",
      "2\n",
      "850\n",
      "710\n",
      "2\n",
      "596.1353302\n",
      "606.057853699\n",
      "2\n",
      "577.667655945\n",
      "880\n",
      "576.614494324\n",
      "800\n",
      "2\n",
      "589.98008728\n",
      "550.300102234\n",
      "643.080368042\n",
      "2\n",
      "589.987945557\n",
      "610\n",
      "2\n",
      "591.539802551\n",
      "581.469154358\n",
      "2\n",
      "587.733955383\n",
      "548.082885742\n",
      "583.415565491\n",
      "2\n",
      "568.778419495\n",
      "770\n",
      "582.819595337\n",
      "595.262298584\n",
      "2\n",
      "592.691955566\n",
      "564.091377258\n",
      "579.894523621\n",
      "2\n",
      "570\n",
      "680\n",
      "2\n",
      "591.539802551\n",
      "620\n",
      "2\n",
      "740\n",
      "524.034690857\n",
      "568.649787903\n",
      "2\n",
      "601.809921265\n",
      "860\n",
      "2\n",
      "593.30745697\n",
      "660\n",
      "557.335968018\n",
      "577.864265442\n",
      "538.105964661\n",
      "560\n",
      "2\n",
      "850\n",
      "559.493217468\n",
      "551.321868896\n",
      "591.014404297\n",
      "2\n",
      "579.095535278\n",
      "730\n",
      "590.442428589\n",
      "551.751785278\n",
      "2\n",
      "617.572021484\n",
      "640\n",
      "2\n",
      "480\n",
      "2\n",
      "610.725975037\n",
      "544.50881958\n",
      "586.306991577\n",
      "2\n",
      "602.542037964\n",
      "558.044967651\n",
      "500\n",
      "561.272544861\n",
      "2\n",
      "530\n",
      "2\n",
      "574.340629578\n",
      "531.512260437\n",
      "640\n",
      "580\n",
      "2\n",
      "597.593727112\n",
      "563.280487061\n",
      "563.987197876\n",
      "740\n",
      "2\n",
      "572.780914307\n",
      "810\n",
      "590.599937439\n",
      "575.203857422\n",
      "2\n",
      "569.701881409\n",
      "524.132080078\n",
      "564.536476135\n",
      "568.019142151\n",
      "2\n",
      "572.780914307\n",
      "573.316955566\n",
      "2\n",
      "593.169708252\n",
      "720\n",
      "2\n",
      "587.340545654\n",
      "568.326034546\n",
      "2\n",
      "610.740585327\n",
      "632.323074341\n",
      "2\n",
      "760\n",
      "539.352645874\n",
      "2\n",
      "601.809921265\n",
      "579.191017151\n",
      "620\n",
      "2\n",
      "582.847290039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499.926452637\n",
      "670\n",
      "2\n",
      "630\n",
      "650\n",
      "583.954048157\n",
      "602.637138367\n",
      "565.632209778\n",
      "562.828330994\n",
      "575.174713135\n",
      "2\n",
      "593.169708252\n",
      "599.949455261\n",
      "2\n",
      "406.693000793\n",
      "2\n",
      "602.542037964\n",
      "522.329483032\n",
      "569.380950928\n",
      "2\n",
      "596.1353302\n",
      "598.141136169\n",
      "2\n",
      "579.227294922\n",
      "571.376304626\n",
      "540.315742493\n",
      "520\n",
      "850\n",
      "529.647102356\n",
      "612.397422791\n",
      "2\n",
      "617.572021484\n",
      "598.441162109\n",
      "603.700332642\n",
      "2\n",
      "586.812477112\n",
      "573.627548218\n",
      "548.887481689\n",
      "552.269210815\n",
      "2\n",
      "433.764419556\n",
      "2\n",
      "593.615379333\n",
      "601.284980774\n",
      "2\n",
      "750\n",
      "576.436500549\n",
      "590.97984314\n",
      "641.708297729\n",
      "579.014129639\n",
      "592.831306458\n",
      "2\n",
      "572.780914307\n",
      "608.88217926\n",
      "608.92250061\n",
      "2\n",
      "610.740585327\n",
      "510\n",
      "572.944221497\n",
      "561.370697021\n",
      "664.84703064\n",
      "2\n",
      "593.148384094\n",
      "598.855476379\n",
      "2\n",
      "582.852630615\n",
      "574.574699402\n",
      "2\n",
      "580.492134094\n",
      "585.210762024\n",
      "2\n",
      "510\n",
      "2\n",
      "400\n",
      "2\n",
      "603.00907135\n",
      "860\n",
      "2\n",
      "605.83896637\n",
      "623.94695282\n",
      "2\n",
      "610.740585327\n",
      "596.166687012\n",
      "2\n",
      "407.952156067\n",
      "2\n",
      "595.802574158\n",
      "535.886268616\n",
      "2\n",
      "570.917243958\n",
      "1\n",
      "Epoch 1/1\n",
      "3328/3328 [==============================] - 10s 3ms/step - loss: 210.8313\n",
      "760\n",
      "510\n",
      "840\n",
      "420\n",
      "750\n",
      "2\n",
      "641.283416748\n",
      "830\n",
      "410\n",
      "2\n",
      "630\n",
      "420\n",
      "2\n",
      "597.288208008\n",
      "616.916542053\n",
      "2\n",
      "650\n",
      "610\n",
      "2\n",
      "400\n",
      "2\n",
      "800\n",
      "740\n",
      "2\n",
      "640\n",
      "530\n",
      "670\n",
      "2\n",
      "470\n",
      "2\n",
      "830\n",
      "581.303062439\n",
      "420\n",
      "633.991203308\n",
      "629.637107849\n",
      "810\n",
      "620\n",
      "2\n",
      "641.283416748\n",
      "578.713989258\n",
      "2\n",
      "860\n",
      "820\n",
      "2\n",
      "850\n",
      "530\n",
      "2\n",
      "780\n",
      "540\n",
      "540\n",
      "2\n",
      "430\n",
      "2\n",
      "551.143836975\n",
      "580\n",
      "760\n",
      "500\n",
      "600\n",
      "2\n",
      "612.440986633\n",
      "572.536621094\n",
      "760\n",
      "591.046676636\n",
      "590\n",
      "602.62550354\n",
      "850\n",
      "460\n",
      "581.849975586\n",
      "2\n",
      "594.416770935\n",
      "740\n",
      "2\n",
      "740\n",
      "639.089927673\n",
      "490\n",
      "740\n",
      "2\n",
      "583.6743927\n",
      "850\n",
      "597.555885315\n",
      "610\n",
      "640\n",
      "2\n",
      "581.258850098\n",
      "544.509239197\n",
      "568.012542725\n",
      "710\n",
      "2\n",
      "680\n",
      "591.924514771\n",
      "480\n",
      "2\n",
      "637.281761169\n",
      "600\n",
      "730\n",
      "616.398696899\n",
      "2\n",
      "800\n",
      "577.696685791\n",
      "730\n",
      "720\n",
      "2\n",
      "660\n",
      "565.201797485\n",
      "480\n",
      "2\n",
      "599.416046143\n",
      "629.969673157\n",
      "2\n",
      "830\n",
      "592.015304565\n",
      "2\n",
      "603.032264709\n",
      "610\n",
      "562.268333435\n",
      "582.35042572\n",
      "710\n",
      "553.705673218\n",
      "586.337127686\n",
      "2\n",
      "670\n",
      "450\n",
      "600\n",
      "700\n",
      "605.500640869\n",
      "578.498153687\n",
      "611.402816772\n",
      "2\n",
      "641.283416748\n",
      "603.363647461\n",
      "2\n",
      "790\n",
      "570.685386658\n",
      "680\n",
      "570.220031738\n",
      "624.468421936\n",
      "556.699066162\n",
      "2\n",
      "602.101783752\n",
      "760\n",
      "2\n",
      "610.550384521\n",
      "577.337875366\n",
      "599.258880615\n",
      "594.323959351\n",
      "2\n",
      "760\n",
      "580\n",
      "568.447189331\n",
      "608.910369873\n",
      "2\n",
      "602.54360199\n",
      "630\n",
      "2\n",
      "597.288208008\n",
      "470\n",
      "2\n",
      "597.234764099\n",
      "600.861778259\n",
      "620.12928009\n",
      "2\n",
      "622.016487122\n",
      "680\n",
      "606.917762756\n",
      "609.243888855\n",
      "569.723892212\n",
      "595.028915405\n",
      "572.799339294\n",
      "2\n",
      "627.076721191\n",
      "600.101470947\n",
      "618.30871582\n",
      "547.982292175\n",
      "670.380249023\n",
      "599.771957397\n",
      "2\n",
      "551.527252197\n",
      "537.455253601\n",
      "594.888725281\n",
      "562.790145874\n",
      "579.918899536\n",
      "2\n",
      "470\n",
      "2\n",
      "637.281761169\n",
      "646.386260986\n",
      "2\n",
      "605.850830078\n",
      "614.38331604\n",
      "660\n",
      "582.492103577\n",
      "539.018287659\n",
      "602.410850525\n",
      "520\n",
      "632.27180481\n",
      "583.958625793\n",
      "623.293914795\n",
      "657.829818726\n",
      "2\n",
      "621.073760986\n",
      "555.822792053\n",
      "584.266395569\n",
      "700.03288269\n",
      "2\n",
      "576.479110718\n",
      "610.624542236\n",
      "620.879554749\n",
      "750\n",
      "2\n",
      "890\n",
      "450\n",
      "521.262779236\n",
      "596.666793823\n",
      "2\n",
      "594.416770935\n",
      "657.88734436\n",
      "2\n",
      "621.073760986\n",
      "535.856704712\n",
      "565.189590454\n",
      "583.909835815\n",
      "667.776947021\n",
      "2\n",
      "626.758270264\n",
      "633.549079895\n",
      "2\n",
      "516.21181488\n",
      "2\n",
      "582.352180481\n",
      "639.204978943\n",
      "2\n",
      "603.032264709\n",
      "561.577339172\n",
      "564.513587952\n",
      "599.591407776\n",
      "649.162979126\n",
      "2\n",
      "629.408226013\n",
      "530.163803101\n",
      "589.948883057\n",
      "603.767089844\n",
      "654.162979126\n",
      "2\n",
      "630.760002136\n",
      "593.68976593\n",
      "650.473937988\n",
      "2\n",
      "603.722839355\n",
      "750\n",
      "610.606803894\n",
      "570.898628235\n",
      "586.644172668\n",
      "609.015312195\n",
      "2\n",
      "614.775276184\n",
      "657.938690186\n",
      "2\n",
      "600.17742157\n",
      "590.091323853\n",
      "2\n",
      "610.868835449\n",
      "1\n",
      "Epoch 1/1\n",
      "3456/3456 [==============================] - 11s 3ms/step - loss: 204.5290\n",
      "450\n",
      "2\n",
      "710\n",
      "740\n",
      "2\n",
      "640\n",
      "770\n",
      "615.038909912\n",
      "2\n",
      "780\n",
      "860\n",
      "2\n",
      "650\n",
      "450\n",
      "420\n",
      "760\n",
      "660\n",
      "700.807800293\n",
      "570\n",
      "2\n",
      "860\n",
      "750\n",
      "840\n",
      "2\n",
      "611.952095032\n",
      "570\n",
      "870\n",
      "2\n",
      "540\n",
      "610\n",
      "2\n",
      "600\n",
      "550\n",
      "2\n",
      "500\n",
      "2\n",
      "860\n",
      "660\n",
      "601.974372864\n",
      "500\n",
      "2\n",
      "440\n",
      "2\n",
      "676.649856567\n"
     ]
    }
   ],
   "source": [
    "img = get_img()\n",
    "while(True):\n",
    "    mistrust = mistrust*0.99\n",
    "    press_time = network(model,img,1-mistrust)[0][0]\n",
    "    jump(press_time*10)\n",
    "    time.sleep(2.3+press_time/200)\n",
    "    img_new = get_img()\n",
    "    if fail(img_new):\n",
    "        jump(2)\n",
    "        time.sleep(0.8)\n",
    "        img_new = get_img()\n",
    "    elif success(img_new,img):\n",
    "        if n_sample == 0:\n",
    "            train_x = img\n",
    "            train_y = press_time.reshape(1,1)\n",
    "        else:\n",
    "            train_x = np.concatenate((train_x,img),axis=0)\n",
    "            train_y = np.concatenate((train_y,press_time.reshape(1,1)),axis=0)\n",
    "        n_sample+=1\n",
    "        if n_sample%128==0:\n",
    "            mistrust = 1\n",
    "            print(mistrust)\n",
    "            model.fit(train_x,train_y)\n",
    "            np.save('train_x',train_x)\n",
    "            np.save('train_y',train_y)\n",
    "    img = img_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-c26724e924ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    train(model,img,70)\n",
    "    print(network(model,img,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model-50.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network(model,img,1-mistrust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jump(math.ceil(400.1123))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.save('train_x',train_x)\n",
    "np.save('train_y',train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 181, 101, 8)       80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 45, 25, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 43, 23, 8)         584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 10, 5, 8)          0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 10, 5, 8)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 128)               51328     \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 52,121\n",
      "Trainable params: 52,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6656 samples, validate on 1664 samples\n",
      "Epoch 1/1\n",
      "6656/6656 [==============================] - 2s 288us/step - loss: 4159.0802 - val_loss: 4348.3201\n",
      "Train on 6656 samples, validate on 1664 samples\n",
      "Epoch 1/1\n",
      "6656/6656 [==============================] - 2s 251us/step - loss: 4140.9028 - val_loss: 4348.3201\n",
      "Train on 6656 samples, validate on 1664 samples\n",
      "Epoch 1/1\n",
      "6656/6656 [==============================] - 2s 247us/step - loss: 4140.9028 - val_loss: 4348.3201\n",
      "Train on 6656 samples, validate on 1664 samples\n",
      "Epoch 1/1\n",
      "6656/6656 [==============================] - 2s 255us/step - loss: 4140.9028 - val_loss: 4348.3201\n",
      "Train on 6656 samples, validate on 1664 samples\n",
      "Epoch 1/1\n",
      "1312/6656 [====>.........................] - ETA: 1s - loss: 4145.0962"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-46b7eddc1a36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    model.fit(train_x,train_y,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6656 samples, validate on 1664 samples\n",
      "Epoch 1/300\n",
      "6656/6656 [==============================] - 2s 317us/step - loss: 477.4919 - val_loss: 162.4638\n",
      "Epoch 2/300\n",
      "6656/6656 [==============================] - 2s 252us/step - loss: 181.9958 - val_loss: 249.9112\n",
      "Epoch 3/300\n",
      "6656/6656 [==============================] - 2s 261us/step - loss: 159.8648 - val_loss: 239.4574\n",
      "Epoch 4/300\n",
      "6656/6656 [==============================] - 2s 257us/step - loss: 154.5732 - val_loss: 127.9332\n",
      "Epoch 5/300\n",
      "6656/6656 [==============================] - 2s 255us/step - loss: 144.1473 - val_loss: 79.8146\n",
      "Epoch 6/300\n",
      "6656/6656 [==============================] - 2s 284us/step - loss: 148.4117 - val_loss: 115.3470\n",
      "Epoch 7/300\n",
      "6656/6656 [==============================] - 2s 308us/step - loss: 135.7729 - val_loss: 114.9308\n",
      "Epoch 8/300\n",
      "6656/6656 [==============================] - 2s 280us/step - loss: 147.0888 - val_loss: 98.0207\n",
      "Epoch 9/300\n",
      "6656/6656 [==============================] - 2s 265us/step - loss: 128.7862 - val_loss: 105.9872\n",
      "Epoch 10/300\n",
      "6656/6656 [==============================] - 2s 305us/step - loss: 135.1842 - val_loss: 149.0867\n",
      "Epoch 11/300\n",
      "6656/6656 [==============================] - 2s 305us/step - loss: 131.5680 - val_loss: 82.3193\n",
      "Epoch 12/300\n",
      "6656/6656 [==============================] - 2s 273us/step - loss: 127.8143 - val_loss: 62.6480\n",
      "Epoch 13/300\n",
      "6656/6656 [==============================] - 2s 307us/step - loss: 129.0611 - val_loss: 77.3378\n",
      "Epoch 14/300\n",
      "6656/6656 [==============================] - 2s 268us/step - loss: 130.3275 - val_loss: 85.9920\n",
      "Epoch 15/300\n",
      "6656/6656 [==============================] - 2s 260us/step - loss: 122.9507 - val_loss: 75.4097\n",
      "Epoch 16/300\n",
      "6656/6656 [==============================] - 2s 277us/step - loss: 127.7169 - val_loss: 73.2948\n",
      "Epoch 17/300\n",
      "6656/6656 [==============================] - 2s 291us/step - loss: 117.8603 - val_loss: 65.3104\n",
      "Epoch 18/300\n",
      "6656/6656 [==============================] - 2s 321us/step - loss: 117.9210 - val_loss: 72.8534\n",
      "Epoch 19/300\n",
      "6656/6656 [==============================] - 2s 301us/step - loss: 120.8359 - val_loss: 107.8506\n",
      "Epoch 20/300\n",
      "6656/6656 [==============================] - 2s 316us/step - loss: 112.7366 - val_loss: 71.4165\n",
      "Epoch 21/300\n",
      "6656/6656 [==============================] - 2s 316us/step - loss: 121.4938 - val_loss: 68.1001\n",
      "Epoch 22/300\n",
      "6656/6656 [==============================] - 2s 311us/step - loss: 115.1709 - val_loss: 109.5807\n",
      "Epoch 23/300\n",
      "6656/6656 [==============================] - 2s 263us/step - loss: 116.4066 - val_loss: 70.2267\n",
      "Epoch 24/300\n",
      "6656/6656 [==============================] - 2s 296us/step - loss: 115.7600 - val_loss: 57.8145\n",
      "Epoch 25/300\n",
      "6656/6656 [==============================] - 2s 250us/step - loss: 113.2820 - val_loss: 62.7434\n",
      "Epoch 26/300\n",
      "6656/6656 [==============================] - 2s 252us/step - loss: 111.4823 - val_loss: 58.1070\n",
      "Epoch 27/300\n",
      "6656/6656 [==============================] - 2s 266us/step - loss: 111.6269 - val_loss: 59.0441\n",
      "Epoch 28/300\n",
      "6656/6656 [==============================] - 2s 278us/step - loss: 107.5802 - val_loss: 62.6699\n",
      "Epoch 29/300\n",
      "6656/6656 [==============================] - 2s 309us/step - loss: 110.5567 - val_loss: 79.1980\n",
      "Epoch 30/300\n",
      "6656/6656 [==============================] - 2s 310us/step - loss: 112.6720 - val_loss: 64.6156\n",
      "Epoch 31/300\n",
      "6656/6656 [==============================] - 2s 290us/step - loss: 106.2899 - val_loss: 59.1297\n",
      "Epoch 32/300\n",
      "6656/6656 [==============================] - 2s 249us/step - loss: 110.9391 - val_loss: 60.5848\n",
      "Epoch 33/300\n",
      "6656/6656 [==============================] - 2s 279us/step - loss: 103.5757 - val_loss: 59.2874\n",
      "Epoch 34/300\n",
      "6656/6656 [==============================] - 2s 297us/step - loss: 108.3127 - val_loss: 78.2110\n",
      "Epoch 35/300\n",
      "6656/6656 [==============================] - 2s 255us/step - loss: 103.6321 - val_loss: 56.8569\n",
      "Epoch 36/300\n",
      "6656/6656 [==============================] - 2s 298us/step - loss: 103.9792 - val_loss: 58.0531\n",
      "Epoch 37/300\n",
      "6656/6656 [==============================] - 2s 316us/step - loss: 104.6674 - val_loss: 58.9068\n",
      "Epoch 38/300\n",
      "6656/6656 [==============================] - 2s 322us/step - loss: 103.1738 - val_loss: 59.8792\n",
      "Epoch 39/300\n",
      "6656/6656 [==============================] - 2s 297us/step - loss: 104.5172 - val_loss: 57.6901\n",
      "Epoch 40/300\n",
      "6656/6656 [==============================] - 2s 298us/step - loss: 104.6362 - val_loss: 67.0792\n",
      "Epoch 41/300\n",
      "6656/6656 [==============================] - 2s 251us/step - loss: 105.3212 - val_loss: 60.0779\n",
      "Epoch 42/300\n",
      "6656/6656 [==============================] - 2s 297us/step - loss: 101.1193 - val_loss: 54.5832\n",
      "Epoch 43/300\n",
      "6656/6656 [==============================] - 2s 300us/step - loss: 101.4295 - val_loss: 66.7540\n",
      "Epoch 44/300\n",
      "6656/6656 [==============================] - 2s 287us/step - loss: 99.0394 - val_loss: 59.3463\n",
      "Epoch 45/300\n",
      "6656/6656 [==============================] - 2s 272us/step - loss: 99.1240 - val_loss: 58.2472\n",
      "Epoch 46/300\n",
      "6656/6656 [==============================] - 2s 314us/step - loss: 103.4118 - val_loss: 65.0277\n",
      "Epoch 47/300\n",
      "6656/6656 [==============================] - 2s 323us/step - loss: 101.8818 - val_loss: 76.0500\n",
      "Epoch 48/300\n",
      "6656/6656 [==============================] - 2s 266us/step - loss: 101.1078 - val_loss: 71.3545\n",
      "Epoch 49/300\n",
      "6656/6656 [==============================] - 2s 240us/step - loss: 98.9528 - val_loss: 70.0066\n",
      "Epoch 50/300\n",
      "6656/6656 [==============================] - 2s 269us/step - loss: 99.6953 - val_loss: 67.5798\n",
      "Epoch 51/300\n",
      "6656/6656 [==============================] - 2s 291us/step - loss: 97.9869 - val_loss: 74.4028\n",
      "Epoch 52/300\n",
      "6656/6656 [==============================] - 2s 279us/step - loss: 96.3445 - val_loss: 70.8138\n",
      "Epoch 53/300\n",
      "6656/6656 [==============================] - 2s 278us/step - loss: 96.4024 - val_loss: 82.9559\n",
      "Epoch 54/300\n",
      "6656/6656 [==============================] - 2s 273us/step - loss: 98.3241 - val_loss: 67.1339\n",
      "Epoch 55/300\n",
      "6656/6656 [==============================] - 2s 275us/step - loss: 97.0078 - val_loss: 93.7106\n",
      "Epoch 56/300\n",
      "6656/6656 [==============================] - 2s 290us/step - loss: 95.5647 - val_loss: 73.4328\n",
      "Epoch 57/300\n",
      "6656/6656 [==============================] - 2s 305us/step - loss: 97.8577 - val_loss: 79.9080\n",
      "Epoch 58/300\n",
      "6656/6656 [==============================] - 2s 242us/step - loss: 95.3622 - val_loss: 74.2006\n",
      "Epoch 59/300\n",
      "6656/6656 [==============================] - 2s 244us/step - loss: 98.5241 - val_loss: 75.4737\n",
      "Epoch 60/300\n",
      "6656/6656 [==============================] - 2s 253us/step - loss: 93.1987 - val_loss: 83.2030\n",
      "Epoch 61/300\n",
      "6656/6656 [==============================] - 2s 282us/step - loss: 99.3869 - val_loss: 65.4499\n",
      "Epoch 62/300\n",
      "6656/6656 [==============================] - 2s 274us/step - loss: 97.7750 - val_loss: 67.0691\n",
      "Epoch 63/300\n",
      "6656/6656 [==============================] - 2s 251us/step - loss: 100.2422 - val_loss: 71.2554\n",
      "Epoch 64/300\n",
      "6656/6656 [==============================] - 2s 256us/step - loss: 95.3504 - val_loss: 120.5425\n",
      "Epoch 65/300\n",
      "6656/6656 [==============================] - 2s 299us/step - loss: 94.2133 - val_loss: 70.1345\n",
      "Epoch 66/300\n",
      "6656/6656 [==============================] - 2s 271us/step - loss: 93.9562 - val_loss: 68.2428\n",
      "Epoch 67/300\n",
      "6656/6656 [==============================] - 2s 243us/step - loss: 96.4906 - val_loss: 76.4365\n",
      "Epoch 68/300\n",
      "6656/6656 [==============================] - 2s 254us/step - loss: 97.3363 - val_loss: 108.4108\n",
      "Epoch 69/300\n",
      "6656/6656 [==============================] - 2s 261us/step - loss: 99.9419 - val_loss: 70.7673\n",
      "Epoch 70/300\n",
      "6656/6656 [==============================] - 2s 246us/step - loss: 95.1856 - val_loss: 84.7634\n",
      "Epoch 71/300\n",
      "6656/6656 [==============================] - 2s 255us/step - loss: 97.1744 - val_loss: 77.9576\n",
      "Epoch 72/300\n",
      "6656/6656 [==============================] - 2s 250us/step - loss: 91.3267 - val_loss: 65.9477\n",
      "Epoch 73/300\n",
      "6656/6656 [==============================] - 2s 253us/step - loss: 96.9145 - val_loss: 72.4868\n",
      "Epoch 74/300\n",
      "6656/6656 [==============================] - 2s 259us/step - loss: 93.7453 - val_loss: 85.4176\n",
      "Epoch 75/300\n",
      "6656/6656 [==============================] - 2s 253us/step - loss: 98.0464 - val_loss: 75.7980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/300\n",
      "6656/6656 [==============================] - 2s 290us/step - loss: 96.0218 - val_loss: 88.4746\n",
      "Epoch 77/300\n",
      "6656/6656 [==============================] - 2s 306us/step - loss: 97.2360 - val_loss: 86.8281\n",
      "Epoch 78/300\n",
      "6656/6656 [==============================] - 2s 258us/step - loss: 90.7953 - val_loss: 81.7492\n",
      "Epoch 79/300\n",
      "6656/6656 [==============================] - 2s 274us/step - loss: 89.5471 - val_loss: 84.4658\n",
      "Epoch 80/300\n",
      "6656/6656 [==============================] - 2s 247us/step - loss: 93.4343 - val_loss: 85.6195\n",
      "Epoch 81/300\n",
      "6656/6656 [==============================] - 2s 250us/step - loss: 91.9656 - val_loss: 77.3469\n",
      "Epoch 82/300\n",
      "6656/6656 [==============================] - 2s 316us/step - loss: 96.2306 - val_loss: 81.5419\n",
      "Epoch 83/300\n",
      "6656/6656 [==============================] - 2s 296us/step - loss: 94.0766 - val_loss: 91.3626\n",
      "Epoch 84/300\n",
      "6656/6656 [==============================] - 2s 304us/step - loss: 94.4767 - val_loss: 104.6445\n",
      "Epoch 85/300\n",
      "6656/6656 [==============================] - 2s 305us/step - loss: 95.8289 - val_loss: 88.7488\n",
      "Epoch 86/300\n",
      "6656/6656 [==============================] - 2s 305us/step - loss: 91.2165 - val_loss: 91.7638\n",
      "Epoch 87/300\n",
      "6656/6656 [==============================] - 2s 293us/step - loss: 90.1132 - val_loss: 97.0108\n",
      "Epoch 88/300\n",
      "6656/6656 [==============================] - 2s 289us/step - loss: 95.8660 - val_loss: 102.4086\n",
      "Epoch 89/300\n",
      "6656/6656 [==============================] - 2s 255us/step - loss: 90.0723 - val_loss: 83.2871\n",
      "Epoch 90/300\n",
      "6656/6656 [==============================] - 2s 286us/step - loss: 93.8007 - val_loss: 94.5469\n",
      "Epoch 91/300\n",
      "6656/6656 [==============================] - 2s 254us/step - loss: 90.2001 - val_loss: 103.0772\n",
      "Epoch 92/300\n",
      "6656/6656 [==============================] - 2s 263us/step - loss: 87.5846 - val_loss: 89.0998\n",
      "Epoch 93/300\n",
      "6656/6656 [==============================] - 2s 242us/step - loss: 89.7215 - val_loss: 88.7034\n",
      "Epoch 94/300\n",
      "6656/6656 [==============================] - 2s 309us/step - loss: 92.0871 - val_loss: 89.8402\n",
      "Epoch 95/300\n",
      "6656/6656 [==============================] - 2s 252us/step - loss: 90.2058 - val_loss: 85.1924\n",
      "Epoch 96/300\n",
      "6656/6656 [==============================] - 2s 263us/step - loss: 92.6038 - val_loss: 81.4751\n",
      "Epoch 97/300\n",
      "6656/6656 [==============================] - 2s 248us/step - loss: 91.7619 - val_loss: 87.6579\n",
      "Epoch 98/300\n",
      "6656/6656 [==============================] - 2s 273us/step - loss: 92.1866 - val_loss: 83.1647\n",
      "Epoch 99/300\n",
      "6656/6656 [==============================] - 2s 252us/step - loss: 92.1438 - val_loss: 93.2471\n",
      "Epoch 100/300\n",
      "6656/6656 [==============================] - 2s 236us/step - loss: 91.0504 - val_loss: 93.7590\n",
      "Epoch 101/300\n",
      "6656/6656 [==============================] - 2s 281us/step - loss: 90.3072 - val_loss: 83.0353\n",
      "Epoch 102/300\n",
      "6656/6656 [==============================] - 2s 281us/step - loss: 89.6241 - val_loss: 76.7880\n",
      "Epoch 103/300\n",
      "6656/6656 [==============================] - 2s 313us/step - loss: 91.3856 - val_loss: 94.8113\n",
      "Epoch 104/300\n",
      "6656/6656 [==============================] - 2s 247us/step - loss: 93.0225 - val_loss: 97.2171\n",
      "Epoch 105/300\n",
      "6656/6656 [==============================] - 2s 251us/step - loss: 88.7344 - val_loss: 89.9500\n",
      "Epoch 106/300\n",
      "6656/6656 [==============================] - 2s 303us/step - loss: 89.5242 - val_loss: 83.5814\n",
      "Epoch 107/300\n",
      "6656/6656 [==============================] - 2s 259us/step - loss: 88.6232 - val_loss: 89.4308\n",
      "Epoch 108/300\n",
      "6656/6656 [==============================] - 2s 266us/step - loss: 89.9239 - val_loss: 90.1634\n",
      "Epoch 109/300\n",
      "6656/6656 [==============================] - 2s 257us/step - loss: 88.2777 - val_loss: 102.6374\n",
      "Epoch 110/300\n",
      "6656/6656 [==============================] - 2s 286us/step - loss: 86.9751 - val_loss: 112.8879\n",
      "Epoch 111/300\n",
      "6656/6656 [==============================] - 2s 255us/step - loss: 89.9488 - val_loss: 76.2812\n",
      "Epoch 112/300\n",
      "6656/6656 [==============================] - 2s 261us/step - loss: 87.9948 - val_loss: 84.5725\n",
      "Epoch 113/300\n",
      "6656/6656 [==============================] - 2s 258us/step - loss: 87.1488 - val_loss: 97.0378\n",
      "Epoch 114/300\n",
      "6656/6656 [==============================] - 2s 255us/step - loss: 85.4179 - val_loss: 83.1067\n",
      "Epoch 115/300\n",
      "6656/6656 [==============================] - 2s 257us/step - loss: 88.3478 - val_loss: 76.5691\n",
      "Epoch 116/300\n",
      "6656/6656 [==============================] - 2s 256us/step - loss: 93.2660 - val_loss: 70.8618\n",
      "Epoch 117/300\n",
      "4256/6656 [==================>...........] - ETA: 0s - loss: 87.9712"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-271c2bf78261>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# list all data in history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# summarize history for accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x,train_y,validation_split=0.2, epochs=300)\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "637.200775146\n",
      "584.45274353\n",
      "542.729568481\n",
      "608.442687988\n",
      "657.418518066\n",
      "690.343322754\n",
      "642.444610596\n",
      "777.827987671\n",
      "791.10206604\n",
      "2\n",
      "637.526779175\n",
      "788.696746826\n",
      "581.410522461\n",
      "551.08997345\n",
      "549.746704102\n",
      "564.398460388\n",
      "527.251052856\n",
      "545.491943359\n",
      "679.278488159\n",
      "544.193878174\n",
      "563.535385132\n",
      "543.699951172\n",
      "585.170326233\n",
      "535.103492737\n",
      "595.685653687\n",
      "583.087387085\n",
      "526.059188843\n",
      "616.95941925\n",
      "542.667045593\n",
      "616.61857605\n",
      "653.272323608\n",
      "2\n",
      "631.245422363\n",
      "579.812850952\n",
      "726.839599609\n",
      "670.903625488\n",
      "778.406524658\n",
      "2\n",
      "632.856025696\n",
      "494.706954956\n",
      "544.017715454\n",
      "783.596572876\n",
      "2\n",
      "637.526779175\n",
      "764.346389771\n",
      "529.663391113\n",
      "823.953857422\n",
      "827.167053223\n",
      "600.854263306\n",
      "2\n",
      "631.245422363\n",
      "754.198074341\n",
      "581.823501587\n",
      "581.823501587\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-fbd55f77ab7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-710457f7480c>\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mpress_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mjump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpress_time\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.3\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpress_time\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mimg_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "model.add(Conv2D(8, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(8, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "model.add(Conv2D(8, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=keras.optimizers.Adam())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
