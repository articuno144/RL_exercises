{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import random as rd\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = None\n",
    "train_y = None\n",
    "n_sample = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "swipe_x1, swipe_y1, swipe_x2, swipe_y2 = 320, 1000, 320, 1000\n",
    "mistrust = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img():\n",
    "    os.system('adb shell screencap -p /sdcard/1.png')\n",
    "    os.system('adb pull /sdcard/1.png .')\n",
    "    img = cv2.imread('1.png')\n",
    "    img = img[::7,::7,1].reshape(1,183,103,1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKkAAAD8CAYAAAAMloRrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4f6a4bc5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(183, 103, 1)\n",
      "(183, 103)\n"
     ]
    }
   ],
   "source": [
    "img = get_img()\n",
    "im = plt.imshow(img.reshape(183,103))\n",
    "plt.show()\n",
    "input_shape = img.shape[1:]\n",
    "img_dim = img.shape[1:3]\n",
    "print(input_shape)\n",
    "print(img_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[247],\n",
       "         [247],\n",
       "         [247],\n",
       "         ..., \n",
       "         [247],\n",
       "         [247],\n",
       "         [247]],\n",
       "\n",
       "        [[247],\n",
       "         [247],\n",
       "         [247],\n",
       "         ..., \n",
       "         [247],\n",
       "         [247],\n",
       "         [247]],\n",
       "\n",
       "        [[247],\n",
       "         [247],\n",
       "         [247],\n",
       "         ..., \n",
       "         [247],\n",
       "         [247],\n",
       "         [247]],\n",
       "\n",
       "        ..., \n",
       "        [[245],\n",
       "         [245],\n",
       "         [245],\n",
       "         ..., \n",
       "         [245],\n",
       "         [245],\n",
       "         [245]],\n",
       "\n",
       "        [[245],\n",
       "         [245],\n",
       "         [245],\n",
       "         ..., \n",
       "         [245],\n",
       "         [245],\n",
       "         [245]],\n",
       "\n",
       "        [[245],\n",
       "         [245],\n",
       "         [245],\n",
       "         ..., \n",
       "         [245],\n",
       "         [245],\n",
       "         [245]]]], dtype=uint8)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.amax(img[:50,:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jump(press_time):\n",
    "    cmd = 'adb shell input swipe {} {} {} {} {}'.format(swipe_x1, swipe_y1, swipe_x2, swipe_y2, math.ceil(max(press_time,200)))\n",
    "    os.system(cmd)\n",
    "    print(press_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def success(img_new,img):\n",
    "    if np.amax(np.absolute(img_new.reshape(img_dim)[:25,:25]-img.reshape(img_dim)[:25,:25]))>50:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fail(img_new):\n",
    "    if np.amax(img_new.reshape(img_dim)[:25,:25])>50:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=keras.optimizers.Adadelta())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network(model,img,confidence):\n",
    "    if rd.uniform(0,1)<confidence:\n",
    "        return model.predict(img)\n",
    "    else:\n",
    "        return np.array(rd.randint(40,90)).reshape(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(rd.randint(20,120)).reshape(1,1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mistrust = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,img,press_time):\n",
    "    model.fit(img,np.array([press_time]).reshape(1,1),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    img = get_img()\n",
    "    while(True):\n",
    "        press_time = network(model,img,1)[0][0]\n",
    "        jump(press_time*10)\n",
    "        time.sleep(2.3+press_time/200)\n",
    "        img_new = get_img()\n",
    "        if fail(img_new):\n",
    "            jump(2)\n",
    "            time.sleep(0.8)\n",
    "            img_new = get_img()\n",
    "        img = img_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "543.932914734\n",
      "572.351722717\n",
      "570\n",
      "660\n",
      "2\n",
      "618.149032593\n",
      "762.693862915\n",
      "670\n",
      "2\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-7a0fa3abb459>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mjump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mimg_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_new\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_sample\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-094e8e494515>\u001b[0m in \u001b[0;36mget_img\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'adb pull /sdcard/1.png .'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m183\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m103\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "img = get_img()\n",
    "while(True):\n",
    "    mistrust = mistrust*0.99\n",
    "    press_time = network(model,img,1-mistrust)[0][0]\n",
    "    jump(press_time*10)\n",
    "    time.sleep(2.3+press_time/200)\n",
    "    img_new = get_img()\n",
    "    if fail(img_new):\n",
    "        jump(2)\n",
    "        time.sleep(0.8)\n",
    "        img_new = get_img()\n",
    "    elif success(img_new,img):\n",
    "        if n_sample == 0:\n",
    "            train_x = img\n",
    "            train_y = press_time.reshape(1,1)\n",
    "        else:\n",
    "            train_x = np.concatenate((train_x,img),axis=0)\n",
    "            train_y = np.concatenate((train_y,press_time.reshape(1,1)),axis=0)\n",
    "        n_sample+=1\n",
    "        if n_sample%128==0:\n",
    "            mistrust = rd.uniform(0,1)\n",
    "            print(mistrust)\n",
    "            model.fit(train_x,train_y)\n",
    "            np.save('train_x',train_x)\n",
    "            np.save('train_y',train_y)\n",
    "    img = img_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 4900.0000\n",
      "[[ 0.]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4900.0000\n",
      "[[ 0.]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4900.0000\n",
      "[[ 0.]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4652.7266\n",
      "[[ 0.]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4900.0000\n",
      "[[ 42.95502472]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4900.0000\n",
      "[[ 84.20837402]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1703.4292\n",
      "[[ 82.27296448]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6936.6968\n",
      "[[ 44.29628754]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4900.0000\n",
      "[[ 16.30095673]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 99.2701\n",
      "[[ 4.54102993]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 838.1266\n",
      "[[ 5.14898443]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1079.7200\n",
      "[[ 13.3798027]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4900.0000\n",
      "[[ 20.93753052]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3511.4016\n",
      "[[ 7.56851816]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4900.0000\n",
      "[[ 0.]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4900.0000\n",
      "[[ 0.]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1345.4932\n",
      "[[ 0.]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4125.6011\n",
      "[[ 15.8893404]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4900.0000\n",
      "[[ 35.05157471]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4621.3159\n",
      "[[ 58.56404114]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 16041.0674\n",
      "[[ 50.66128159]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4900.0000\n",
      "[[ 42.83993149]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5851.6338\n",
      "[[ 25.61764717]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1535.9296\n",
      "[[ 15.85347652]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4900.0000\n",
      "[[ 11.06505871]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 260.8739\n",
      "[[ 6.2120657]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2132.9187\n",
      "[[ 7.33571053]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.3094\n",
      "[[ 8.5145483]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3217.7297\n",
      "[[ 13.88646507]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2127.0476\n",
      "[[ 24.15745735]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2215.7920\n",
      "[[ 38.24620438]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 192.1590\n",
      "[[ 52.43790436]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2077\n",
      "[[ 65.12081146]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4900.0000\n",
      "[[ 76.59806061]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2676.8240\n",
      "[[ 92.02714539]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2534.6768\n",
      "[[ 105.29213715]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3989.7507\n",
      "[[ 106.84816742]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2032.4418\n",
      "[[ 102.63564301]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 232.2092\n",
      "[[ 97.54743958]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3126.7437\n",
      "[[ 97.45398712]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3066.0933\n",
      "[[ 93.10830688]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1137.1208\n",
      "[[ 85.85034943]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 30.7166\n",
      "[[ 79.94848633]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 677.6822\n",
      "[[ 77.34300995]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1141.2888\n",
      "[[ 72.69146729]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 149.7647\n",
      "[[ 68.69245148]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 237.2990\n",
      "[[ 64.07105255]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 157.8891\n",
      "[[ 59.1905098]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 38.9810\n",
      "[[ 55.00991058]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3877.1340\n",
      "[[ 54.74059677]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1686.8853\n",
      "[[ 50.98710632]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 363.4279\n",
      "[[ 48.77288437]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1163.7729\n",
      "[[ 47.60856247]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4900.0000\n",
      "[[ 46.80561829]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4252.0684\n",
      "[[ 48.52834702]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2197.7349\n",
      "[[ 51.2317543]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 313.3471\n",
      "[[ 54.53881454]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 110.2774\n",
      "[[ 56.94248581]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 510.1525\n",
      "[[ 57.84011841]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1155.1223\n",
      "[[ 57.12070847]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2010.2493\n",
      "[[ 58.27681351]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 668.9681\n",
      "[[ 59.7216568]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 313.3771\n",
      "[[ 61.59409332]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1360.4851\n",
      "[[ 64.25382996]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 678.6895\n",
      "[[ 66.36912537]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 31.1486\n",
      "[[ 68.4789505]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 252.7251\n",
      "[[ 70.95217133]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 701.2623\n",
      "[[ 73.67248535]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 657.5814\n",
      "[[ 76.94139862]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5120\n",
      "[[ 80.01229095]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 318.3501\n",
      "[[ 81.88898468]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5117\n",
      "[[ 83.6738739]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.2426\n",
      "[[ 85.42822266]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 171.9669\n",
      "[[ 86.21317291]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1405.7156\n",
      "[[ 83.81210327]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2202\n",
      "[[ 81.5117569]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 106.8709\n",
      "[[ 78.87270355]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 188.1555\n",
      "[[ 76.87821198]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1889.4977\n",
      "[[ 72.0749054]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.1671\n",
      "[[ 68.00714874]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8213\n",
      "[[ 64.28939056]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6057\n",
      "[[ 61.07383728]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1083.7795\n",
      "[[ 59.07510757]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 325.4405\n",
      "[[ 57.76247787]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.8545\n",
      "[[ 56.49136734]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 182.9261\n",
      "[[ 55.97696686]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 33.2697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 55.77524185]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 122.2159\n",
      "[[ 55.91777802]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.0043\n",
      "[[ 56.2035675]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.2877\n",
      "[[ 56.57242966]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6736\n",
      "[[ 56.84421921]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 227.1259\n",
      "[[ 57.68836594]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 178.9497\n",
      "[[ 58.81879425]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 210.2518\n",
      "[[ 59.05179977]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 428.9409\n",
      "[[ 60.0333786]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8557\n",
      "[[ 60.954216]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 180.9769\n",
      "[[ 60.90051651]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 158.2719\n",
      "[[ 61.4486084]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 40.7369\n",
      "[[ 62.34273529]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1921.0168\n",
      "[[ 64.56604767]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 29.3904\n",
      "[[ 66.27142334]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 140.0818\n",
      "[[ 68.30960083]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 258.5291\n",
      "[[ 70.88772583]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1108.7484\n",
      "[[ 70.67726135]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1971.7179\n",
      "[[ 71.38214111]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 521.7226\n",
      "[[ 70.70993805]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 237.9791\n",
      "[[ 70.59906006]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 56.9590\n",
      "[[ 71.28443909]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.3654e-04\n",
      "[[ 72.21329498]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 319.0595\n",
      "[[ 71.63665771]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1053.7395\n",
      "[[ 71.96546936]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2259\n",
      "[[ 72.23253632]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5335\n",
      "[[ 72.42125702]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 350.4130\n",
      "[[ 73.73677826]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1409.0601\n",
      "[[ 75.59506226]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 17.8163\n",
      "[[ 77.41546631]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1784.8994\n",
      "[[ 75.32320404]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 145.0137\n",
      "[[ 74.09901428]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 66.3550\n",
      "[[ 72.10505676]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1192.1680\n",
      "[[ 67.46261597]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.5473\n",
      "[[ 63.96299744]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 193.8850\n",
      "[[ 61.82167053]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 159.7885\n",
      "[[ 59.01936722]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 79.2603\n",
      "[[ 56.05323029]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 653.2061\n",
      "[[ 54.23419189]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 698.0560\n",
      "[[ 54.00938416]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 227.2176\n",
      "[[ 52.9790802]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 771.1913\n",
      "[[ 53.71582413]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 279.7134\n",
      "[[ 54.95370483]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 195.3133\n",
      "[[ 56.63693237]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 14.1007\n",
      "[[ 58.33787155]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 401.9589\n",
      "[[ 61.3044281]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.2280\n",
      "[[ 63.79722977]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 190.4430\n",
      "[[ 66.60528564]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 27.9923\n",
      "[[ 68.92456818]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7965\n",
      "[[ 71.11360931]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1334\n",
      "[[ 73.13063049]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 325.4339\n",
      "[[ 73.65113831]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 326.1068\n",
      "[[ 75.14054108]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1313.3223\n",
      "[[ 78.1423111]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 63.6542\n",
      "[[ 81.34423065]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 389.0984\n",
      "[[ 85.31452179]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 21.8760\n",
      "[[ 88.56587219]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 429.5581\n",
      "[[ 89.90740967]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3704.6882\n",
      "[[ 84.16072845]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 498.1991\n",
      "[[ 77.36769867]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 638.4412\n",
      "[[ 68.68775177]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1544.3074\n",
      "[[ 57.81503677]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.5270\n",
      "[[ 48.9782486]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 498.2214\n",
      "[[ 42.70244217]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 286.5013\n",
      "[[ 38.44828796]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 792.7018\n",
      "[[ 36.07590103]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 49.8728\n",
      "[[ 34.32226944]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1197.6385\n",
      "[[ 33.96602631]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4354.5801\n",
      "[[ 34.12037277]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 759.8088\n",
      "[[ 35.31784821]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1164.9320\n",
      "[[ 37.46100616]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 265.5149\n",
      "[[ 40.13228607]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1549.6842\n",
      "[[ 43.38265991]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 875.9795\n",
      "[[ 47.15308762]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 858.7115\n",
      "[[ 51.4686203]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1340\n",
      "[[ 55.35424805]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 398.5031\n",
      "[[ 59.50112152]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 428.9358\n",
      "[[ 64.00604248]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2122.2615\n",
      "[[ 68.9519577]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1051.2277\n",
      "[[ 74.58185577]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1345.7289\n",
      "[[ 80.69063568]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 419.7103\n",
      "[[ 84.8562088]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 154.9749\n",
      "[[ 89.31950378]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1450.4445\n",
      "[[ 90.35043335]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 14.7368\n",
      "[[ 91.43746948]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.4149\n",
      "[[ 92.48361206]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 258.3548\n",
      "[[ 92.59223175]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 539.8727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 91.11585999]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 159.9081\n",
      "[[ 90.36210632]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3697.2656\n",
      "[[ 83.80457306]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 415.1817\n",
      "[[ 76.86546326]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 647.2256\n",
      "[[ 69.30181885]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 155.7297\n",
      "[[ 62.29963303]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 129.1864\n",
      "[[ 56.12612152]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.5100\n",
      "[[ 50.99726105]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1404.9729\n",
      "[[ 47.64123154]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 182.8706\n",
      "[[ 45.19827652]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1219.9688\n",
      "[[ 44.03242493]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 191.3522\n",
      "[[ 43.48141479]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 531.9438\n",
      "[[ 43.52794647]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3877.9368\n",
      "[[ 43.76823807]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1863.4722\n",
      "[[ 44.58525848]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 186.7272\n",
      "[[ 45.85069656]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2966.4038\n",
      "[[ 47.63033295]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 765.6689\n",
      "[[ 50.06510544]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 243.1791\n",
      "[[ 52.78497314]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 85.2845\n",
      "[[ 55.66669846]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 13.8655\n",
      "[[ 58.14268112]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 733.9053\n",
      "[[ 61.62968826]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 14.6021\n",
      "[[ 65.38198853]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.1058\n",
      "[[ 68.93796539]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1124.3954\n",
      "[[ 69.89833832]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.0379\n",
      "[[ 70.85533142]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 582.0436\n",
      "[[ 73.32946014]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.5303\n",
      "[[ 75.70246124]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1048.7997\n",
      "[[ 74.78688812]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 48.4956\n",
      "[[ 74.27349091]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 44.9822\n",
      "[[ 74.29681396]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 176.7721\n",
      "[[ 74.92956543]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1093\n",
      "[[ 75.57935333]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 904.6764\n",
      "[[ 77.29483795]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1606.9956\n",
      "[[ 76.0868454]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1515.9673\n",
      "[[ 71.81603241]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.4053\n",
      "[[ 67.92718506]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 65.0144\n",
      "[[ 65.0291748]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 272.0457\n",
      "[[ 63.28199005]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4969\n",
      "[[ 61.76700211]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3136\n",
      "[[ 60.55418777]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 62.9598\n",
      "[[ 59.93687057]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 273.6009\n",
      "[[ 60.10680771]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 229.1641\n",
      "[[ 59.21235275]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.6241\n",
      "[[ 58.5993042]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 214.0224\n",
      "[[ 58.72043991]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 245.4514\n",
      "[[ 59.77940369]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 183.0786\n",
      "[[ 61.48220062]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 305.1106\n",
      "[[ 61.78432083]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 74.1502\n",
      "[[ 61.53448868]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 698.4844\n",
      "[[ 62.27448273]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1349.4098\n",
      "[[ 63.76126099]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 308.3951\n",
      "[[ 65.89208221]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5314\n",
      "[[ 67.90475464]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.7779\n",
      "[[ 69.64606476]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 43.2560\n",
      "[[ 71.59057617]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 140.5412\n",
      "[[ 74.11367035]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 580.5323\n",
      "[[ 74.3224411]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 84.3251\n",
      "[[ 73.85694122]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 177.6984\n",
      "[[ 74.228508]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 217.8121\n",
      "[[ 75.28551483]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 199.8818\n",
      "[[ 75.08573151]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 633.3552\n",
      "[[ 72.85231781]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 239.2896\n",
      "[[ 71.43143463]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 256.2105\n",
      "[[ 69.12100983]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 16.7720\n",
      "[[ 66.85731506]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 129.9140\n",
      "[[ 65.40556335]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 39.0773\n",
      "[[ 63.70561218]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 100.5276\n",
      "[[ 61.4650116]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 358.7863\n",
      "[[ 60.69754791]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 167.4975\n",
      "[[ 60.65466309]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 410.8189\n",
      "[[ 61.73207474]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 418.8470\n",
      "[[ 63.77509689]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 295.1469\n",
      "[[ 66.29417419]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0073\n",
      "[[ 68.62219238]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 95.0967\n",
      "[[ 71.33520508]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 42.7181\n",
      "[[ 74.27019501]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 37.2976\n",
      "[[ 76.51830292]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 646.9800\n",
      "[[ 79.93477631]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1353.3571\n",
      "[[ 79.68460083]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 246.6763\n",
      "[[ 78.48904419]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 522.3052\n",
      "[[ 75.19285583]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2431.9099\n",
      "[[ 67.03145599]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.7980\n",
      "[[ 59.97730255]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 394.3568\n",
      "[[ 54.80789185]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 153.3100\n",
      "[[ 50.9360199]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 828.8119\n",
      "[[ 48.74563217]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 72.3730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 46.54044724]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 331.9078\n",
      "[[ 45.42181015]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 759.0979\n",
      "[[ 45.49934387]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1778.8126\n",
      "[[ 46.46931839]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 143.4612\n",
      "[[ 47.8792305]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 84.0903\n",
      "[[ 49.50481796]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 29.4733\n",
      "[[ 51.24308014]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 222.0245\n",
      "[[ 53.37713623]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1699.6838\n",
      "[[ 56.5069313]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 725.4031\n",
      "[[ 60.55806732]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 40.2678\n",
      "[[ 63.86751938]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1020.1586\n",
      "[[ 68.17902374]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 959.4770\n",
      "[[ 73.39555359]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 313.8917\n",
      "[[ 77.01130676]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2385.3213\n",
      "[[ 75.5375824]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 56.4574\n",
      "[[ 74.66613007]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 394.4908\n",
      "[[ 74.78701782]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 127.6382\n",
      "[[ 74.08640289]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 44.7466\n",
      "[[ 73.84081268]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 72.9948\n",
      "[[ 74.03618622]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 165.2348\n",
      "[[ 73.18544769]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 77.5413\n",
      "[[ 72.98513031]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 636.0450\n",
      "[[ 73.89060974]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 34.9540\n",
      "[[ 75.04878235]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0805\n",
      "[[ 76.08803558]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 335.7559\n",
      "[[ 81.36991119]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1052.9072\n",
      "[[ 85.24173737]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 569.9348\n",
      "[[ 86.42173004]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1201\n",
      "[[ 87.05477142]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 44.2680\n",
      "[[ 89.37702179]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1448.8997\n",
      "[[ 82.94165039]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 189.4230\n",
      "[[ 79.41927338]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9073\n",
      "[[ 76.37586212]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5398\n",
      "[[ 73.43674469]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 82.8111\n",
      "[[ 72.03513336]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 712.9229\n",
      "[[ 72.01641083]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 90.9022\n",
      "[[ 70.61099243]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 43.8358\n",
      "[[ 69.79816437]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 598.8226\n",
      "[[ 70.08559418]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 198.0799\n",
      "[[ 72.09406281]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 15.4576\n",
      "[[ 73.34375763]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 260.6146\n",
      "[[ 71.68188477]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 26.0756\n",
      "[[ 69.450737]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 169.2322\n",
      "[[ 65.47283173]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 876.5604\n",
      "[[ 65.12562561]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1187.2455\n",
      "[[ 59.06658936]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1194.2675\n",
      "[[ 55.3904953]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 65.2461\n",
      "[[ 53.19145966]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.6257\n",
      "[[ 51.59654999]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 250.0571\n",
      "[[ 51.95159912]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1920.4996\n",
      "[[ 54.47335434]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 551.0731\n",
      "[[ 58.75996399]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 59.6258\n",
      "[[ 61.65518951]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.2096\n",
      "[[ 64.15092468]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 30.9130\n",
      "[[ 65.68532562]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 216.3587\n",
      "[[ 68.22289276]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3308.4241\n",
      "[[ 72.06049347]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 562.5179\n",
      "[[ 77.23308563]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 118.3086\n",
      "[[ 80.18928528]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2236.2683\n",
      "[[ 74.6537323]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 686.8904\n",
      "[[ 66.16152191]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 207.4472\n",
      "[[ 60.33713531]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.4601\n",
      "[[ 54.87297821]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4945\n",
      "[[ 50.12066269]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 399.2705\n",
      "[[ 47.37126541]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 462.3125\n",
      "[[ 46.78697205]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 742.2488\n",
      "[[ 48.36998749]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 112.0916\n",
      "[[ 50.72877502]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1373.8276\n",
      "[[ 54.50388718]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 124.5737\n",
      "[[ 58.81926727]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 137.3499\n",
      "[[ 63.9295845]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0115\n",
      "[[ 68.70444489]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1072.2742\n",
      "[[ 74.40254974]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 49.6874\n",
      "[[ 80.43965912]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1316.4304\n",
      "[[ 80.60704041]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 560.9914\n",
      "[[ 77.62540436]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.9186\n",
      "[[ 75.22454834]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9028\n",
      "[[ 73.0386734]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 80.1079\n",
      "[[ 71.91915894]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 50.6360\n",
      "[[ 71.56541443]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 377.3708\n",
      "[[ 68.89814758]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 377.5786\n",
      "[[ 64.37762451]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 18.6893\n",
      "[[ 60.12533188]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 559.7191\n",
      "[[ 58.33673096]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1879\n",
      "[[ 56.79801941]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0532\n",
      "[[ 55.46237946]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1436.9373\n",
      "[[ 55.81635284]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 264.1052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 57.01533127]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 39.2441\n",
      "[[ 58.50535202]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 148.3686\n",
      "[[ 60.91508102]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 163.2032\n",
      "[[ 64.24649048]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1038.2283\n",
      "[[ 68.6686554]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 42.5774\n",
      "[[ 73.16466522]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 135.4187\n",
      "[[ 78.23326111]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 77.3289\n",
      "[[ 81.96627808]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1301.0829\n",
      "[[ 80.36690521]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 345.8680\n",
      "[[ 76.7049942]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 475.3017\n",
      "[[ 70.80455017]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 304.1725\n",
      "[[ 66.88258362]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 53.4212\n",
      "[[ 64.73214722]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 40.4349\n",
      "[[ 62.24994278]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 225.7377\n",
      "[[ 61.40136719]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 49.5623\n",
      "[[ 61.51731873]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 200.6272\n",
      "[[ 59.49927521]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 62.5433\n",
      "[[ 56.71375656]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1001.4293\n",
      "[[ 56.91203308]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 106.1868\n",
      "[[ 58.1383667]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 298.0159\n",
      "[[ 61.01423264]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 207.6465\n",
      "[[ 61.79441071]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0078\n",
      "[[ 62.36297989]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 89.7334\n",
      "[[ 63.61261368]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 97.5833\n",
      "[[ 65.72389221]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 98.1659\n",
      "[[ 68.47242737]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 610.5901\n",
      "[[ 73.31102753]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.1706\n",
      "[[ 78.06767273]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 821.5563\n",
      "[[ 77.77645874]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 20.0075\n",
      "[[ 77.97257233]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 892.5590\n",
      "[[ 79.78462219]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2836.9854\n",
      "[[ 72.29192352]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 60.7548\n",
      "[[ 66.55841827]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 58.2227\n",
      "[[ 62.42820358]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 459.8630\n",
      "[[ 60.12557602]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 197.3477\n",
      "[[ 59.80665588]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 96.0359\n",
      "[[ 58.5240097]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.9317\n",
      "[[ 57.58201599]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 33.9124\n",
      "[[ 56.21300507]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1939\n",
      "[[ 54.94618988]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 17.3760\n",
      "[[ 54.14432526]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 232.0951\n",
      "[[ 54.5643692]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 23.0487\n",
      "[[ 55.35127258]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1044.7659\n",
      "[[ 58.08123016]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 156.4230\n",
      "[[ 61.5315361]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.6591\n",
      "[[ 65.03710938]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.2129\n",
      "[[ 68.73654938]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 39.2556\n",
      "[[ 72.80233765]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0359\n",
      "[[ 76.59281158]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.2670\n",
      "[[ 79.91969299]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 242.3719\n",
      "[[ 80.80976105]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 15.9451\n",
      "[[ 82.09331512]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.5064\n",
      "[[ 83.57209778]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 237.6985\n",
      "[[ 82.63613892]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 162.1254\n",
      "[[ 80.13431549]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 152.5404\n",
      "[[ 76.29886627]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 103.7395\n",
      "[[ 73.79662323]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 472.7708\n",
      "[[ 68.94241333]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 159.9114\n",
      "[[ 63.35162354]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1206.3475\n",
      "[[ 54.36975861]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 39.4953\n",
      "[[ 47.60254669]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 530.3923\n",
      "[[ 43.453125]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 538.1188\n",
      "[[ 41.18039703]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 659.7918\n",
      "[[ 40.58224869]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1473.6614\n",
      "[[ 41.59837341]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1638.8074\n",
      "[[ 43.74388123]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1449.9872\n",
      "[[ 47.10334778]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2430.4573\n",
      "[[ 51.06171036]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1386.4749\n",
      "[[ 55.93606949]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 588.8694\n",
      "[[ 61.76057816]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 30.9623\n",
      "[[ 67.60235596]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.6353\n",
      "[[ 72.91471863]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 237.5341\n",
      "[[ 76.54562378]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 555.4456\n",
      "[[ 77.55724335]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 456.1820\n",
      "[[ 79.78124237]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 47.6995\n",
      "[[ 82.25078583]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 361.6227\n",
      "[[ 82.58509827]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1324.6324\n",
      "[[ 78.71323395]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2818.0762\n",
      "[[ 69.15224457]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1792.2889\n",
      "[[ 61.99780273]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 61.5014\n",
      "[[ 55.57355499]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 199.1927\n",
      "[[ 51.09844208]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 263.5940\n",
      "[[ 48.09981537]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2722.7012\n",
      "[[ 46.48288727]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 693.4884\n",
      "[[ 46.22179031]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 378.3596\n",
      "[[ 46.9802742]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 34.1124\n",
      "[[ 48.00356674]]\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 4.3705\n",
      "[[ 49.07348633]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1268\n",
      "[[ 50.1389122]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 660.5197\n",
      "[[ 52.2554512]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 367.4901\n",
      "[[ 55.29154968]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 35.5471\n",
      "[[ 57.66072464]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.5229\n",
      "[[ 59.92738724]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 263.6041\n",
      "[[ 63.02319336]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 157.8204\n",
      "[[ 64.9118042]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 120.5018\n",
      "[[ 67.29614258]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 239.1844\n",
      "[[ 70.42090607]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 137.3439\n",
      "[[ 72.29610443]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 71.2988\n",
      "[[ 74.57807159]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 414.6927\n",
      "[[ 77.74897003]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 49.4504\n",
      "[[ 81.10929108]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 231.1675\n",
      "[[ 82.83309937]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 381.3240\n",
      "[[ 82.62495422]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2283\n",
      "[[ 82.55527496]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 429.4816\n",
      "[[ 80.65644073]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 27.0739\n",
      "[[ 79.29107666]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 378.1113\n",
      "[[ 76.37376404]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1432.5531\n",
      "[[ 70.13646698]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 49.7807\n",
      "[[ 64.2617569]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 723.8720\n",
      "[[ 60.2232132]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1380.4435\n",
      "[[ 58.19521332]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 90.8303\n",
      "[[ 56.99118805]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 928.7939\n",
      "[[ 57.30651093]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.5768\n",
      "[[ 57.45736313]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 33.4793\n",
      "[[ 57.94239044]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 342.5299\n",
      "[[ 59.2518959]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.7920\n",
      "[[ 60.21225357]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 560.9022\n",
      "[[ 62.10938263]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2895\n",
      "[[ 63.88295364]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1606\n",
      "[[ 65.47530365]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 25.1802\n",
      "[[ 67.27671051]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 64.9714\n",
      "[[ 68.27328491]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 61.4413\n",
      "[[ 69.71981049]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0332\n",
      "[[ 71.02342224]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 230.4419\n",
      "[[ 70.87716675]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 32.4951\n",
      "[[ 71.05174255]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 147.3377\n",
      "[[ 71.99288177]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8033\n",
      "[[ 72.90426636]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1200\n",
      "[[ 73.70449066]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 31.2594\n",
      "[[ 73.99729919]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 325.6700\n",
      "[[ 75.07316589]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.5146\n",
      "[[ 76.19719696]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 305.2124\n",
      "[[ 75.55856323]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 264.4745\n",
      "[[ 73.52348328]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3501\n",
      "[[ 71.54719543]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 590.6307\n",
      "[[ 67.58511353]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 65.9019\n",
      "[[ 63.51954651]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 13.4191\n",
      "[[ 60.21089935]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 60.3864\n",
      "[[ 57.79809189]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 404.9594\n",
      "[[ 56.72585678]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 585.9704\n",
      "[[ 57.00177765]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 406.0490\n",
      "[[ 58.20287704]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 469.2544\n",
      "[[ 60.29109955]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 345.5772\n",
      "[[ 63.11958694]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 629.6605\n",
      "[[ 66.8964386]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 119.0362\n",
      "[[ 71.06896973]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.7736\n",
      "[[ 74.68797302]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 146.5497\n",
      "[[ 78.81378937]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 99.2759\n",
      "[[ 81.82010651]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 455.7905\n",
      "[[ 82.50435638]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 21.3437\n",
      "[[ 83.42597198]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 151.3958\n",
      "[[ 84.93052673]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 682.9689\n",
      "[[ 83.79795837]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 467.2094\n",
      "[[ 80.89387512]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 152.4314\n",
      "[[ 79.10231018]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 140.8557\n",
      "[[ 76.50574493]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 51.7234\n",
      "[[ 74.621521]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 123.9713\n",
      "[[ 72.06840515]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.2768\n",
      "[[ 69.93226624]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 156.5065\n",
      "[[ 68.71665955]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 22.9576\n",
      "[[ 67.28852844]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5190\n",
      "[[ 65.96659088]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 82.0989\n",
      "[[ 64.13301086]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 373.7292\n",
      "[[ 60.94832993]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3410.0647\n",
      "[[ 58.92734909]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.8586\n",
      "[[ 57.277565]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 57.2530\n",
      "[[ 56.2486763]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 31.5189\n",
      "[[ 54.94462967]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.3229\n",
      "[[ 53.9422226]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 459.3438\n",
      "[[ 54.09336853]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1071.8580\n",
      "[[ 55.35183716]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 61.0194\n",
      "[[ 56.93823242]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 368.6336\n",
      "[[ 59.28567505]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1921\n",
      "[[ 61.370327]]\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 129.1784\n",
      "[[ 62.37025452]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 634.7738\n",
      "[[ 64.42686462]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 197.2951\n",
      "[[ 67.0075531]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 275.6447\n",
      "[[ 70.42813873]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 349.2512\n",
      "[[ 74.53035736]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 104.6180\n",
      "[[ 77.56890106]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 105.1784\n",
      "[[ 79.56702423]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 456.9867\n",
      "[[ 82.23452759]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 594.7177\n",
      "[[ 82.32379913]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1597.7328\n",
      "[[ 83.83219147]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1364.4043\n",
      "[[ 81.24998474]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 257.9990\n",
      "[[ 77.77529144]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 996.5922\n",
      "[[ 71.82984161]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.8333\n",
      "[[ 66.52548218]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 225.9193\n",
      "[[ 62.65752411]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 88.6297\n",
      "[[ 59.84893417]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.1365e-05\n",
      "[[ 57.38008881]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 188.5863\n",
      "[[ 55.91376495]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 934.2049\n",
      "[[ 55.75285339]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 31.9373\n",
      "[[ 55.89404297]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 305.1873\n",
      "[[ 56.97208023]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 22.5748\n",
      "[[ 58.2163353]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 459.4236\n",
      "[[ 60.22629929]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 205.5496\n",
      "[[ 62.82143402]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 125.7115\n",
      "[[ 64.29056549]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 92.2206\n",
      "[[ 64.92668915]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 710.7442\n",
      "[[ 66.73776245]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 107.7364\n",
      "[[ 67.60315704]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 292.7458\n",
      "[[ 66.90194702]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7962\n",
      "[[ 66.40036011]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 228.5397\n",
      "[[ 66.87088776]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 91.6876\n",
      "[[ 67.8438797]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 418.3342\n",
      "[[ 69.75336456]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 15.3730\n",
      "[[ 71.70963287]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 18.4556\n",
      "[[ 73.15862274]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1720.7185\n",
      "[[ 70.51000977]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 57.3472\n",
      "[[ 68.57909393]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 50.6906\n",
      "[[ 67.22390747]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 438.9014\n",
      "[[ 64.38428497]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 290.5132\n",
      "[[ 60.54705429]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1774.1345\n",
      "[[ 58.73281097]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.3523\n",
      "[[ 56.94124985]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 26.6163\n",
      "[[ 54.99192047]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 16.2703\n",
      "[[ 52.99891281]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.9823\n",
      "[[ 51.33717728]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1541.4807\n",
      "[[ 50.97920227]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1071.1768\n",
      "[[ 51.7416153]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.5352\n",
      "[[ 52.68909454]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 827.8363\n",
      "[[ 54.82121277]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9476\n",
      "[[ 56.84093094]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.6146\n",
      "[[ 58.81275177]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.1567\n",
      "[[ 60.74106216]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 516.9882\n",
      "[[ 61.00538635]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 50.1401\n",
      "[[ 61.72338867]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1168.2938\n",
      "[[ 63.50017548]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.4866\n",
      "[[ 65.31223297]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 229.0727\n",
      "[[ 65.3560791]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 210.0197\n",
      "[[ 66.08953857]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 77.3523\n",
      "[[ 65.94048309]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 35.6396\n",
      "[[ 65.39365387]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 207.4859\n",
      "[[ 66.15531158]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 56.2815\n",
      "[[ 67.22968292]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 43.9456\n",
      "[[ 67.54644012]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.6176\n",
      "[[ 67.95555878]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 506.3127\n",
      "[[ 69.62892914]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 277.6501\n",
      "[[ 72.16181946]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 28.9161\n",
      "[[ 74.85760498]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 43.5845\n",
      "[[ 76.87480927]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.6042\n",
      "[[ 78.3775177]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 65.1080\n",
      "[[ 79.13877869]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1352.1000\n",
      "[[ 76.14391327]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 110.3412\n",
      "[[ 72.7024765]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1171.5537\n",
      "[[ 70.96329498]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1305.3612\n",
      "[[ 66.2250824]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.4324\n",
      "[[ 62.29940033]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 40.3331\n",
      "[[ 59.29393387]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1498.7931\n",
      "[[ 57.86965179]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 174.2033\n",
      "[[ 57.38793564]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 88.2622\n",
      "[[ 57.58739853]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 165.1738\n",
      "[[ 58.5173645]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.4481\n",
      "[[ 59.53895187]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.6895\n",
      "[[ 60.69203568]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 45.6005\n",
      "[[ 62.19482803]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 33.3336\n",
      "[[ 63.96955109]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 100.3341\n",
      "[[ 66.22259521]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.3843\n",
      "[[ 68.62585449]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 233.0313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 71.78836823]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.9359e-04\n",
      "[[ 74.6910553]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 684.9622\n",
      "[[ 74.8290863]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 184.4241\n",
      "[[ 73.76053619]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 271.2433\n",
      "[[ 71.50643921]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 130.4089\n",
      "[[ 70.18727112]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 257.6350\n",
      "[[ 69.8939743]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2164.6355\n",
      "[[ 70.74155426]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 448.4990\n",
      "[[ 69.52178955]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 784.3929\n",
      "[[ 69.73916626]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8265\n",
      "[[ 69.8756485]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 265.8841\n",
      "[[ 68.68205261]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1317.3490\n",
      "[[ 64.19980621]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 88.0703\n",
      "[[ 60.83575058]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0651\n",
      "[[ 57.87680054]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 96.5889\n",
      "[[ 55.8468132]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 296.8283\n",
      "[[ 54.96525192]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 403.5811\n",
      "[[ 55.13753128]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 789.0252\n",
      "[[ 56.49703979]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 688.0733\n",
      "[[ 58.84973145]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6314\n",
      "[[ 61.08382797]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 71.6738\n",
      "[[ 63.65327454]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.9941\n",
      "[[ 65.74012756]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 838.1708\n",
      "[[ 68.86526489]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1599.2738\n",
      "[[ 72.97380829]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 988.5668\n",
      "[[ 78.23916626]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 294.4233\n",
      "[[ 84.04607391]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 948.7107\n",
      "[[ 86.25692749]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1466.9919\n",
      "[[ 84.23557281]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.3926\n",
      "[[ 82.18553925]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 437.1632\n",
      "[[ 78.50847626]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1148.5698\n",
      "[[ 72.00730133]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 208.3008\n",
      "[[ 67.11417389]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.2737\n",
      "[[ 62.93969727]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 35.6851\n",
      "[[ 59.64841461]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 26.3472\n",
      "[[ 56.41399002]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 185.0140\n",
      "[[ 54.33283234]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 531.8124\n",
      "[[ 53.57333374]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1230.3657\n",
      "[[ 54.15649033]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 384.3265\n",
      "[[ 55.66347122]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1348.4758\n",
      "[[ 58.26696014]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 118.9698\n",
      "[[ 59.78918457]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 152.1040\n",
      "[[ 61.82693863]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1443.8846\n",
      "[[ 64.91255188]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 108.8731\n",
      "[[ 66.96878052]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 21.0267\n",
      "[[ 68.51881409]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3336\n",
      "[[ 69.89022064]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 429.1465\n",
      "[[ 69.29769897]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 243.4242\n",
      "[[ 67.53496552]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 79.0914\n",
      "[[ 65.34707642]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 99.2524\n",
      "[[ 64.00914764]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.9544\n",
      "[[ 62.90099716]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 603.6191\n",
      "[[ 62.88647461]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 94.5231\n",
      "[[ 62.14028168]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.8072\n",
      "[[ 61.6460762]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 573.1796\n",
      "[[ 62.26416016]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 20.1398\n",
      "[[ 62.5154686]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 457.7893\n",
      "[[ 63.74205017]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 405.6648\n",
      "[[ 63.1322403]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.3658\n",
      "[[ 62.39144897]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.3116\n",
      "[[ 61.59341431]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.6185\n",
      "[[ 61.15714645]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 40.9688\n",
      "[[ 61.17803955]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 218.0208\n",
      "[[ 59.98042297]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 15.8110\n",
      "[[ 59.14489365]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 148.9935\n",
      "[[ 59.1664505]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1091.2865\n",
      "[[ 60.49046326]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 871.9819\n",
      "[[ 62.74963379]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.6548\n",
      "[[ 64.96133423]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 151.7945\n",
      "[[ 67.63693237]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 173.1677\n",
      "[[ 70.86073303]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 43.3484\n",
      "[[ 73.32886505]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1371.5712\n",
      "[[ 71.96429443]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 194.6916\n",
      "[[ 69.62212372]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 25.0018\n",
      "[[ 67.8892746]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 746.0927\n",
      "[[ 63.9419136]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 53.5066\n",
      "[[ 60.9115715]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 651.3738\n",
      "[[ 56.225811]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 902.5256\n",
      "[[ 53.28100586]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 34.1277\n",
      "[[ 50.21353531]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 484.5540\n",
      "[[ 48.56050873]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 559.0787\n",
      "[[ 48.126194]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.3701\n",
      "[[ 47.90558243]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 208.7649\n",
      "[[ 48.48222351]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 369.1707\n",
      "[[ 49.97920609]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 397.6422\n",
      "[[ 52.34830093]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 892.1298\n",
      "[[ 55.77619553]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 576.1280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 59.92925262]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 260.3241\n",
      "[[ 64.65616608]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 336.4305\n",
      "[[ 69.92266846]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.6567\n",
      "[[ 75.08899689]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 108.7485\n",
      "[[ 80.54380798]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 108.8204\n",
      "[[ 84.82552338]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1274.4440\n",
      "[[ 85.24658203]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2443.3521\n",
      "[[ 80.36746979]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 150.3788\n",
      "[[ 75.24238586]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 13.7051\n",
      "[[ 71.0069046]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 253.9144\n",
      "[[ 66.14228821]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 82.3960\n",
      "[[ 61.31641006]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 164.8557\n",
      "[[ 57.85737991]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 399.5671\n",
      "[[ 55.74197388]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 887.1078\n",
      "[[ 54.92324829]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5452\n",
      "[[ 54.29750061]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6123\n",
      "[[ 53.79572296]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8220\n",
      "[[ 53.29301834]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 60.6362\n",
      "[[ 53.29389572]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.5849\n",
      "[[ 53.40860367]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0309\n",
      "[[ 53.52596283]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 349.3058\n",
      "[[ 54.4708786]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 17.3009\n",
      "[[ 55.05381775]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 270.0146\n",
      "[[ 56.37690353]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 39.6549\n",
      "[[ 57.93211365]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 589.3733\n",
      "[[ 60.30735779]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 503.7429\n",
      "[[ 63.41137695]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 265.5042\n",
      "[[ 67.11960602]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 225.0300\n",
      "[[ 69.37332153]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.1796\n",
      "[[ 71.6190033]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 15.5942\n",
      "[[ 73.42253876]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 14.9796\n",
      "[[ 74.81624603]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 217.5895\n",
      "[[ 75.00682068]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 895.4830\n",
      "[[ 72.65061188]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 14.1053\n",
      "[[ 70.78662872]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 257.2936\n",
      "[[ 68.00445557]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.3288\n",
      "[[ 65.66039276]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 51.1053\n",
      "[[ 63.96743393]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 585.9209\n",
      "[[ 63.48173523]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1969.1792\n",
      "[[ 64.15611267]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 428.5748\n",
      "[[ 63.24544907]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 89.8618\n",
      "[[ 62.90502548]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 239.3539\n",
      "[[ 63.31839752]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 73.6997\n",
      "[[ 63.09171677]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 663.0287\n",
      "[[ 60.89489746]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.9065\n",
      "[[ 58.81449127]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 36.2977\n",
      "[[ 57.30772018]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 565.8649\n",
      "[[ 56.91718292]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1914.4528\n",
      "[[ 57.67560959]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2802.4121\n",
      "[[ 59.07936478]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.1645\n",
      "[[ 60.46363449]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 545.9857\n",
      "[[ 62.70166779]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 781.1298\n",
      "[[ 65.77198792]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 23.5683\n",
      "[[ 68.88144684]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 631.4290\n",
      "[[ 72.7029953]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 514.7635\n",
      "[[ 74.31116486]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.4126\n",
      "[[ 75.64080048]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 85.4107\n",
      "[[ 77.43223572]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 294.2956\n",
      "[[ 77.76270294]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 943.6472\n",
      "[[ 75.37165833]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 422.8572\n",
      "[[ 71.78059387]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 172.6345\n",
      "[[ 69.51036072]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 85.1088\n",
      "[[ 66.79398346]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 228.0475\n",
      "[[ 63.35838318]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 39.7854\n",
      "[[ 59.95607758]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 119.9051\n",
      "[[ 56.27051163]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1797.0906\n",
      "[[ 54.05884552]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 543.3376\n",
      "[[ 52.93667603]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 323.8643\n",
      "[[ 52.73875046]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1534.2687\n",
      "[[ 53.56026459]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 514.4748\n",
      "[[ 55.27291489]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 120.2757\n",
      "[[ 56.09213638]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 17.4356\n",
      "[[ 57.08814621]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 27.8955\n",
      "[[ 58.31546021]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9736\n",
      "[[ 59.37625122]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 434.1380\n",
      "[[ 61.36345673]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 106.5594\n",
      "[[ 62.47439194]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 620.4153\n",
      "[[ 64.53593445]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 169.6627\n",
      "[[ 67.1222229]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.4223\n",
      "[[ 69.6315155]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 349.4796\n",
      "[[ 72.92071533]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 47.6372\n",
      "[[ 76.36945343]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1863\n",
      "[[ 79.46414185]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 70.3715\n",
      "[[ 81.63755035]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 378.1057\n",
      "[[ 81.79425049]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 61.8055\n",
      "[[ 82.46408081]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1244.3462\n",
      "[[ 79.43454742]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 148.2738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 75.75680542]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1247.7493\n",
      "[[ 69.17700195]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.2541\n",
      "[[ 64.29136658]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 76.2776\n",
      "[[ 60.55304718]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 594.6929\n",
      "[[ 58.22688675]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1315.6250\n",
      "[[ 57.54319763]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 623.1213\n",
      "[[ 58.10484314]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 134.0381\n",
      "[[ 59.22466278]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 339.8968\n",
      "[[ 60.9433136]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 22.4036\n",
      "[[ 62.74168777]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 138.4643\n",
      "[[ 64.90341187]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 391.6491\n",
      "[[ 67.69782257]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 423.5393\n",
      "[[ 71.16497803]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 39.0824\n",
      "[[ 74.70270538]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 567.6365\n",
      "[[ 78.93546295]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1906.6437\n",
      "[[ 78.60703278]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 263.8120\n",
      "[[ 78.98818207]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.7552\n",
      "[[ 79.53073883]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 198.9140\n",
      "[[ 80.63672638]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 576.9327\n",
      "[[ 79.7441864]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 23.3125\n",
      "[[ 79.20867157]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.1182\n",
      "[[ 78.84905243]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 14.2360\n",
      "[[ 78.29171753]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 237.5755\n",
      "[[ 76.69207764]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 38.7255\n",
      "[[ 74.86663055]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 68.7562\n",
      "[[ 72.77721405]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 423.0164\n",
      "[[ 71.74293518]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.1774\n",
      "[[ 70.64923859]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 612.8790\n",
      "[[ 70.57164764]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 769.3570\n",
      "[[ 71.50305939]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 165.9460\n",
      "[[ 71.48382568]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 114.2868\n",
      "[[ 70.75660706]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 313.1819\n",
      "[[ 70.92208099]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1263.2837\n",
      "[[ 68.19403076]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 335.7703\n",
      "[[ 64.60208893]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1347\n",
      "[[ 61.40351486]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 94.8484\n",
      "[[ 58.01572037]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 322.2613\n",
      "[[ 55.75614548]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 18.0399\n",
      "[[ 53.96206284]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 14.0581\n",
      "[[ 52.56381607]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 209.7821\n",
      "[[ 51.95023727]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 308.3675\n",
      "[[ 52.15947342]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 110.0830\n",
      "[[ 52.83974838]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 74.4788\n",
      "[[ 53.8602829]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 16.5504\n",
      "[[ 54.55313873]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1060.8832\n",
      "[[ 56.14567947]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 72.9899\n",
      "[[ 58.01780319]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 621.8401\n",
      "[[ 60.60013199]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 901.5440\n",
      "[[ 63.90364075]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 168.2041\n",
      "[[ 67.53704834]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 100.5840\n",
      "[[ 71.42984772]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 53.8778\n",
      "[[ 75.41585541]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5808\n",
      "[[ 79.16140747]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1421.6550\n",
      "[[ 79.37516022]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4808\n",
      "[[ 79.60848999]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 848.8154\n",
      "[[ 77.38066101]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 319.4998\n",
      "[[ 74.19784546]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 109.9213\n",
      "[[ 70.76140594]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8971\n",
      "[[ 67.70023346]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 123.0799\n",
      "[[ 64.33309174]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 287.8286\n",
      "[[ 62.07015991]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 32.3556\n",
      "[[ 59.76910782]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.9788\n",
      "[[ 57.95054626]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 527.2687\n",
      "[[ 57.15189362]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 825.9842\n",
      "[[ 57.35476303]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.6477\n",
      "[[ 57.62376022]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.6341\n",
      "[[ 58.00918198]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 523.1107\n",
      "[[ 59.13364792]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 38.7595\n",
      "[[ 59.81118011]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 31.4348\n",
      "[[ 60.69513702]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1746.2502\n",
      "[[ 62.4693985]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 86.7354\n",
      "[[ 64.52880096]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5579\n",
      "[[ 66.38034058]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 184.5512\n",
      "[[ 67.19408417]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 441.9384\n",
      "[[ 66.45279694]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 36.0126\n",
      "[[ 65.44002533]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1866.9286\n",
      "[[ 65.37924957]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 414.0132\n",
      "[[ 63.95158005]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 553.2888\n",
      "[[ 63.61925888]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 114.1436\n",
      "[[ 62.67506409]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 17.7457\n",
      "[[ 62.04561234]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 640.2173\n",
      "[[ 62.40790939]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 407.3497\n",
      "[[ 61.38497925]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 192.6484\n",
      "[[ 59.57048035]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1834\n",
      "[[ 57.98418045]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 715.6821\n",
      "[[ 57.50762939]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 294.8299\n",
      "[[ 57.81397247]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 56.9168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 58.44517899]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 472.3464\n",
      "[[ 59.8399353]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 118.4912\n",
      "[[ 61.64829254]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6460\n",
      "[[ 63.34380341]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 575.6597\n",
      "[[ 65.72827148]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 40.6947\n",
      "[[ 67.53149414]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 18.6623\n",
      "[[ 68.93934631]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 100.6529\n",
      "[[ 70.75411987]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 238.3875\n",
      "[[ 71.34802246]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 79.3329\n",
      "[[ 72.3536911]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 148.3905\n",
      "[[ 72.46937561]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8859\n",
      "[[ 72.63150024]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 287.9219\n",
      "[[ 71.5745697]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.0375\n",
      "[[ 70.73429871]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.4549\n",
      "[[ 69.8157959]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 483.8506\n",
      "[[ 67.32037354]]\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 101.4220\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-c26724e924ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-a985efddab0c>\u001b[0m in \u001b[0;36mnetwork\u001b[0;34m(model, img, confidence)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfidence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mconfidence\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1004\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m         return self._predict_loop(f, ins, batch_size=batch_size,\n\u001b[0;32m-> 1790\u001b[0;31m                                   verbose=verbose, steps=steps)\n\u001b[0m\u001b[1;32m   1791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1297\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m                     \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1299\u001b[0;31m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1300\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m                     \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    train(model,img,70)\n",
    "    print(network(model,img,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network(model,img,1-mistrust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jump(math.ceil(400.1123))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.save('train_x',train_x)\n",
    "np.save('train_y',train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 181, 101, 16)      160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 45, 25, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 43, 23, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 10, 5, 16)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10, 5, 16)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 28,145\n",
      "Trainable params: 28,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 1s 358us/step - loss: 710.2869 - val_loss: 141.7359\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 342.1548 - val_loss: 106.4325\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 270.6826 - val_loss: 101.0679\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 258.7419 - val_loss: 112.6773\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 236.0895 - val_loss: 58.2856\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 226.8815 - val_loss: 55.2471\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 216.3279 - val_loss: 65.9497\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 216.6232 - val_loss: 61.1145\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 265us/step - loss: 208.5963 - val_loss: 41.7410\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 218.6590 - val_loss: 56.0127\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 276us/step - loss: 191.6640 - val_loss: 47.5058\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 257us/step - loss: 197.6755 - val_loss: 73.1699\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 208.4206 - val_loss: 55.0611\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 187.9378 - val_loss: 58.5539\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 184.5890 - val_loss: 61.5472\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 208.4211 - val_loss: 135.5800\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 188.2624 - val_loss: 56.3044\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 183.3860 - val_loss: 40.6832\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 202.6264 - val_loss: 42.3734\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 181.8714 - val_loss: 76.7466\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 288us/step - loss: 185.5371 - val_loss: 50.7137\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 191.8888 - val_loss: 37.3417\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 190.1720 - val_loss: 82.7204\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 169.9050 - val_loss: 38.9145\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 182.8582 - val_loss: 36.6751\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 258us/step - loss: 182.3493 - val_loss: 40.6102\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 190.7020 - val_loss: 40.9102\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 196.2439 - val_loss: 141.8058\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 282us/step - loss: 195.3769 - val_loss: 34.8716\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 187.6790 - val_loss: 52.6806\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 180.7320 - val_loss: 36.7994\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 182.2537 - val_loss: 43.9376\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 179.1553 - val_loss: 38.6965\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 188.3906 - val_loss: 36.0145\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 188.0972 - val_loss: 34.9522\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 258us/step - loss: 171.0446 - val_loss: 34.9096\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 169.2786 - val_loss: 46.3519\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 169.0920 - val_loss: 36.4497\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 286us/step - loss: 193.3629 - val_loss: 41.8852\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 160.5225 - val_loss: 38.2830\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 275us/step - loss: 175.7133 - val_loss: 52.6916\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 163.8661 - val_loss: 43.6043\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 183.1801 - val_loss: 36.9701\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 181.3561 - val_loss: 37.1452\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 263us/step - loss: 177.4788 - val_loss: 39.2088\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 264us/step - loss: 163.4789 - val_loss: 34.3760\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 172.9965 - val_loss: 51.6086\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 164.3776 - val_loss: 35.1548\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 262us/step - loss: 154.5780 - val_loss: 53.2100\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 154.8197 - val_loss: 36.2253\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 266us/step - loss: 151.3896 - val_loss: 39.0559\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 155.5303 - val_loss: 36.2896\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 280us/step - loss: 157.8300 - val_loss: 35.4994\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1567/1567 [==============================] - 0s 248us/step - loss: 160.2686 - val_loss: 81.6682\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 263us/step - loss: 152.9585 - val_loss: 34.4970\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 277us/step - loss: 149.6350 - val_loss: 34.6382\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 267us/step - loss: 158.2753 - val_loss: 58.7117\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 262us/step - loss: 165.1204 - val_loss: 39.6014\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 164.2447 - val_loss: 35.9767\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 273us/step - loss: 149.9279 - val_loss: 34.9596\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 149.3385 - val_loss: 34.5015\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 262us/step - loss: 159.5251 - val_loss: 44.2560\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 160.1150 - val_loss: 38.5534\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 267us/step - loss: 164.1571 - val_loss: 40.1099\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 149.5080 - val_loss: 38.5282\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 263us/step - loss: 156.3975 - val_loss: 39.0017\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 151.5985 - val_loss: 35.2100\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 274us/step - loss: 146.1243 - val_loss: 56.4040\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 157.6603 - val_loss: 35.6888\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 266us/step - loss: 148.4016 - val_loss: 33.8770\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 151.6366 - val_loss: 39.1676\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 261us/step - loss: 149.4738 - val_loss: 33.5158\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 143.0997 - val_loss: 34.1839\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 258us/step - loss: 136.9186 - val_loss: 35.5535\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 135.6691 - val_loss: 42.3349\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 153.7877 - val_loss: 59.5894\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 141.0081 - val_loss: 33.4725\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 282us/step - loss: 142.9073 - val_loss: 32.9504\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 262us/step - loss: 145.5059 - val_loss: 33.8173\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 145.3349 - val_loss: 35.5260\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 261us/step - loss: 139.3232 - val_loss: 36.7138\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 139.8698 - val_loss: 33.6789\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 145.2591 - val_loss: 35.0993\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 265us/step - loss: 141.6216 - val_loss: 68.4518\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 154.3430 - val_loss: 33.8849\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 139.4795 - val_loss: 33.0180\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 261us/step - loss: 137.2900 - val_loss: 43.6664\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 145.4628 - val_loss: 44.9662\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 142.2282 - val_loss: 36.1283\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 273us/step - loss: 138.9180 - val_loss: 47.1249\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 138.5611 - val_loss: 40.1009\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 265us/step - loss: 142.1342 - val_loss: 38.0325\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 137.0510 - val_loss: 36.7648\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 263us/step - loss: 146.2926 - val_loss: 37.0616\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 270us/step - loss: 137.1766 - val_loss: 37.0094\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 137.2389 - val_loss: 37.7649\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 260us/step - loss: 140.6529 - val_loss: 38.1293\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 143.9078 - val_loss: 63.0037\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 263us/step - loss: 149.1235 - val_loss: 33.4072\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 268us/step - loss: 136.8557 - val_loss: 51.0520\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 140.5567 - val_loss: 35.6087\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 142.6794 - val_loss: 35.7206\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 138.8105 - val_loss: 34.3191\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 139.6810 - val_loss: 39.6655\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 279us/step - loss: 132.4920 - val_loss: 40.6716\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 258us/step - loss: 139.6660 - val_loss: 48.2135\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 140.8320 - val_loss: 36.2574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 141.0737 - val_loss: 33.1289\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 234us/step - loss: 141.0254 - val_loss: 59.7288\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 270us/step - loss: 145.2934 - val_loss: 33.7637\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 274us/step - loss: 130.6358 - val_loss: 34.3896\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 264us/step - loss: 141.3539 - val_loss: 49.2855\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 265us/step - loss: 128.3683 - val_loss: 34.8713\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 143.1232 - val_loss: 34.1372\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 136.5974 - val_loss: 34.0814\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 133.3263 - val_loss: 34.6020\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 150.6155 - val_loss: 40.8992\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 145.0380 - val_loss: 38.6222\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 259us/step - loss: 128.9658 - val_loss: 36.8173\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 263us/step - loss: 137.6322 - val_loss: 37.7414\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 143.2159 - val_loss: 34.6938\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 141.1710 - val_loss: 33.9692\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 137.0555 - val_loss: 34.8679\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 140.1120 - val_loss: 37.1086\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 138.5442 - val_loss: 36.2712\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 136.4422 - val_loss: 33.6452\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 258us/step - loss: 139.0864 - val_loss: 39.7461\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 140.4445 - val_loss: 40.4825\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 131.9611 - val_loss: 41.1247\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 132.8796 - val_loss: 37.0757\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 146.2872 - val_loss: 33.6319\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 126.6456 - val_loss: 34.3491\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 133.4886 - val_loss: 35.3223\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 120.9157 - val_loss: 64.4182\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 132.9044 - val_loss: 35.4929\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 131.7480 - val_loss: 39.8845\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 142.3489 - val_loss: 34.8432\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 141.6417 - val_loss: 37.7676\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 137.8340 - val_loss: 33.4600\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 127.6349 - val_loss: 37.2672\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 132.6073 - val_loss: 38.3985\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 132.9333 - val_loss: 38.4616\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 129.0557 - val_loss: 33.3031\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 130.7468 - val_loss: 33.3104\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 138.0393 - val_loss: 32.0795\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 137.4933 - val_loss: 42.6153\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 146.7277 - val_loss: 32.2371\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 131.8593 - val_loss: 42.2549\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 129.4191 - val_loss: 31.9956\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 261us/step - loss: 134.0472 - val_loss: 32.4345\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 125.2495 - val_loss: 38.2377\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 138.8071 - val_loss: 33.5946\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 139.7811 - val_loss: 31.3414\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 136.6628 - val_loss: 36.3409\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 134.2063 - val_loss: 31.2421\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 129.9586 - val_loss: 32.1161\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 134.9337 - val_loss: 31.0617\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 133.9442 - val_loss: 31.6965\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 131.5510 - val_loss: 30.6685\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 126.4525 - val_loss: 46.5080\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1567/1567 [==============================] - 0s 238us/step - loss: 134.6599 - val_loss: 38.7017\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 126.4143 - val_loss: 39.3293\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 138.8613 - val_loss: 58.1029\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 131.8318 - val_loss: 34.0174\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 138.2569 - val_loss: 32.3891\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 131.8388 - val_loss: 33.4209\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 128.4259 - val_loss: 32.5463\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 234us/step - loss: 141.4108 - val_loss: 32.9673\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 131.6950 - val_loss: 36.3935\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 134.4510 - val_loss: 36.7788\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 129.7887 - val_loss: 30.9328\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 261us/step - loss: 137.6060 - val_loss: 35.1257\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 124.8361 - val_loss: 31.3198\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 132.0813 - val_loss: 38.7810\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 130.2672 - val_loss: 72.2677\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 128.8688 - val_loss: 31.2939\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 127.5790 - val_loss: 32.0889\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 127.4334 - val_loss: 36.8474\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 257us/step - loss: 127.0598 - val_loss: 33.7687\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 266us/step - loss: 123.7682 - val_loss: 33.5062\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 264us/step - loss: 130.9746 - val_loss: 32.9157\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 263us/step - loss: 125.8738 - val_loss: 34.1780\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 134.0301 - val_loss: 30.8042\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 125.1251 - val_loss: 33.5041\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 131.3379 - val_loss: 47.2695\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 127.1113 - val_loss: 39.1953\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 124.1475 - val_loss: 44.5475\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 267us/step - loss: 124.2521 - val_loss: 32.0504\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 121.0910 - val_loss: 32.8241\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 131.7454 - val_loss: 31.2977\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 136.8187 - val_loss: 31.2784\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 122.9140 - val_loss: 49.9631\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 126.0573 - val_loss: 31.5154\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 127.6435 - val_loss: 36.2396\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 121.1440 - val_loss: 37.7715\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 126.0232 - val_loss: 33.2152\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 136.0588 - val_loss: 35.0869\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 127.6221 - val_loss: 36.8686\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 133.0737 - val_loss: 36.2544\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 123.8394 - val_loss: 51.7512\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 128.0054 - val_loss: 35.9384\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 118.5193 - val_loss: 36.3411\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 131.5214 - val_loss: 32.9921\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 126.2359 - val_loss: 31.9410\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 119.4194 - val_loss: 30.7719\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 135.7951 - val_loss: 33.6111\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 117.5339 - val_loss: 30.6896\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 126.8321 - val_loss: 39.0326\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 132.1890 - val_loss: 30.8289\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 129.0178 - val_loss: 31.0581\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 121.5007 - val_loss: 32.6087\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 124.1076 - val_loss: 38.1378\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 126.8328 - val_loss: 40.2329\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 121.9106 - val_loss: 32.0515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 129.0246 - val_loss: 31.1254\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 131.3546 - val_loss: 32.4634\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 266us/step - loss: 128.6576 - val_loss: 34.8079\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 258us/step - loss: 117.0773 - val_loss: 32.2421\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 124.9735 - val_loss: 34.0556\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 259us/step - loss: 119.1545 - val_loss: 32.2079\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 127.8180 - val_loss: 31.3671\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 133.8575 - val_loss: 40.1540\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 279us/step - loss: 127.1380 - val_loss: 42.8322\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 121.6114 - val_loss: 31.4930\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 118.0827 - val_loss: 32.0913\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 130.1648 - val_loss: 31.6062\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 115.5981 - val_loss: 32.6245\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 118.5637 - val_loss: 33.0303\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 120.4019 - val_loss: 37.5501\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 257us/step - loss: 123.9178 - val_loss: 31.0856\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 259us/step - loss: 120.8782 - val_loss: 33.7579\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 258us/step - loss: 120.4294 - val_loss: 30.4140\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 263us/step - loss: 130.5609 - val_loss: 33.3025\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 263us/step - loss: 118.1291 - val_loss: 33.5388\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 270us/step - loss: 132.8496 - val_loss: 31.3041\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 124.6890 - val_loss: 42.2476\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 117.4577 - val_loss: 30.6037\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 121.9838 - val_loss: 30.6037\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 122.2217 - val_loss: 30.7230\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 120.2746 - val_loss: 30.2680\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 124.9855 - val_loss: 30.1018\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 119.4548 - val_loss: 32.4341\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 122.8387 - val_loss: 29.7781\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 119.5867 - val_loss: 31.1526\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 118.1742 - val_loss: 29.7418\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 121.5626 - val_loss: 38.8670\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 118.1261 - val_loss: 44.9554\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 120.7791 - val_loss: 30.4504\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 119.0227 - val_loss: 30.2573\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 122.6075 - val_loss: 34.1052\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 119.3280 - val_loss: 38.3502\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 126.8975 - val_loss: 77.2411\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 129.5152 - val_loss: 31.4224\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 121.9383 - val_loss: 32.1236\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 121.0354 - val_loss: 41.0421\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 128.5938 - val_loss: 33.2308\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 113.6626 - val_loss: 32.5196\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 122.6439 - val_loss: 30.7654\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 119.3256 - val_loss: 34.3013\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 115.6567 - val_loss: 32.7244\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 119.7984 - val_loss: 33.8585\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 122.3844 - val_loss: 48.3557\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 129.6178 - val_loss: 32.4227\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 122.2516 - val_loss: 36.4621\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 117.0872 - val_loss: 31.2114\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 125.6169 - val_loss: 33.3840\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 115.5659 - val_loss: 33.0677\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1567/1567 [==============================] - 0s 238us/step - loss: 126.3740 - val_loss: 42.9683\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 120.5354 - val_loss: 32.8925\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 121.3849 - val_loss: 35.7558\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 118.3727 - val_loss: 37.0494\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 128.6037 - val_loss: 30.3185\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 257us/step - loss: 122.5319 - val_loss: 36.6846\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 265us/step - loss: 118.4797 - val_loss: 29.8660\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 123.5660 - val_loss: 30.3769\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 118.7268 - val_loss: 29.9274\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 261us/step - loss: 109.6513 - val_loss: 36.1760\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 119.5846 - val_loss: 45.2041\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 124.7471 - val_loss: 30.3210\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 267us/step - loss: 119.2592 - val_loss: 31.6180\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 122.7766 - val_loss: 45.1667\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 119.6857 - val_loss: 30.8628\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 121.9084 - val_loss: 31.8667\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 279us/step - loss: 127.9934 - val_loss: 36.7745\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 269us/step - loss: 118.4164 - val_loss: 30.3015\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 261us/step - loss: 130.9994 - val_loss: 34.8827\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 272us/step - loss: 116.7310 - val_loss: 31.3945\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 112.7110 - val_loss: 31.4539\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 265us/step - loss: 116.7588 - val_loss: 34.4396\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 120.2645 - val_loss: 30.8522\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 121.3483 - val_loss: 30.3539\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 129.0216 - val_loss: 38.8793\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 115.8937 - val_loss: 30.7086\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 112.5720 - val_loss: 33.2402\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 115.5996 - val_loss: 31.9327\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 115.0703 - val_loss: 30.4106\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 117.7830 - val_loss: 38.4086\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 120.7285 - val_loss: 30.4454\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 260us/step - loss: 112.4690 - val_loss: 30.3913\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 265us/step - loss: 113.9226 - val_loss: 31.2300\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 115.8272 - val_loss: 31.5698\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 260us/step - loss: 117.6977 - val_loss: 41.6426\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 261us/step - loss: 115.9764 - val_loss: 31.3419\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 257us/step - loss: 117.0199 - val_loss: 30.3908\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 125.2575 - val_loss: 33.2826\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 132.0322 - val_loss: 35.2758\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 257us/step - loss: 110.0302 - val_loss: 31.8465\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 116.8277 - val_loss: 44.5679\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 235us/step - loss: 115.2950 - val_loss: 30.6353\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 122.8569 - val_loss: 33.5631\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 125.0663 - val_loss: 31.0928\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 125.2856 - val_loss: 41.2969\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 114.9515 - val_loss: 30.8895\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 116.7136 - val_loss: 41.8599\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 124.4003 - val_loss: 30.9044\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 113.4995 - val_loss: 36.3588\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 116.9222 - val_loss: 30.9852\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 107.8218 - val_loss: 30.8843\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 110.6675 - val_loss: 30.9744\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 105.9562 - val_loss: 30.1234\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 116.2749 - val_loss: 31.7377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 113.4259 - val_loss: 40.8355\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 107.5077 - val_loss: 38.1785\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 110.1577 - val_loss: 31.2889\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 271us/step - loss: 107.2333 - val_loss: 30.6510\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 262us/step - loss: 112.2267 - val_loss: 32.2844\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 115.8678 - val_loss: 30.8132\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 264us/step - loss: 118.3612 - val_loss: 35.0780\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 119.2029 - val_loss: 30.4882\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 274us/step - loss: 112.0212 - val_loss: 30.1573\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 114.0218 - val_loss: 32.8522\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 266us/step - loss: 115.2084 - val_loss: 30.5961\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 114.1462 - val_loss: 34.7938\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 113.5593 - val_loss: 34.8641\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 110.2805 - val_loss: 29.7016\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 258us/step - loss: 115.7979 - val_loss: 37.5488\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 114.2348 - val_loss: 35.1350\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 111.4606 - val_loss: 33.1942\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 114.3625 - val_loss: 29.8031\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 112.1399 - val_loss: 36.7562\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 112.1384 - val_loss: 35.3921\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 114.2200 - val_loss: 29.2676\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 112.8799 - val_loss: 29.6870\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 114.6323 - val_loss: 34.5617\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 261us/step - loss: 108.2549 - val_loss: 34.6247\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 108.1576 - val_loss: 33.0966\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 103.6338 - val_loss: 37.0155\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 111.6331 - val_loss: 31.7852\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 122.7743 - val_loss: 34.6492\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 112.3022 - val_loss: 31.5265\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 103.0175 - val_loss: 30.8641\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 257us/step - loss: 109.2104 - val_loss: 30.0471\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 258us/step - loss: 109.1625 - val_loss: 31.4651\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 112.4390 - val_loss: 30.6807\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 111.7699 - val_loss: 31.1171\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 105.1771 - val_loss: 33.3053\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 112.6147 - val_loss: 30.1961\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 112.0858 - val_loss: 30.3872\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 111.5898 - val_loss: 30.1965\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 109.1356 - val_loss: 31.0144\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 114.0430 - val_loss: 30.4141\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 109.6517 - val_loss: 41.8353\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 110.0336 - val_loss: 29.7321\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 113.8556 - val_loss: 30.4238\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 119.2273 - val_loss: 30.9386\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 108.5493 - val_loss: 29.5412\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 115.9324 - val_loss: 30.5591\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 110.6021 - val_loss: 33.5919\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 116.1702 - val_loss: 29.7595\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 113.3741 - val_loss: 30.5731\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 110.1390 - val_loss: 33.0619\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 102.2384 - val_loss: 31.2044\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 112.2991 - val_loss: 30.5395\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 112.5458 - val_loss: 34.6546\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1567/1567 [==============================] - 0s 238us/step - loss: 116.8027 - val_loss: 37.1206\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 109.6958 - val_loss: 30.1491\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 113.2136 - val_loss: 30.1650\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 102.4899 - val_loss: 30.6656\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 117.2411 - val_loss: 29.6063\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 103.4902 - val_loss: 32.3198\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 109.7940 - val_loss: 31.6257\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 105.4379 - val_loss: 32.2927\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 109.1150 - val_loss: 39.0997\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 259us/step - loss: 105.1125 - val_loss: 40.5722\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 116.2504 - val_loss: 29.6395\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 108.6260 - val_loss: 30.3681\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 103.2465 - val_loss: 30.4638\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 112.2482 - val_loss: 44.4960\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 258us/step - loss: 99.8975 - val_loss: 29.7712\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 111.4961 - val_loss: 30.6393\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 104.6548 - val_loss: 30.4619\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 121.1483 - val_loss: 36.5839\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 111.8596 - val_loss: 32.4656\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 281us/step - loss: 113.2422 - val_loss: 29.3862\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 265us/step - loss: 104.5263 - val_loss: 30.7054\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 257us/step - loss: 107.5477 - val_loss: 40.6351\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 275us/step - loss: 108.5025 - val_loss: 30.3218\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 109.9491 - val_loss: 67.4010\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 117.6834 - val_loss: 31.1814\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 115.3276 - val_loss: 37.5460\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 110.0478 - val_loss: 29.8963\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 107.9142 - val_loss: 38.6966\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 109.1552 - val_loss: 37.5493\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 258us/step - loss: 112.1682 - val_loss: 38.0507\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 108.8536 - val_loss: 29.7978\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 106.5405 - val_loss: 50.2632\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 113.6910 - val_loss: 35.0179\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 113.3984 - val_loss: 31.4677\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 257us/step - loss: 104.7150 - val_loss: 32.9119\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 106.5749 - val_loss: 30.5730\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 102.3430 - val_loss: 30.6009\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 100.0568 - val_loss: 29.2477\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 102.8553 - val_loss: 30.0147\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 106.2970 - val_loss: 29.5336\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 109.8215 - val_loss: 31.4576\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 106.7759 - val_loss: 30.1904\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 105.4437 - val_loss: 34.1276\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 101.4951 - val_loss: 33.6156\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 103.9766 - val_loss: 31.5519\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 104.2447 - val_loss: 29.2791\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 110.5378 - val_loss: 32.1794\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 111.8002 - val_loss: 34.5907\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 108.1439 - val_loss: 30.9823\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 108.6660 - val_loss: 31.5492\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 102.0312 - val_loss: 39.2163\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 108.6806 - val_loss: 32.9797\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 104.3626 - val_loss: 32.3523\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 106.9761 - val_loss: 30.5198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 102.7744 - val_loss: 29.5924\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 100.5551 - val_loss: 28.9837\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 280us/step - loss: 99.2602 - val_loss: 38.8860\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 274us/step - loss: 107.6895 - val_loss: 30.8015\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 261us/step - loss: 111.8917 - val_loss: 30.5124\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 113.4961 - val_loss: 28.6181\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 106.7574 - val_loss: 30.9535\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 103.8165 - val_loss: 29.9004\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 106.7361 - val_loss: 32.9896\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 282us/step - loss: 108.6322 - val_loss: 34.9423\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 282us/step - loss: 103.2347 - val_loss: 32.4296\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 277us/step - loss: 108.2902 - val_loss: 31.6059\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 99.3993 - val_loss: 32.0751\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 113.7822 - val_loss: 29.7175\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 258us/step - loss: 107.0854 - val_loss: 30.7378\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 259us/step - loss: 102.7708 - val_loss: 32.6899\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 109.8162 - val_loss: 36.9267\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 106.7301 - val_loss: 30.5669\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 103.6307 - val_loss: 43.3022\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 273us/step - loss: 103.5604 - val_loss: 30.6030\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 103.8280 - val_loss: 30.2934\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 93.3620 - val_loss: 34.4718\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 105.6594 - val_loss: 30.3696\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 97.0807 - val_loss: 34.7519\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 97.7478 - val_loss: 29.3626\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 109.7631 - val_loss: 29.8796\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 101.1929 - val_loss: 36.3840\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 99.3560 - val_loss: 29.4781\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 106.6123 - val_loss: 33.6380\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 269us/step - loss: 106.2548 - val_loss: 44.6788\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 111.5537 - val_loss: 62.1446\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 101.3562 - val_loss: 29.2242\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 101.8866 - val_loss: 30.1112\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 104.9946 - val_loss: 31.4245\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 257us/step - loss: 110.1607 - val_loss: 33.1685\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 102.3175 - val_loss: 35.5623\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 104.7673 - val_loss: 32.5644\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 103.2351 - val_loss: 31.3733\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 104.7356 - val_loss: 32.1584\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 103.9762 - val_loss: 31.9145\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 101.8307 - val_loss: 31.2535\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 102.2572 - val_loss: 36.6618\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 105.2804 - val_loss: 31.5517\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 96.2083 - val_loss: 33.6175\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 110.2475 - val_loss: 31.1741\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 103.0565 - val_loss: 32.5921\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 99.2895 - val_loss: 30.8404\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 99.1661 - val_loss: 31.7702\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 110.1621 - val_loss: 31.4065\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 105.9628 - val_loss: 35.0962\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 98.9967 - val_loss: 32.2051\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 108.3316 - val_loss: 29.9450\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 102.5480 - val_loss: 30.1578\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1567/1567 [==============================] - 0s 247us/step - loss: 98.5149 - val_loss: 30.9410\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 257us/step - loss: 109.3001 - val_loss: 32.8012\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 104.4363 - val_loss: 31.2892\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 264us/step - loss: 105.5873 - val_loss: 44.2480\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 262us/step - loss: 101.8042 - val_loss: 33.6045\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 102.5563 - val_loss: 30.0125\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 103.0512 - val_loss: 32.2584\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 100.9711 - val_loss: 33.2720\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 104.4419 - val_loss: 30.0000\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 99.2849 - val_loss: 30.3837\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 99.4588 - val_loss: 30.5067\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 98.4537 - val_loss: 33.2885\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 111.8172 - val_loss: 30.0566\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 95.4211 - val_loss: 30.6685\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 98.4885 - val_loss: 30.7039\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 102.3346 - val_loss: 33.7282\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 100.9913 - val_loss: 43.0254\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 107.2036 - val_loss: 32.0359\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 100.4370 - val_loss: 42.7983\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 102.5416 - val_loss: 30.5047\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 266us/step - loss: 103.8761 - val_loss: 33.9992\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 267us/step - loss: 98.5179 - val_loss: 38.8690\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 267us/step - loss: 102.5115 - val_loss: 32.0988\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 264us/step - loss: 107.4389 - val_loss: 33.2085\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 263us/step - loss: 96.2811 - val_loss: 30.9066\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 97.2584 - val_loss: 33.5301\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 87.4396 - val_loss: 31.0094\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 99.0400 - val_loss: 34.8858\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 96.1613 - val_loss: 40.9645\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 100.1866 - val_loss: 31.2294\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 102.1661 - val_loss: 31.1350\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 96.7930 - val_loss: 33.5187\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 94.4768 - val_loss: 34.1062\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 90.4685 - val_loss: 32.5041\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 95.9287 - val_loss: 34.1984\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 258us/step - loss: 100.7632 - val_loss: 32.7898\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 97.5500 - val_loss: 38.9104\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 106.8472 - val_loss: 30.0049\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 270us/step - loss: 93.7274 - val_loss: 30.0039\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 97.1228 - val_loss: 34.7835\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 101.4606 - val_loss: 30.6849\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 94.3704 - val_loss: 31.5536\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 103.0993 - val_loss: 35.1456\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 95.1055 - val_loss: 30.5777\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 100.1333 - val_loss: 33.3707\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 99.4620 - val_loss: 31.8506\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 94.1550 - val_loss: 31.3882\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 99.1589 - val_loss: 29.7353\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 96.0474 - val_loss: 31.4532\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 94.5917 - val_loss: 32.4176\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 98.5765 - val_loss: 29.8688\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 93.3091 - val_loss: 30.3837\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 89.9926 - val_loss: 32.5324\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 95.7694 - val_loss: 38.4500\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1567/1567 [==============================] - 0s 234us/step - loss: 95.1447 - val_loss: 30.2130\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 235us/step - loss: 100.4123 - val_loss: 50.0618\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 258us/step - loss: 89.8742 - val_loss: 31.0288\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 96.5142 - val_loss: 30.3509\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 95.2570 - val_loss: 34.2312\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 98.8785 - val_loss: 47.9778\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 100.1902 - val_loss: 32.2677\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 99.2115 - val_loss: 32.3597\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 101.8224 - val_loss: 30.6772\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 275us/step - loss: 93.8912 - val_loss: 613.4285\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 261us/step - loss: 133.0614 - val_loss: 38.0911\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 263us/step - loss: 102.7663 - val_loss: 31.0966\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 265us/step - loss: 94.0819 - val_loss: 32.7204\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 91.9576 - val_loss: 32.9269\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 273us/step - loss: 95.0221 - val_loss: 36.4104\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 96.2353 - val_loss: 36.1232\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 94.7332 - val_loss: 33.0456\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 269us/step - loss: 94.4009 - val_loss: 32.7925\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 260us/step - loss: 93.9399 - val_loss: 29.2919\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 100.7415 - val_loss: 53.3799\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 96.4951 - val_loss: 29.7860\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 85.2602 - val_loss: 31.4987\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 94.1479 - val_loss: 30.2778\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 91.9770 - val_loss: 35.8277\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 96.5765 - val_loss: 37.8906\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 92.6257 - val_loss: 30.4362\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 93.9319 - val_loss: 30.8718\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 257us/step - loss: 97.3549 - val_loss: 30.4596\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 96.1966 - val_loss: 30.1620\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 261us/step - loss: 98.7984 - val_loss: 31.0845\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 90.8383 - val_loss: 31.4277\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 92.3079 - val_loss: 32.0597\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 94.7925 - val_loss: 30.5089\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 93.7153 - val_loss: 30.9938\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 97.6858 - val_loss: 31.2089\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 88.4306 - val_loss: 32.4084\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 99.0659 - val_loss: 31.5435\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 91.0667 - val_loss: 36.1902\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 97.8338 - val_loss: 33.2725\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 92.7582 - val_loss: 29.7629\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 96.8107 - val_loss: 35.3728\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 88.5153 - val_loss: 30.9453\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 87.2422 - val_loss: 29.6485\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 98.5397 - val_loss: 33.1808\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 92.6084 - val_loss: 30.7508\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 260us/step - loss: 92.4451 - val_loss: 30.4645\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 92.5914 - val_loss: 30.1745\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 93.7401 - val_loss: 32.7002\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 90.7083 - val_loss: 44.2152\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 96.7995 - val_loss: 32.9799\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 92.6532 - val_loss: 32.0173\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 89.2086 - val_loss: 31.0313\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 90.2317 - val_loss: 30.3568\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 91.4974 - val_loss: 31.1165\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1567/1567 [==============================] - 0s 243us/step - loss: 96.5988 - val_loss: 31.1369\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 84.3435 - val_loss: 31.4935\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 234us/step - loss: 95.9255 - val_loss: 31.2437\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 257us/step - loss: 95.6668 - val_loss: 29.9263\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 266us/step - loss: 99.2290 - val_loss: 42.4306\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 89.4632 - val_loss: 30.1631\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 234us/step - loss: 88.7301 - val_loss: 36.9776\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 94.8369 - val_loss: 39.6054\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 235us/step - loss: 88.7793 - val_loss: 30.9413\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 267us/step - loss: 90.8688 - val_loss: 45.7225\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 257us/step - loss: 89.1234 - val_loss: 28.8966\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 85.8438 - val_loss: 29.6291\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 258us/step - loss: 87.9610 - val_loss: 31.6536\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 265us/step - loss: 94.5455 - val_loss: 30.2115\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 264us/step - loss: 92.7376 - val_loss: 31.0108\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 271us/step - loss: 90.2132 - val_loss: 28.8547\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 269us/step - loss: 87.8896 - val_loss: 29.7986\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 89.5285 - val_loss: 30.6738\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 88.0911 - val_loss: 29.2647\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 258us/step - loss: 86.4182 - val_loss: 30.6129\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 257us/step - loss: 95.3493 - val_loss: 34.1918\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 274us/step - loss: 86.1350 - val_loss: 37.8605\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 90.7471 - val_loss: 30.7492\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 89.2773 - val_loss: 30.9570\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 89.3581 - val_loss: 32.2171\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 90.5069 - val_loss: 32.6402\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 86.7113 - val_loss: 46.8579\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 89.9510 - val_loss: 31.6452\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 87.6887 - val_loss: 30.6195\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 262us/step - loss: 82.3146 - val_loss: 29.5738\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 88.0380 - val_loss: 32.8389\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 77.8113 - val_loss: 30.3414\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 77.6700 - val_loss: 31.5406\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 85.2819 - val_loss: 30.6508\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 84.6193 - val_loss: 34.0420\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 85.0506 - val_loss: 31.6827\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 87.7200 - val_loss: 35.0357\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 91.1029 - val_loss: 29.1757\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 81.7521 - val_loss: 32.8226\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 84.5547 - val_loss: 33.4968\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 84.0748 - val_loss: 31.1189\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 89.6850 - val_loss: 31.5702\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 88.6175 - val_loss: 30.3315\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 88.2410 - val_loss: 32.7163\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 257us/step - loss: 78.1910 - val_loss: 33.5850\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 84.0131 - val_loss: 37.8643\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 82.0665 - val_loss: 33.2017\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 258us/step - loss: 83.2692 - val_loss: 29.8069\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 89.9396 - val_loss: 31.2187\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 85.5925 - val_loss: 34.0778\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 88.2818 - val_loss: 34.5510\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 88.8729 - val_loss: 33.7605\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 82.5161 - val_loss: 37.8591\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 82.9887 - val_loss: 30.8503\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1567/1567 [==============================] - 0s 237us/step - loss: 83.1591 - val_loss: 30.9622\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 83.0971 - val_loss: 31.9871\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 233us/step - loss: 84.8313 - val_loss: 32.8908\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 81.8229 - val_loss: 39.6875\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 86.6872 - val_loss: 31.4889\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 269us/step - loss: 81.9155 - val_loss: 32.4535\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 269us/step - loss: 83.0683 - val_loss: 32.6422\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 270us/step - loss: 81.9599 - val_loss: 31.2184\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 266us/step - loss: 86.6014 - val_loss: 33.0035\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 235us/step - loss: 84.0538 - val_loss: 33.4175\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 77.7522 - val_loss: 31.7058\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 264us/step - loss: 76.4503 - val_loss: 34.2033\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 80.1869 - val_loss: 35.8855\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 83.1896 - val_loss: 30.5561\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 86.3339 - val_loss: 33.5983\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 257us/step - loss: 89.1784 - val_loss: 29.1207\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 78.4661 - val_loss: 31.9995\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 83.2907 - val_loss: 31.6192\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 81.8831 - val_loss: 31.7951\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 80.7706 - val_loss: 35.7529\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 86.1009 - val_loss: 31.3068\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 260us/step - loss: 79.7712 - val_loss: 31.0871\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 84.6975 - val_loss: 38.0098\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 82.9509 - val_loss: 31.6729\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 263us/step - loss: 84.4663 - val_loss: 29.4585\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 257us/step - loss: 82.3937 - val_loss: 31.7107\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 79.2566 - val_loss: 32.8521\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 83.5380 - val_loss: 29.7904\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 84.7299 - val_loss: 30.9515\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 76.3192 - val_loss: 34.4668\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 82.6230 - val_loss: 33.2239\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 77.8340 - val_loss: 39.7813\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 77.5320 - val_loss: 31.5364\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 78.3499 - val_loss: 37.5054\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 80.5961 - val_loss: 32.5067\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 76.1843 - val_loss: 29.5230\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 258us/step - loss: 75.0945 - val_loss: 30.0001\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 78.7222 - val_loss: 35.9831\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 81.2472 - val_loss: 30.8132\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 76.7983 - val_loss: 30.5256\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 74.7632 - val_loss: 40.3254\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 81.3094 - val_loss: 30.5475\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 75.3792 - val_loss: 30.9197\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 76.4478 - val_loss: 30.0048\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 74.4336 - val_loss: 29.7950\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 77.0435 - val_loss: 31.0841\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 76.0416 - val_loss: 31.8224\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 74.4515 - val_loss: 30.9369\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 77.0686 - val_loss: 31.1661\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 76.3704 - val_loss: 30.8270\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 73.8106 - val_loss: 29.2938\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 80.0722 - val_loss: 29.9387\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 76.2434 - val_loss: 30.3837\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 76.1702 - val_loss: 28.1681\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1567/1567 [==============================] - 0s 236us/step - loss: 79.1467 - val_loss: 29.6072\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 259us/step - loss: 77.2099 - val_loss: 32.6288\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 259us/step - loss: 74.9806 - val_loss: 28.9288\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 78.3733 - val_loss: 30.5916\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 72.9216 - val_loss: 29.9646\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 79.3390 - val_loss: 30.9564\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 260us/step - loss: 74.3436 - val_loss: 28.4377\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 74.0514 - val_loss: 31.9704\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 74.8358 - val_loss: 28.7054\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 73.5628 - val_loss: 30.8007\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 74.1734 - val_loss: 30.0994\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 75.4806 - val_loss: 30.2668\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 266us/step - loss: 73.4011 - val_loss: 30.3975\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 268us/step - loss: 75.7677 - val_loss: 30.1166\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 262us/step - loss: 74.8289 - val_loss: 32.1197\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 72.2947 - val_loss: 28.6232\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 74.8255 - val_loss: 34.1062\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 73.0383 - val_loss: 31.0927\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 78.4307 - val_loss: 34.6394\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 74.7069 - val_loss: 32.6421\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 72.3748 - val_loss: 30.1113\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 261us/step - loss: 76.1404 - val_loss: 28.6188\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 75.3288 - val_loss: 36.1273\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 80.5582 - val_loss: 31.6414\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 70.2885 - val_loss: 31.3980\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 70.2887 - val_loss: 29.5986\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 73.6573 - val_loss: 29.1751\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 71.8603 - val_loss: 34.6294\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 260us/step - loss: 72.2912 - val_loss: 30.8304\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 73.2278 - val_loss: 30.9095\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 72.9151 - val_loss: 30.3833\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 70.6348 - val_loss: 31.9937\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 78.6887 - val_loss: 33.5097\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 257us/step - loss: 78.9500 - val_loss: 30.6497\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 72.6649 - val_loss: 30.4426\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 72.5138 - val_loss: 29.7173\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 257us/step - loss: 73.3935 - val_loss: 29.7374\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 73.9912 - val_loss: 30.1611\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 74.2935 - val_loss: 29.1674\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 258us/step - loss: 71.4665 - val_loss: 29.4778\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 70.3814 - val_loss: 29.5014\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 70.0698 - val_loss: 27.7503\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 73.9128 - val_loss: 28.2950\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 70.7612 - val_loss: 30.3895\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 74.8152 - val_loss: 31.0768\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 74.1506 - val_loss: 29.6593\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 260us/step - loss: 68.2689 - val_loss: 29.0839\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 73.2519 - val_loss: 31.1200\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 65.3865 - val_loss: 29.7281\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 70.1069 - val_loss: 29.9123\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 71.3516 - val_loss: 28.2012\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 74.6625 - val_loss: 29.5755\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 71.8866 - val_loss: 31.2564\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 72.7250 - val_loss: 30.2588\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1567/1567 [==============================] - 0s 240us/step - loss: 67.4365 - val_loss: 28.4498\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 70.2062 - val_loss: 30.1716\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 234us/step - loss: 69.6080 - val_loss: 30.2446\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 66.9596 - val_loss: 29.9013\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 234us/step - loss: 68.8236 - val_loss: 27.7718\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 67.6003 - val_loss: 29.4562\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 67.2618 - val_loss: 29.0655\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 67.2976 - val_loss: 28.3739\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 67.9508 - val_loss: 30.3478\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 73.9327 - val_loss: 30.8152\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 65.8898 - val_loss: 27.9982\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 66.2096 - val_loss: 29.8624\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 64.1785 - val_loss: 29.6858\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 63.9658 - val_loss: 28.6307\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 63.3023 - val_loss: 28.2428\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 257us/step - loss: 73.6673 - val_loss: 29.4195\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 266us/step - loss: 66.8941 - val_loss: 27.8692\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 262us/step - loss: 66.4523 - val_loss: 28.0389\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 67.1834 - val_loss: 29.4090\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 69.0895 - val_loss: 29.1743\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 66.3349 - val_loss: 28.7899\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 63.5706 - val_loss: 28.4821\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 67.5327 - val_loss: 28.8598\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 257us/step - loss: 68.4480 - val_loss: 28.8719\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 66.0844 - val_loss: 28.0312\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 67.5409 - val_loss: 28.6546\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 68.6589 - val_loss: 29.9828\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 69.4325 - val_loss: 28.1825\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 64.6911 - val_loss: 28.3579\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 67.6535 - val_loss: 30.2977\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 260us/step - loss: 66.3202 - val_loss: 28.1301\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 70.1903 - val_loss: 30.9004\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 61.5189 - val_loss: 29.0493\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 64.3030 - val_loss: 27.7815\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 264us/step - loss: 62.7488 - val_loss: 30.6980\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 63.9091 - val_loss: 29.5694\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 65.4870 - val_loss: 29.3907\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 68.5559 - val_loss: 30.6817\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 68.6663 - val_loss: 28.5660\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 65.6337 - val_loss: 28.3544\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 66.3457 - val_loss: 27.9713\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 63.6857 - val_loss: 28.5354\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 64.3803 - val_loss: 28.9711\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 61.5473 - val_loss: 28.1059\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 60.8619 - val_loss: 27.6311\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 59.6451 - val_loss: 29.6420\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 62.5618 - val_loss: 29.1240\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 62.8073 - val_loss: 29.0822\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 57.2510 - val_loss: 29.2496\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 61.9347 - val_loss: 29.0259\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 65.1692 - val_loss: 28.9272\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 58.7368 - val_loss: 28.6354\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 61.6492 - val_loss: 29.1019\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 61.0512 - val_loss: 29.3376\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1567/1567 [==============================] - 0s 239us/step - loss: 62.1305 - val_loss: 27.5228\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 63.7428 - val_loss: 29.5411\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 64.0529 - val_loss: 28.0066\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 62.7634 - val_loss: 27.6071\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 62.1712 - val_loss: 30.4164\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 63.5390 - val_loss: 28.1315\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 65.1867 - val_loss: 28.1807\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 268us/step - loss: 66.2046 - val_loss: 28.2867\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 270us/step - loss: 63.4968 - val_loss: 27.7412\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 265us/step - loss: 62.8930 - val_loss: 27.8109\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 267us/step - loss: 64.7958 - val_loss: 30.2232\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 258us/step - loss: 65.7570 - val_loss: 27.0956\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 64.3517 - val_loss: 27.2950\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 278us/step - loss: 63.1630 - val_loss: 28.1199\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 67.2501 - val_loss: 27.6436\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 64.3693 - val_loss: 29.2075\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 60.1610 - val_loss: 28.9492\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 63.9850 - val_loss: 29.8197\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 60.9964 - val_loss: 28.2429\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 67.1747 - val_loss: 28.9867\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 60.4374 - val_loss: 28.5950\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 61.3691 - val_loss: 28.0431\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 62.2177 - val_loss: 28.3893\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 63.1954 - val_loss: 28.6953\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 61.2138 - val_loss: 28.4234\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 62.2884 - val_loss: 29.2488\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 59.7147 - val_loss: 30.1496\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 59.4022 - val_loss: 27.5265\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 63.1074 - val_loss: 28.1246\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 63.6145 - val_loss: 28.9500\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 62.4213 - val_loss: 27.8203\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 56.8550 - val_loss: 27.4535\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 62.6358 - val_loss: 28.2909\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 63.4622 - val_loss: 30.1629\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 64.1322 - val_loss: 27.5568\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 59.5322 - val_loss: 28.0546\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 60.6218 - val_loss: 27.4633\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 264us/step - loss: 58.8834 - val_loss: 28.6781\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 63.5521 - val_loss: 29.0104\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 58.4853 - val_loss: 27.8167\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 59.2121 - val_loss: 29.5732\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 62.4457 - val_loss: 27.5656\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 59.6166 - val_loss: 30.2382\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 61.5569 - val_loss: 27.9715\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 60.5245 - val_loss: 26.7477\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 60.2591 - val_loss: 26.9531\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 62.9332 - val_loss: 27.9143\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 62.9233 - val_loss: 26.2034\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 62.5517 - val_loss: 30.5178\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 61.2132 - val_loss: 27.9608\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 64.8367 - val_loss: 29.1471\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 66.3125 - val_loss: 27.6529\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 58.6760 - val_loss: 27.0491\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 60.6416 - val_loss: 28.1816\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1567/1567 [==============================] - 0s 250us/step - loss: 60.7452 - val_loss: 31.3191\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 62.9352 - val_loss: 27.4318\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 258us/step - loss: 62.3980 - val_loss: 29.3254\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 265us/step - loss: 63.3336 - val_loss: 27.0026\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 260us/step - loss: 61.4315 - val_loss: 29.7508\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 262us/step - loss: 59.4886 - val_loss: 26.8192\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 61.5742 - val_loss: 29.6779\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 266us/step - loss: 59.5830 - val_loss: 28.7187\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 284us/step - loss: 60.2488 - val_loss: 28.6135\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 60.6789 - val_loss: 27.0155\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 57.4328 - val_loss: 28.9413\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 60.8911 - val_loss: 29.0627\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 60.0470 - val_loss: 26.2563\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 261us/step - loss: 60.5724 - val_loss: 29.8214\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 263us/step - loss: 61.4488 - val_loss: 28.4214\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 60.4795 - val_loss: 31.6574\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 60.3019 - val_loss: 30.2301\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 265us/step - loss: 65.8713 - val_loss: 28.2431\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 57.6801 - val_loss: 29.3597\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 61.6738 - val_loss: 28.1662\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 63.7552 - val_loss: 28.1643\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 59.1435 - val_loss: 28.4200\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 61.3569 - val_loss: 28.3730\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 263us/step - loss: 58.2528 - val_loss: 27.3564\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 64.7692 - val_loss: 26.8537\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 57.9487 - val_loss: 28.6834\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 56.1201 - val_loss: 28.4532\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 62.3415 - val_loss: 27.7936\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 57.4603 - val_loss: 27.1616\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 62.8749 - val_loss: 27.7434\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 59.7291 - val_loss: 26.9217\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 57.5270 - val_loss: 28.3952\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 61.3154 - val_loss: 27.2157\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 58.8344 - val_loss: 28.1462\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 277us/step - loss: 56.2347 - val_loss: 27.8313\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 59.2482 - val_loss: 29.1130\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 62.8037 - val_loss: 28.1653\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 258us/step - loss: 57.0286 - val_loss: 28.3591\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 270us/step - loss: 57.1585 - val_loss: 29.1847\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 63.3996 - val_loss: 27.7092\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 265us/step - loss: 57.4048 - val_loss: 28.5980\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 271us/step - loss: 57.9430 - val_loss: 27.4885\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 59.2731 - val_loss: 27.1140\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 58.8839 - val_loss: 27.2069\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 59.5912 - val_loss: 27.3239\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 259us/step - loss: 62.3240 - val_loss: 27.2810\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 61.7731 - val_loss: 28.3065\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 61.5892 - val_loss: 28.3372\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 61.1007 - val_loss: 27.4000\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 62.7804 - val_loss: 30.3151\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 60.9753 - val_loss: 27.3338\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 60.2360 - val_loss: 27.6124\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 62.6880 - val_loss: 27.1145\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 58.0650 - val_loss: 29.0283\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1567/1567 [==============================] - 0s 239us/step - loss: 59.6005 - val_loss: 27.9194\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 58.6814 - val_loss: 27.1750\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 268us/step - loss: 58.4902 - val_loss: 28.4928\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 264us/step - loss: 61.6034 - val_loss: 26.3566\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 263us/step - loss: 61.7122 - val_loss: 28.2434\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 267us/step - loss: 60.0621 - val_loss: 28.5599\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 263us/step - loss: 57.7532 - val_loss: 28.0491\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 272us/step - loss: 57.3342 - val_loss: 28.5265\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 263us/step - loss: 60.6158 - val_loss: 27.8489\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 264us/step - loss: 57.3706 - val_loss: 26.5894\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 58.2646 - val_loss: 27.8347\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 57.4798 - val_loss: 28.3477\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 58.9348 - val_loss: 28.3282\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 58.1205 - val_loss: 27.4182\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 260us/step - loss: 58.5328 - val_loss: 28.0310\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 59.6942 - val_loss: 26.6967\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 61.2712 - val_loss: 28.1363\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 59.7232 - val_loss: 27.8625\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 235us/step - loss: 56.7484 - val_loss: 27.2455\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 58.8785 - val_loss: 27.1749\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 57.6993 - val_loss: 28.8741\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 62.8295 - val_loss: 28.2370\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 62.1743 - val_loss: 28.4353\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 56.8572 - val_loss: 26.4446\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 58.7496 - val_loss: 26.8043\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 54.1482 - val_loss: 29.6756\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 55.2657 - val_loss: 26.6336\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 60.2850 - val_loss: 30.7409\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 59.9762 - val_loss: 26.8958\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 58.7198 - val_loss: 27.9661\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 58.1123 - val_loss: 28.0241\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 57.8962 - val_loss: 30.2627\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 235us/step - loss: 57.9791 - val_loss: 29.7564\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 63.2918 - val_loss: 31.8923\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 63.0562 - val_loss: 29.4090\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 58.0335 - val_loss: 28.1131\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 60.1112 - val_loss: 27.7691\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 57.3090 - val_loss: 28.0497\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 267us/step - loss: 57.3087 - val_loss: 29.9897\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 54.4767 - val_loss: 28.7772\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 259us/step - loss: 57.7598 - val_loss: 28.9964\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 56.9302 - val_loss: 28.7905\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 57.3130 - val_loss: 27.9014\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 57.4375 - val_loss: 27.0906\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 235us/step - loss: 59.7828 - val_loss: 28.7235\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 55.3681 - val_loss: 26.7869\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 55.3224 - val_loss: 27.2938\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 55.8159 - val_loss: 28.6423\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 56.7184 - val_loss: 28.6102\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 235us/step - loss: 58.3139 - val_loss: 29.4373\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 56.7789 - val_loss: 30.5391\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 57.7465 - val_loss: 28.7516\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 53.9743 - val_loss: 28.4249\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 61.1839 - val_loss: 26.6573\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1567/1567 [==============================] - 0s 240us/step - loss: 54.1684 - val_loss: 26.8103\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 58.0153 - val_loss: 28.4389\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 280us/step - loss: 55.8257 - val_loss: 27.8437\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 278us/step - loss: 54.6652 - val_loss: 27.4371\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 60.8273 - val_loss: 30.2520\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 56.4245 - val_loss: 28.9309\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 57.8351 - val_loss: 27.3234\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 264us/step - loss: 55.9445 - val_loss: 27.2218\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 235us/step - loss: 56.8469 - val_loss: 28.6539\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 257us/step - loss: 57.3991 - val_loss: 27.9840\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 258us/step - loss: 57.1524 - val_loss: 27.4648\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 260us/step - loss: 57.1896 - val_loss: 28.5386\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 269us/step - loss: 52.0771 - val_loss: 27.7168\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 56.3551 - val_loss: 26.1276\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 56.2764 - val_loss: 27.3270\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 284us/step - loss: 54.8400 - val_loss: 26.7550\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 233us/step - loss: 55.6469 - val_loss: 28.0498\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 55.4876 - val_loss: 28.8684\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 235us/step - loss: 53.3269 - val_loss: 27.4404\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 54.3344 - val_loss: 27.1730\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 55.4697 - val_loss: 27.7354\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 59.0827 - val_loss: 28.6871\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 286us/step - loss: 55.9609 - val_loss: 27.0404\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 54.5503 - val_loss: 28.1934\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 266us/step - loss: 52.6538 - val_loss: 27.5072\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 62.4000 - val_loss: 28.3881\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 58.5035 - val_loss: 27.0069\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 58.9249 - val_loss: 27.2879\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 54.7714 - val_loss: 27.8830\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 57.9766 - val_loss: 26.8701\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 261us/step - loss: 55.0013 - val_loss: 28.4233\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 55.4278 - val_loss: 27.1141\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 262us/step - loss: 54.5429 - val_loss: 27.7781\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 260us/step - loss: 56.5266 - val_loss: 27.8398\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 54.5535 - val_loss: 28.6315\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 56.8886 - val_loss: 27.8074\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 52.2790 - val_loss: 30.1198\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 52.6804 - val_loss: 28.4356\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 56.2930 - val_loss: 27.5129\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 58.0802 - val_loss: 27.2496\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 56.5181 - val_loss: 28.9605\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 54.1139 - val_loss: 28.6129\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 56.4491 - val_loss: 27.4272\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 54.3644 - val_loss: 26.6727\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 54.3349 - val_loss: 27.5021\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 56.1020 - val_loss: 27.7224\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 55.8740 - val_loss: 27.2313\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 55.4166 - val_loss: 27.3617\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 51.3855 - val_loss: 30.2727\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 235us/step - loss: 55.0853 - val_loss: 27.8911\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 53.5632 - val_loss: 27.7580\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 55.4711 - val_loss: 27.9028\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 53.6878 - val_loss: 27.8714\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 54.1511 - val_loss: 27.0634\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1567/1567 [==============================] - 0s 250us/step - loss: 55.1999 - val_loss: 26.8861\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 54.2506 - val_loss: 28.2507\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 260us/step - loss: 55.8371 - val_loss: 26.9208\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 57.9635 - val_loss: 27.1339\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 233us/step - loss: 56.9896 - val_loss: 26.3343\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 260us/step - loss: 56.5126 - val_loss: 26.7790\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 268us/step - loss: 53.9472 - val_loss: 28.2573\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 268us/step - loss: 55.5501 - val_loss: 27.0673\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 57.8916 - val_loss: 25.9896\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 51.6502 - val_loss: 28.7377\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 257us/step - loss: 52.7444 - val_loss: 26.4941\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 51.7495 - val_loss: 26.9298\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 261us/step - loss: 50.2061 - val_loss: 26.8190\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 56.0643 - val_loss: 27.4980\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 54.6288 - val_loss: 28.0145\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 54.1526 - val_loss: 29.2260\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 54.0258 - val_loss: 28.4762\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 54.9892 - val_loss: 28.8521\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 56.0346 - val_loss: 27.4419\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 54.9149 - val_loss: 26.8172\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 54.9673 - val_loss: 27.6655\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 232us/step - loss: 54.8901 - val_loss: 27.2807\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 50.0253 - val_loss: 26.9671\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 57.4348 - val_loss: 27.4317\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 265us/step - loss: 53.1830 - val_loss: 28.3748\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 258us/step - loss: 53.8480 - val_loss: 27.5402\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 55.1075 - val_loss: 26.6259\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 56.2450 - val_loss: 28.9417\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 52.0719 - val_loss: 28.9627\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 235us/step - loss: 54.0107 - val_loss: 27.6825\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 263us/step - loss: 54.3255 - val_loss: 29.5509\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 53.3277 - val_loss: 26.9343\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 55.0171 - val_loss: 27.0261\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 54.8802 - val_loss: 27.1015\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 54.8769 - val_loss: 27.2348\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 52.7205 - val_loss: 27.1704\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 54.3005 - val_loss: 26.8745\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 54.6037 - val_loss: 25.8941\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 52.0405 - val_loss: 31.8128\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 54.1814 - val_loss: 26.5980\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 53.3779 - val_loss: 28.5672\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 54.0279 - val_loss: 28.1002\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 51.9036 - val_loss: 27.2845\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 53.9825 - val_loss: 26.8746\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 51.2808 - val_loss: 28.8162\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 234us/step - loss: 51.2011 - val_loss: 26.7905\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 55.9870 - val_loss: 31.1763\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 61.7305 - val_loss: 28.4814\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 55.0498 - val_loss: 29.2694\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 53.6357 - val_loss: 30.2929\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 55.3266 - val_loss: 27.8223\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 54.5230 - val_loss: 28.9106\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 52.4869 - val_loss: 30.7464\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 56.7495 - val_loss: 27.8138\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1567/1567 [==============================] - 0s 265us/step - loss: 51.8975 - val_loss: 28.7021\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 52.7434 - val_loss: 26.8372\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 53.9727 - val_loss: 27.0925\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 265us/step - loss: 53.1639 - val_loss: 28.2519\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 57.3621 - val_loss: 28.9494\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 55.3910 - val_loss: 28.1371\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 54.1635 - val_loss: 26.5556\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 257us/step - loss: 53.5752 - val_loss: 27.3941\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 54.4342 - val_loss: 28.4817\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 277us/step - loss: 53.4188 - val_loss: 27.5857\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 264us/step - loss: 52.4233 - val_loss: 29.0062\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 48.3182 - val_loss: 27.3154\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 267us/step - loss: 50.3170 - val_loss: 28.6498\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 51.6661 - val_loss: 28.2629\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 51.9174 - val_loss: 29.0949\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 52.6083 - val_loss: 28.4997\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 54.5689 - val_loss: 27.0414\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 259us/step - loss: 53.4241 - val_loss: 28.0524\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 51.6633 - val_loss: 28.9985\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 54.0070 - val_loss: 28.3685\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 264us/step - loss: 53.8236 - val_loss: 27.0722\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 50.9164 - val_loss: 26.9158\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 58.6307 - val_loss: 27.5427\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 55.2046 - val_loss: 27.6845\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 51.3340 - val_loss: 26.9101\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 54.4847 - val_loss: 27.3441\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 52.6642 - val_loss: 28.9484\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 52.7037 - val_loss: 28.2595\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 257us/step - loss: 51.1763 - val_loss: 28.3326\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 56.4106 - val_loss: 28.2777\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 259us/step - loss: 57.7217 - val_loss: 28.5715\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 50.9681 - val_loss: 26.9489\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 51.9029 - val_loss: 26.7747\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 52.8149 - val_loss: 28.4088\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 51.6707 - val_loss: 27.4927\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 51.1010 - val_loss: 28.4969\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 54.2574 - val_loss: 28.2739\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 49.2393 - val_loss: 28.0891\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 50.2645 - val_loss: 27.7428\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 50.4029 - val_loss: 28.2709\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 49.8787 - val_loss: 28.3005\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 54.0994 - val_loss: 27.7559\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 53.6158 - val_loss: 28.0961\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 52.1682 - val_loss: 28.0972\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 56.3151 - val_loss: 28.0823\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 50.7747 - val_loss: 28.0260\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 52.5983 - val_loss: 27.4029\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 258us/step - loss: 54.0026 - val_loss: 29.2383\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 49.5494 - val_loss: 28.7086\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 50.9597 - val_loss: 27.9380\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 50.5620 - val_loss: 27.7197\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 51.5979 - val_loss: 27.0301\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 48.1202 - val_loss: 28.6862\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 50.5485 - val_loss: 29.7037\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1567/1567 [==============================] - 0s 246us/step - loss: 51.2928 - val_loss: 28.3787\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 51.6346 - val_loss: 26.8933\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 49.7495 - val_loss: 28.0596\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 49.6625 - val_loss: 28.8780\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 52.7680 - val_loss: 27.8586\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 257us/step - loss: 53.0571 - val_loss: 29.0194\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 275us/step - loss: 55.0150 - val_loss: 29.0823\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 280us/step - loss: 51.2693 - val_loss: 28.0863\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 271us/step - loss: 49.3310 - val_loss: 27.8166\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 263us/step - loss: 52.2588 - val_loss: 29.7034\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 274us/step - loss: 50.6205 - val_loss: 26.5322\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 261us/step - loss: 49.7111 - val_loss: 26.9492\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 54.1113 - val_loss: 27.4517\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 264us/step - loss: 49.1072 - val_loss: 27.5951\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 53.0306 - val_loss: 26.9027\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 50.0733 - val_loss: 28.3285\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 50.7747 - val_loss: 28.1221\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 50.2547 - val_loss: 27.7593\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 50.6486 - val_loss: 28.3107\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 49.2756 - val_loss: 27.6407\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 50.0980 - val_loss: 26.9618\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 51.6918 - val_loss: 27.1567\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 51.2187 - val_loss: 27.5670\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 50.2802 - val_loss: 29.3311\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 50.4646 - val_loss: 26.4810\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 50.0506 - val_loss: 26.1484\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 258us/step - loss: 51.9126 - val_loss: 28.0877\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 267us/step - loss: 52.1064 - val_loss: 27.3948\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 263us/step - loss: 50.8446 - val_loss: 26.3357\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 50.7547 - val_loss: 28.0651\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 50.0600 - val_loss: 27.8552\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 51.9940 - val_loss: 26.6676\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 52.7126 - val_loss: 26.6395\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 233us/step - loss: 50.6334 - val_loss: 26.4438\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 234us/step - loss: 53.4822 - val_loss: 29.6082\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 51.3394 - val_loss: 27.5275\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 51.5435 - val_loss: 29.0942\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 49.7897 - val_loss: 28.2776\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 53.1432 - val_loss: 28.1568\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 51.9906 - val_loss: 28.0165\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 51.4065 - val_loss: 26.3020\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 49.1191 - val_loss: 27.1695\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 50.7148 - val_loss: 28.7881\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 48.5550 - val_loss: 26.4189\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 54.2123 - val_loss: 27.2423\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 48.4340 - val_loss: 28.5414\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 52.1428 - val_loss: 28.1682\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 49.1397 - val_loss: 27.3676\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 48.4569 - val_loss: 26.9936\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 234us/step - loss: 49.5579 - val_loss: 28.1749\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 257us/step - loss: 50.8940 - val_loss: 28.2698\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 266us/step - loss: 52.7047 - val_loss: 27.1828\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 47.5447 - val_loss: 27.8429\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 50.0102 - val_loss: 26.9379\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1567/1567 [==============================] - 0s 234us/step - loss: 51.9524 - val_loss: 29.0071\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 49.0883 - val_loss: 26.7520\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 50.1356 - val_loss: 27.2647\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 49.5790 - val_loss: 30.2645\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 53.7722 - val_loss: 26.1019\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 48.6463 - val_loss: 27.0586\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 54.0931 - val_loss: 26.8444\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 271us/step - loss: 49.8061 - val_loss: 27.1961\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 262us/step - loss: 47.6261 - val_loss: 27.8739\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 268us/step - loss: 50.1777 - val_loss: 28.7682\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 258us/step - loss: 50.1508 - val_loss: 27.0964\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 268us/step - loss: 48.5758 - val_loss: 26.9021\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 272us/step - loss: 52.3588 - val_loss: 27.8003\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 48.0905 - val_loss: 27.9170\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 259us/step - loss: 51.7630 - val_loss: 26.9377\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 258us/step - loss: 48.6402 - val_loss: 28.1056\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 52.2603 - val_loss: 26.4440\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 47.8293 - val_loss: 25.9087\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 51.3328 - val_loss: 26.1253\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 46.3899 - val_loss: 26.7395\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 51.6558 - val_loss: 26.7545\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 47.8291 - val_loss: 28.2536\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 51.4601 - val_loss: 26.6251\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 234us/step - loss: 47.8408 - val_loss: 27.6318\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 276us/step - loss: 51.5206 - val_loss: 27.4079\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 51.8069 - val_loss: 29.4455\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 46.7376 - val_loss: 28.0239\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 50.5090 - val_loss: 27.5298\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 235us/step - loss: 51.7703 - val_loss: 27.4616\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 50.5282 - val_loss: 27.6248\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 53.0509 - val_loss: 27.7020\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 48.4891 - val_loss: 27.5732\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 50.7301 - val_loss: 26.6863\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 277us/step - loss: 49.0367 - val_loss: 27.0031\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 47.1165 - val_loss: 28.5942\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 48.6758 - val_loss: 27.0308\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 235us/step - loss: 50.4934 - val_loss: 26.6996\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 46.5180 - val_loss: 28.4920\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 51.3247 - val_loss: 27.1976\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 48.0515 - val_loss: 26.7103\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 47.7937 - val_loss: 26.9650\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 48.1382 - val_loss: 27.5325\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 50.4698 - val_loss: 28.5178\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 51.1372 - val_loss: 26.6306\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 48.3565 - val_loss: 26.4160\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 272us/step - loss: 43.8255 - val_loss: 26.7687\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 48.1119 - val_loss: 27.8614\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 233us/step - loss: 48.7452 - val_loss: 27.2714\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 49.7193 - val_loss: 27.5230\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 45.5601 - val_loss: 27.4111\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 49.3351 - val_loss: 27.4455\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 46.9501 - val_loss: 28.1751\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 46.5977 - val_loss: 26.6564\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 46.7122 - val_loss: 27.0736\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1567/1567 [==============================] - 0s 233us/step - loss: 48.7652 - val_loss: 27.2243\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 49.2302 - val_loss: 26.7604\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 45.9964 - val_loss: 27.4196\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 231us/step - loss: 49.4922 - val_loss: 27.5689\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 49.4015 - val_loss: 27.0367\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 277us/step - loss: 46.9481 - val_loss: 27.3865\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 276us/step - loss: 46.2408 - val_loss: 27.9935\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 265us/step - loss: 48.2895 - val_loss: 26.7370\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 310us/step - loss: 49.4760 - val_loss: 29.0635\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 46.4204 - val_loss: 27.1553\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 46.6657 - val_loss: 27.7476\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 235us/step - loss: 50.3033 - val_loss: 28.8843\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 268us/step - loss: 48.5592 - val_loss: 27.2792\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 261us/step - loss: 46.1679 - val_loss: 27.5907\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 263us/step - loss: 49.7312 - val_loss: 27.2515\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 259us/step - loss: 45.6185 - val_loss: 27.8430\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 258us/step - loss: 49.2984 - val_loss: 27.4075\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 47.0115 - val_loss: 26.4618\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 46.7329 - val_loss: 26.2726\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 259us/step - loss: 43.6464 - val_loss: 27.4733\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 267us/step - loss: 45.0357 - val_loss: 29.3847\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 47.0919 - val_loss: 28.4530\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 45.2910 - val_loss: 27.4097\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 44.3505 - val_loss: 28.0074\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 260us/step - loss: 48.5301 - val_loss: 27.0724\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 260us/step - loss: 47.2215 - val_loss: 27.6229\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 44.9563 - val_loss: 27.5123\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 47.9529 - val_loss: 28.3379\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 48.2450 - val_loss: 27.2391\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 49.4837 - val_loss: 26.9197\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 232us/step - loss: 47.0866 - val_loss: 28.3166\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 47.9298 - val_loss: 27.6615\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 49.2751 - val_loss: 25.9155\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 47.5864 - val_loss: 26.9719\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 45.1763 - val_loss: 26.7325\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 47.0405 - val_loss: 26.8390\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 233us/step - loss: 44.0010 - val_loss: 27.9421\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 288us/step - loss: 45.4090 - val_loss: 28.0220\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 46.4642 - val_loss: 27.1462\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 45.0471 - val_loss: 26.5764\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 48.3255 - val_loss: 27.8212\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 46.4478 - val_loss: 26.4980\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 49.4389 - val_loss: 26.8533\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 45.4268 - val_loss: 27.2139\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 45.9064 - val_loss: 26.5299\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 46.2089 - val_loss: 26.6523\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 46.3118 - val_loss: 27.5081\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 45.7971 - val_loss: 25.4501\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 43.8366 - val_loss: 26.1879\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 49.3348 - val_loss: 29.5165\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 47.3241 - val_loss: 27.4341\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 47.4816 - val_loss: 26.7173\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 43.8060 - val_loss: 26.6024\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 45.2648 - val_loss: 27.9392\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1567/1567 [==============================] - 0s 233us/step - loss: 46.5736 - val_loss: 27.5848\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 277us/step - loss: 45.4686 - val_loss: 27.6635\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 279us/step - loss: 46.3005 - val_loss: 26.7984\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 278us/step - loss: 43.7478 - val_loss: 29.1897\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 269us/step - loss: 47.2960 - val_loss: 27.3832\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 298us/step - loss: 45.1933 - val_loss: 27.0236\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 259us/step - loss: 42.7996 - val_loss: 26.9917\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 44.1684 - val_loss: 28.1351\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 48.3387 - val_loss: 27.5006\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 269us/step - loss: 44.2540 - val_loss: 28.2279\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 264us/step - loss: 48.4057 - val_loss: 29.3549\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 269us/step - loss: 47.1161 - val_loss: 27.5181\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 257us/step - loss: 44.7519 - val_loss: 27.1715\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 48.6499 - val_loss: 26.0546\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 260us/step - loss: 45.5181 - val_loss: 27.5084\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 47.4060 - val_loss: 27.3194\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 47.8845 - val_loss: 26.5919\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 46.3116 - val_loss: 26.6829\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 44.1883 - val_loss: 28.0080\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 45.2395 - val_loss: 27.2494\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 47.2542 - val_loss: 27.6276\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 43.9714 - val_loss: 27.9608\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 44.9261 - val_loss: 27.6761\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 45.5287 - val_loss: 27.4640\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 45.6309 - val_loss: 27.2976\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 47.4952 - val_loss: 27.9443\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 46.8577 - val_loss: 29.3078\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 43.9201 - val_loss: 28.3171\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 46.6318 - val_loss: 28.9048\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 46.2814 - val_loss: 28.1025\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 46.4724 - val_loss: 28.1729\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 46.4156 - val_loss: 26.7719\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 45.5496 - val_loss: 27.6961\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 45.4574 - val_loss: 27.2567\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 44.7811 - val_loss: 26.9207\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 45.0844 - val_loss: 27.8769\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 44.6277 - val_loss: 26.9833\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 261us/step - loss: 47.4922 - val_loss: 29.1479\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 45.3133 - val_loss: 29.7351\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 44.3927 - val_loss: 28.1307\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 45.9980 - val_loss: 27.1917\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 43.3518 - val_loss: 27.8179\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 44.5991 - val_loss: 27.6798\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 44.9672 - val_loss: 28.2168\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 43.7221 - val_loss: 27.4013\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 43.6687 - val_loss: 26.8562\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 45.9784 - val_loss: 28.3119\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 46.1871 - val_loss: 28.1100\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 44.2116 - val_loss: 28.7935\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 235us/step - loss: 45.0896 - val_loss: 29.2496\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 44.3167 - val_loss: 27.7549\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 44.8754 - val_loss: 26.8278\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 44.9462 - val_loss: 26.7639\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 44.8051 - val_loss: 27.9137\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1567/1567 [==============================] - 0s 237us/step - loss: 47.4678 - val_loss: 27.6304\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 235us/step - loss: 46.7185 - val_loss: 28.4404\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 233us/step - loss: 45.6666 - val_loss: 27.7486\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 266us/step - loss: 45.4652 - val_loss: 29.2687\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 46.4511 - val_loss: 27.9052\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 268us/step - loss: 47.6254 - val_loss: 27.0459\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 270us/step - loss: 46.7017 - val_loss: 27.9645\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 45.8010 - val_loss: 27.4701\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 264us/step - loss: 47.7516 - val_loss: 27.4830\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 268us/step - loss: 45.7483 - val_loss: 25.9693\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 266us/step - loss: 43.9409 - val_loss: 27.4463\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 258us/step - loss: 43.0444 - val_loss: 27.4835\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 46.3101 - val_loss: 27.5108\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 45.0855 - val_loss: 27.0474\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 265us/step - loss: 45.6621 - val_loss: 27.4625\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 45.7033 - val_loss: 27.9119\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 287us/step - loss: 48.4021 - val_loss: 27.3170\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 43.9740 - val_loss: 26.6318\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 44.3712 - val_loss: 27.7370\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 45.5957 - val_loss: 28.1133\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 45.3612 - val_loss: 27.1925\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 45.3677 - val_loss: 27.6236\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 43.6422 - val_loss: 27.9725\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 267us/step - loss: 43.1681 - val_loss: 26.5781\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 46.0029 - val_loss: 27.3859\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 44.2851 - val_loss: 27.3824\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 261us/step - loss: 45.3902 - val_loss: 28.0787\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 45.2990 - val_loss: 27.7991\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 42.7539 - val_loss: 27.6839\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 265us/step - loss: 43.6041 - val_loss: 28.0478\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 46.2185 - val_loss: 27.3263\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 41.1455 - val_loss: 27.0503\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 42.0448 - val_loss: 27.2598\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 43.2827 - val_loss: 28.4380\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 45.3880 - val_loss: 27.1372\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 45.0299 - val_loss: 27.5213\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 43.8674 - val_loss: 27.6042\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 235us/step - loss: 47.3106 - val_loss: 27.6819\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 48.0692 - val_loss: 27.6850\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 44.4429 - val_loss: 27.4306\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 45.1089 - val_loss: 28.2535\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 46.1816 - val_loss: 27.6423\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 41.2616 - val_loss: 26.5381\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 44.8308 - val_loss: 26.3943\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 43.4431 - val_loss: 27.4840\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 235us/step - loss: 46.7790 - val_loss: 28.1983\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 44.9145 - val_loss: 27.0639\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 44.9833 - val_loss: 26.7909\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 46.0787 - val_loss: 27.7528\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 234us/step - loss: 44.5610 - val_loss: 27.7179\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 44.7530 - val_loss: 29.4266\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 44.9485 - val_loss: 26.5899\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 44.4064 - val_loss: 26.6608\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 43.2847 - val_loss: 27.2471\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1567/1567 [==============================] - 0s 242us/step - loss: 44.0389 - val_loss: 26.9923\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 44.0001 - val_loss: 29.5641\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 270us/step - loss: 44.3442 - val_loss: 27.3225\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 274us/step - loss: 43.4768 - val_loss: 27.5874\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 264us/step - loss: 43.7505 - val_loss: 27.2479\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 257us/step - loss: 44.0218 - val_loss: 27.7998\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 43.8749 - val_loss: 27.9342\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 44.6224 - val_loss: 28.7339\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 42.9203 - val_loss: 28.0837\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 44.7582 - val_loss: 27.4685\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 44.3980 - val_loss: 27.9114\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 264us/step - loss: 43.5783 - val_loss: 27.1175\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 43.7172 - val_loss: 27.7918\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 261us/step - loss: 43.5344 - val_loss: 26.9763\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 236us/step - loss: 45.7197 - val_loss: 28.4045\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 46.1151 - val_loss: 26.5669\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 43.8558 - val_loss: 27.7535\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 45.3162 - val_loss: 27.5865\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 41.7185 - val_loss: 26.3928\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 40.9708 - val_loss: 28.2329\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 43.5747 - val_loss: 26.3073\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 259us/step - loss: 45.4901 - val_loss: 27.4377\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 44.4277 - val_loss: 26.3803\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 43.4353 - val_loss: 26.0128\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 235us/step - loss: 41.7082 - val_loss: 26.7806\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 266us/step - loss: 44.0024 - val_loss: 25.9282\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 267us/step - loss: 43.3121 - val_loss: 26.4759\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 259us/step - loss: 42.6572 - val_loss: 27.5179\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 43.6256 - val_loss: 27.0304\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 45.7087 - val_loss: 28.7578\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 46.2292 - val_loss: 29.0369\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 42.9219 - val_loss: 27.3569\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 42.2402 - val_loss: 27.9673\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 43.0416 - val_loss: 29.3751\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 42.2736 - val_loss: 27.5310\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 45.3396 - val_loss: 28.5380\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 258us/step - loss: 43.9930 - val_loss: 27.3151\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 42.9191 - val_loss: 27.9094\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 43.8927 - val_loss: 29.6546\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 44.4917 - val_loss: 27.3125\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 43.6817 - val_loss: 28.3325\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 44.0030 - val_loss: 28.5679\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 44.7309 - val_loss: 27.0450\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 43.3268 - val_loss: 27.5558\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 44.5399 - val_loss: 26.2543\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 41.7024 - val_loss: 25.9307\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 41.3544 - val_loss: 26.2614\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 42.8719 - val_loss: 27.5477\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 46.0758 - val_loss: 26.7748\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 43.3941 - val_loss: 27.2443\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 41.4684 - val_loss: 27.6715\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 45.1058 - val_loss: 28.0184\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 42.2399 - val_loss: 27.6203\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 232us/step - loss: 44.4628 - val_loss: 26.2356\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1567/1567 [==============================] - 0s 260us/step - loss: 43.3688 - val_loss: 27.7125\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 43.5809 - val_loss: 26.9928\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 260us/step - loss: 43.8301 - val_loss: 27.0683\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 42.8654 - val_loss: 26.6709\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 42.6016 - val_loss: 26.1307\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 261us/step - loss: 43.1697 - val_loss: 26.8891\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 263us/step - loss: 45.7035 - val_loss: 27.9914\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 45.5224 - val_loss: 27.4458\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 257us/step - loss: 42.3315 - val_loss: 27.9266\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 42.2813 - val_loss: 27.2919\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 259us/step - loss: 42.6012 - val_loss: 27.4924\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 43.1194 - val_loss: 27.0403\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 41.8721 - val_loss: 27.0585\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 44.5094 - val_loss: 29.9723\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 41.5156 - val_loss: 29.4238\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 281us/step - loss: 44.4046 - val_loss: 25.8021\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 43.2924 - val_loss: 28.4781\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 44.2178 - val_loss: 28.2738\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 258us/step - loss: 45.3841 - val_loss: 27.3658\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 272us/step - loss: 43.3478 - val_loss: 27.1981\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 43.1353 - val_loss: 27.9418\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 44.8578 - val_loss: 25.9905\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 42.9206 - val_loss: 25.4383\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 43.1307 - val_loss: 25.6539\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 40.9300 - val_loss: 27.4446\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 42.6402 - val_loss: 27.5872\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 235us/step - loss: 43.0764 - val_loss: 26.2805\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 43.4657 - val_loss: 26.3331\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 43.1917 - val_loss: 28.3300\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 40.5252 - val_loss: 27.2561\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 43.9173 - val_loss: 27.0406\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 45.0906 - val_loss: 26.4732\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 42.4910 - val_loss: 27.5537\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 266us/step - loss: 42.2505 - val_loss: 26.7504\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 42.3090 - val_loss: 28.7756\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 43.8650 - val_loss: 26.2776\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 43.4246 - val_loss: 26.8071\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 41.2322 - val_loss: 28.6438\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 44.5958 - val_loss: 27.4897\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 43.1210 - val_loss: 26.9758\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 43.3584 - val_loss: 26.9591\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 42.3717 - val_loss: 27.3962\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 244us/step - loss: 42.8912 - val_loss: 27.5963\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 42.0250 - val_loss: 26.5645\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 43.3812 - val_loss: 26.6606\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 237us/step - loss: 42.4015 - val_loss: 26.6992\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 43.8574 - val_loss: 26.1316\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 234us/step - loss: 40.5557 - val_loss: 27.4454\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 40.7336 - val_loss: 26.7076\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 235us/step - loss: 41.3842 - val_loss: 26.6259\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 234us/step - loss: 43.4242 - val_loss: 27.5859\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 41.7652 - val_loss: 27.1433\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 40.8242 - val_loss: 28.1506\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 234us/step - loss: 40.9215 - val_loss: 28.2509\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1567/1567 [==============================] - 0s 244us/step - loss: 42.0762 - val_loss: 28.2068\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 41.3888 - val_loss: 26.9624\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 233us/step - loss: 44.0807 - val_loss: 27.2672\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 40.7926 - val_loss: 26.9911\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 235us/step - loss: 42.9134 - val_loss: 28.8428\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 231us/step - loss: 43.1085 - val_loss: 28.1985\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 42.9954 - val_loss: 27.4251\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 41.6764 - val_loss: 27.4231\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 260us/step - loss: 42.0122 - val_loss: 27.0192\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 238us/step - loss: 40.5478 - val_loss: 27.3608\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 235us/step - loss: 44.4394 - val_loss: 27.2155\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 266us/step - loss: 43.6835 - val_loss: 28.3069\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 265us/step - loss: 40.8540 - val_loss: 28.7028\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 267us/step - loss: 42.1153 - val_loss: 28.9653\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 267us/step - loss: 41.4824 - val_loss: 26.8369\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 295us/step - loss: 41.0164 - val_loss: 27.3421\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 44.6730 - val_loss: 28.0822\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 42.3918 - val_loss: 26.5468\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 261us/step - loss: 42.2810 - val_loss: 26.3473\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 271us/step - loss: 44.0815 - val_loss: 26.9021\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 40.5156 - val_loss: 27.1311\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 41.3313 - val_loss: 28.2630\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 257us/step - loss: 44.4126 - val_loss: 31.0820\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 258us/step - loss: 42.3798 - val_loss: 28.5567\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 42.0482 - val_loss: 27.7675\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 42.2033 - val_loss: 27.7507\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 261us/step - loss: 43.1164 - val_loss: 26.5755\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 260us/step - loss: 43.3432 - val_loss: 26.7700\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 263us/step - loss: 40.6294 - val_loss: 26.9435\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 277us/step - loss: 43.6981 - val_loss: 26.7219\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 41.3290 - val_loss: 26.4559\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 42.2132 - val_loss: 26.9842\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 276us/step - loss: 43.7611 - val_loss: 25.9233\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 268us/step - loss: 40.4566 - val_loss: 27.0110\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 42.5941 - val_loss: 28.2463\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 45.4213 - val_loss: 25.5695\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 42.1851 - val_loss: 26.6589\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 42.1278 - val_loss: 28.4773\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 271us/step - loss: 41.4590 - val_loss: 27.7168\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 42.5873 - val_loss: 26.7320\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 43.1297 - val_loss: 28.8583\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 257us/step - loss: 42.4352 - val_loss: 27.3013\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 257us/step - loss: 45.1842 - val_loss: 26.4386\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 43.9382 - val_loss: 27.2938\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 270us/step - loss: 40.7204 - val_loss: 29.1300\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 262us/step - loss: 42.2174 - val_loss: 27.9893\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 42.3853 - val_loss: 28.8757\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 43.0670 - val_loss: 29.5053\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 281us/step - loss: 42.3474 - val_loss: 28.2275\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 41.9399 - val_loss: 28.1491\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 43.5335 - val_loss: 26.7106\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 40.4674 - val_loss: 27.9086\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 43.1263 - val_loss: 27.0294\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 262us/step - loss: 42.9709 - val_loss: 28.7245\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1567/1567 [==============================] - 0s 241us/step - loss: 43.2531 - val_loss: 26.7655\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 42.8666 - val_loss: 27.4313\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 39.0871 - val_loss: 27.8335\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 257us/step - loss: 42.6057 - val_loss: 27.3126\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 264us/step - loss: 42.5684 - val_loss: 26.9257\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 266us/step - loss: 41.8421 - val_loss: 27.0348\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 262us/step - loss: 43.3752 - val_loss: 26.8893\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 41.5035 - val_loss: 26.7900\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 264us/step - loss: 41.9102 - val_loss: 27.6838\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 258us/step - loss: 43.2639 - val_loss: 28.8334\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 41.0183 - val_loss: 27.9955\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 41.4596 - val_loss: 27.7900\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 41.4601 - val_loss: 27.4461\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 42.1224 - val_loss: 27.7594\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 40.6252 - val_loss: 28.3479\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 40.8671 - val_loss: 27.1385\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 275us/step - loss: 40.3920 - val_loss: 28.0273\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 41.2317 - val_loss: 27.6015\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 257us/step - loss: 38.7432 - val_loss: 27.1806\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 40.9896 - val_loss: 28.2990\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 40.8635 - val_loss: 28.6886\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 43.6451 - val_loss: 28.6844\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 41.4327 - val_loss: 27.6713\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 40.1087 - val_loss: 28.2928\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 265us/step - loss: 40.6321 - val_loss: 27.5372\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 39.3303 - val_loss: 27.4720\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 42.1246 - val_loss: 29.1494\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 263us/step - loss: 39.2530 - val_loss: 28.4255\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 268us/step - loss: 42.4008 - val_loss: 28.0615\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 41.2663 - val_loss: 27.1289\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 261us/step - loss: 41.2761 - val_loss: 29.7214\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 259us/step - loss: 42.3011 - val_loss: 28.1566\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 41.0502 - val_loss: 29.3624\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 41.8179 - val_loss: 28.9057\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 41.2304 - val_loss: 28.6675\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 42.2716 - val_loss: 28.3392\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 259us/step - loss: 38.4372 - val_loss: 28.6627\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 41.6310 - val_loss: 28.0367\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 40.9686 - val_loss: 27.1391\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 38.9542 - val_loss: 27.8322\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 44.1510 - val_loss: 28.8970\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 42.7347 - val_loss: 29.2597\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 41.6680 - val_loss: 28.3732\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 45.4235 - val_loss: 29.7718\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 38.7646 - val_loss: 28.5004\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 42.6090 - val_loss: 28.3382\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 39.3539 - val_loss: 26.5947\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 42.4125 - val_loss: 28.4740\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 40.3093 - val_loss: 27.8547\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 38.9538 - val_loss: 27.5345\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 40.3249 - val_loss: 28.0381\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 259us/step - loss: 40.9832 - val_loss: 29.1684\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 43.2340 - val_loss: 28.3856\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 41.1229 - val_loss: 29.5314\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1567/1567 [==============================] - 0s 250us/step - loss: 38.5036 - val_loss: 28.5520\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 243us/step - loss: 39.7651 - val_loss: 29.3185\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 262us/step - loss: 40.7409 - val_loss: 27.8251\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 41.1844 - val_loss: 27.1740\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 38.2582 - val_loss: 28.7344\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 39.0854 - val_loss: 27.1967\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 41.4698 - val_loss: 26.0287\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 40.6074 - val_loss: 27.9086\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 36.8311 - val_loss: 27.7008\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 37.9926 - val_loss: 27.3333\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 39.2956 - val_loss: 27.8139\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 260us/step - loss: 40.2789 - val_loss: 27.9873\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 273us/step - loss: 38.3657 - val_loss: 27.3491\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 39.3028 - val_loss: 27.0435\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 41.9846 - val_loss: 27.2712\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 41.8742 - val_loss: 27.7746\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 40.5563 - val_loss: 31.2183\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 269us/step - loss: 38.9574 - val_loss: 27.9848\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 41.1911 - val_loss: 27.3011\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 39.0171 - val_loss: 26.7977\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 40.3004 - val_loss: 28.0689\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 40.8373 - val_loss: 27.9221\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 262us/step - loss: 40.9014 - val_loss: 27.9400\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 260us/step - loss: 41.7460 - val_loss: 29.2938\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 260us/step - loss: 38.6711 - val_loss: 28.0270\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 38.1869 - val_loss: 27.1012\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 41.7226 - val_loss: 28.4117\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 264us/step - loss: 40.0891 - val_loss: 29.6295\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 41.4059 - val_loss: 27.7912\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 41.4486 - val_loss: 26.6938\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 40.6429 - val_loss: 28.3265\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 39.9870 - val_loss: 27.6734\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 257us/step - loss: 35.3596 - val_loss: 26.8235\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 39.0111 - val_loss: 27.5248\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 40.2869 - val_loss: 28.4090\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 260us/step - loss: 40.9190 - val_loss: 28.8332\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 40.8522 - val_loss: 29.0029\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 38.6044 - val_loss: 28.3653\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 39.4038 - val_loss: 27.5917\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 40.8786 - val_loss: 28.2830\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 41.6574 - val_loss: 27.7164\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 39.4008 - val_loss: 28.6045\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 39.6699 - val_loss: 28.0099\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 39.3518 - val_loss: 28.2218\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 40.6643 - val_loss: 28.6059\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 267us/step - loss: 39.8125 - val_loss: 31.3283\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 41.8762 - val_loss: 28.2093\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 41.3030 - val_loss: 27.8642\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 38.5271 - val_loss: 26.8081\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 38.8514 - val_loss: 26.8753\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 262us/step - loss: 38.9213 - val_loss: 28.2901\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 39.2650 - val_loss: 27.5041\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 39.7978 - val_loss: 28.4637\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 40.0110 - val_loss: 28.4547\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1567/1567 [==============================] - 0s 246us/step - loss: 39.7253 - val_loss: 28.5641\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 259us/step - loss: 38.0049 - val_loss: 29.7738\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 275us/step - loss: 38.5447 - val_loss: 28.9590\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 276us/step - loss: 41.0873 - val_loss: 28.5748\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 262us/step - loss: 39.5261 - val_loss: 29.4925\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 261us/step - loss: 39.9239 - val_loss: 28.5046\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 263us/step - loss: 38.6323 - val_loss: 28.9655\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 284us/step - loss: 38.6864 - val_loss: 28.3190\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 274us/step - loss: 42.2024 - val_loss: 29.1256\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 37.2060 - val_loss: 27.4249\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 301us/step - loss: 40.2996 - val_loss: 27.6905\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 40.1140 - val_loss: 30.2237\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 39.8662 - val_loss: 27.9485\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 40.1903 - val_loss: 28.2717\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 39.5151 - val_loss: 28.7333\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 257us/step - loss: 41.3221 - val_loss: 27.2246\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 38.9276 - val_loss: 28.0120\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 39.7242 - val_loss: 26.6278\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 39.9745 - val_loss: 28.0291\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 39.1879 - val_loss: 27.8801\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 35.7386 - val_loss: 28.8378\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 242us/step - loss: 36.3583 - val_loss: 27.5991\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 239us/step - loss: 40.3951 - val_loss: 28.1626\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 263us/step - loss: 40.9957 - val_loss: 27.9797\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 240us/step - loss: 39.1396 - val_loss: 27.6069\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 40.4994 - val_loss: 28.1360\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 278us/step - loss: 39.4289 - val_loss: 27.7657\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 241us/step - loss: 40.5876 - val_loss: 27.3125\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 278us/step - loss: 38.1884 - val_loss: 28.9955\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 267us/step - loss: 40.4611 - val_loss: 29.2526\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 38.9877 - val_loss: 28.7098\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 42.6794 - val_loss: 29.9787\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 42.0494 - val_loss: 27.7417\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 41.0459 - val_loss: 29.5915\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 258us/step - loss: 38.1298 - val_loss: 27.8271\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 40.1547 - val_loss: 27.8281\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 38.4073 - val_loss: 28.4099\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 40.8364 - val_loss: 27.5898\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 267us/step - loss: 40.4572 - val_loss: 28.7435\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 40.0004 - val_loss: 27.2826\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 39.4475 - val_loss: 29.9644\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 39.9412 - val_loss: 28.7092\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 41.4030 - val_loss: 28.4386\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 42.0102 - val_loss: 28.1086\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 38.7265 - val_loss: 28.9611\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 40.5399 - val_loss: 28.8380\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 260us/step - loss: 40.9600 - val_loss: 27.3995\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 245us/step - loss: 39.3594 - val_loss: 28.0892\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 39.7114 - val_loss: 28.2392\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 38.3612 - val_loss: 28.3706\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 38.3848 - val_loss: 27.2010\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 40.7440 - val_loss: 27.8555\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 37.5142 - val_loss: 29.4614\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 39.3247 - val_loss: 28.8241\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1567/1567 [==============================] - 0s 249us/step - loss: 38.2754 - val_loss: 28.0116\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 259us/step - loss: 37.5942 - val_loss: 27.3304\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 39.8341 - val_loss: 27.8343\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 263us/step - loss: 39.8869 - val_loss: 27.5901\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 267us/step - loss: 39.0832 - val_loss: 28.2913\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 257us/step - loss: 38.6450 - val_loss: 27.0436\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 37.1041 - val_loss: 27.4457\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 39.0099 - val_loss: 27.8670\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 39.0945 - val_loss: 29.1235\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 268us/step - loss: 39.3802 - val_loss: 27.7318\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 39.7482 - val_loss: 28.2609\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 37.5624 - val_loss: 27.8066\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 38.8974 - val_loss: 26.7980\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 39.5871 - val_loss: 28.6733\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 37.9918 - val_loss: 27.5921\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 38.7780 - val_loss: 27.7269\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 37.2019 - val_loss: 27.9146\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 265us/step - loss: 37.2441 - val_loss: 27.3918\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 254us/step - loss: 39.1652 - val_loss: 27.8199\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 263us/step - loss: 37.8395 - val_loss: 27.3179\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 264us/step - loss: 40.2570 - val_loss: 28.1561\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 39.0654 - val_loss: 28.0419\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 40.6689 - val_loss: 27.4275\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 40.2081 - val_loss: 26.9971\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 36.7218 - val_loss: 27.7529\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 37.6815 - val_loss: 28.0206\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 264us/step - loss: 37.8416 - val_loss: 27.0724\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 260us/step - loss: 37.2308 - val_loss: 27.3056\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 251us/step - loss: 36.3015 - val_loss: 27.0359\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 38.4713 - val_loss: 28.2972\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 38.6024 - val_loss: 28.0490\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 39.6629 - val_loss: 28.5640\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 252us/step - loss: 40.2508 - val_loss: 29.6662\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 38.9661 - val_loss: 29.3571\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 259us/step - loss: 38.0099 - val_loss: 27.1168\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 37.4541 - val_loss: 29.3021\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 39.5030 - val_loss: 28.3494\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 38.8651 - val_loss: 27.3024\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 246us/step - loss: 40.6922 - val_loss: 28.5682\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 39.0108 - val_loss: 27.3453\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 40.5501 - val_loss: 27.1854\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 247us/step - loss: 42.0821 - val_loss: 27.6660\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 278us/step - loss: 38.3005 - val_loss: 26.6204\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 248us/step - loss: 40.8874 - val_loss: 28.4224\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 253us/step - loss: 38.1752 - val_loss: 27.6153\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 249us/step - loss: 36.8579 - val_loss: 27.4517\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 250us/step - loss: 39.8301 - val_loss: 28.3862\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 256us/step - loss: 37.0886 - val_loss: 27.8419\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "1567/1567 [==============================] - 0s 255us/step - loss: 38.4587 - val_loss: 28.0966\n",
      "Train on 1567 samples, validate on 392 samples\n",
      "Epoch 1/1\n",
      "  32/1567 [..............................] - ETA: 0s - loss: 30.1350"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-46b7eddc1a36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    model.fit(train_x,train_y,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "679.069519043\n",
      "644.972381592\n",
      "604.736824036\n",
      "666.200332642\n",
      "2\n",
      "636.189956665\n",
      "606.906585693\n",
      "580.840530396\n",
      "2\n",
      "646.739807129\n",
      "547.72026062\n",
      "644.138031006\n",
      "628.647689819\n",
      "589.686126709\n",
      "573.268661499\n",
      "622.477416992\n",
      "2\n",
      "656.226501465\n",
      "684.249343872\n",
      "2\n",
      "638.997917175\n",
      "576.546325684\n",
      "622.89226532\n",
      "613.993263245\n",
      "2\n",
      "641.936187744\n",
      "615.985946655\n",
      "701.667022705\n",
      "2\n",
      "650.136413574\n",
      "631.121444702\n",
      "643.49105835\n",
      "607.932510376\n",
      "619.295043945\n",
      "2\n",
      "643.857574463\n",
      "558.6277771\n",
      "594.150085449\n",
      "640.268096924\n",
      "2\n",
      "602.979125977\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-fbd55f77ab7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-90-710457f7480c>\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mpress_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mjump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpress_time\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.3\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpress_time\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mimg_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(8, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "model.add(Conv2D(4, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=keras.optimizers.Adam())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
