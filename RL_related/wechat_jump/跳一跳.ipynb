{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import random as rd\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.concatenate([np.load(\"train_x_1.npy\"),np.load(\"train_x_2.npy\")],axis=0)\n",
    "train_y = np.load(\"train_y.npy\")\n",
    "n_sample = train_x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = None\n",
    "train_y = None\n",
    "n_sample = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKkAAAD8CAYAAAAMloRrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAFuFJREFUeJztnX20VWWZwH/PvVy4iTgIeB289yrg\nAKYzSUU5DX3YSKaNSZYyXKWswcBRVlNLLPpiKldrLDVXLcmikdQxURw0tUX5wWiRZYmOkSSgAeoF\n4iJEKDJyP575Y+992ffcvc/X3vuc99zz/NY665zznvfs/W7uj+f92Hs/R1QVw3CZhmo3wDAKYZIa\nzmOSGs5jkhrOY5IazmOSGs6TmaQicpaIbBKR50VkcVb7MYY+ksU6qYg0ApuB9wGdwBNAh6r+IfWd\nGUOerCLp24HnVXWLqh4C7gBmZbQvY4gzLKPttgIvhd53AqfFVR4zpkHb27NqiuES69d3v6yqx5Ty\nnazMkIiyAeMKEZkPzAdobW3kgdXjMmqK4RLj23a+UOp3suruO4H20Ps2YEe4gqouU9Xpqjp97Fhb\nZDDiycqOJ4DJIjJRRIYDc4D7MtqXMcTJpLtX1R4RWQg8ADQCy1V1Qxb7MoY+mc1WVHU1sDqr7Rv1\ng02p64yFL5xbkf3ccEJ6ozuTtA64ce/bANjwyviK7XPhC+dy7fH30ixRCz2lYdPqOmDDK+MzE3Tl\npDWsnLQm8rNFL6Zz/sYkNZzHuvshzqde/GBm2145aQ2zt5wBwJQjuwDY/GrLgDprD3oR/F1v2Fn2\nfiySDnH6dPCY8L8m/gw43FUH3XVctx3H7C1n9H9/86stbH61hW+03zugzl27p3PX7ulltt4jk6ug\nSuXUU4ernRbNhixn8w2i9Kkw5ciu/gg6vKGXQ32N/XXeOOpPAFw+5rcAjG/b+aSqlmStRdIhTppL\nQbncMuEBZo59lm2vje2PqGFBwZMzELRcbExqlM1Ht57V/zoYm4aZOfbZVPZjktYBQTTd2D2SG3YM\nlinLfaaBdfeG81gkrSNOajqQ6Rg1KyySGs5jkhrOY5IazmOSGs5jkhrOY5IazlPTS1BzZ1824P33\n71jKyIbkF9kabmGR1HCemo6kt638bv/rubMvsyg6RCk7kopIu4g8IiLPisgGEfk3v/wrIrJdRJ72\nHx9Ir7n5OdBX/csOjfRJEkl7gCtU9SkRGQU8KSIP+Z9dr6rXJm+eYSSQVFV3Ajv916+IyLN4icoM\nI1VSmTiJyATgzcBv/KKFIrJeRJaLyNFp7MOoXxJLKiJHAquAT6vqfuBG4ERgGl6kvS7me/NFZJ2I\nrNuzpy9pM4whTCJJRaQJT9AfqerdAKq6S1V7VbUP+AFeQt1BZJFVz2b3Q5Mks3sBbgKeVdVvhcrD\nWQjOA54pv3nFE16OMoYWSWb3M4CPAr8Xkaf9si8AHSIyDS9p7jZgQaIWGnVPktn9L4nO6GyZ9IxU\nsdOihvOYpIbzmKSG85ikhvOYpIbzmKSG85ikhvOYpIbzmKSG85ikhvOYpIbzmKSG85ikhvOYpIbz\nmKSG85ikhvOYpIbzmKSG85ikhvOYpIbzmKSG8yRO/Sgi24BXgF6gR1Wni8gY4E5gAt5tzbNV9c9J\n92XUJ2lF0veq6rTQr+8uBtao6mRgjf/eMMoiq+5+FnCL//oW4EMZ7ceoA9KQVIEHReRJEZnvlx3r\np4YMUkS25H7JEpYZxZJGOvIZqrpDRFqAh0RkYzFfUtVlwDKAU08dbimajVgSR1JV3eE/dwH34GXR\n2xUkLvOfu5Lux6hfkqZ+HOmnIkdERgJn4mXRuw+42K92MXBvkv0Y9U3S7v5Y4B4vCyTDgNtV9Wci\n8gSwUkTmAS8CFyTcj1HHJJJUVbcAp0aU7wHOSLJtwwiwM06G85ikhvOYpIbzmKSG85ikhvO48QO4\nqvSqnXQyorFIajiPSWo4j0lqOI9JajiPSWo4j0lqOI9JajiPSWo4j0lqOI9JajiPSWo4j0lqOI9J\najiPSWo4T9mX6onIVLykZAGTgCXAaOCTwG6//AuqurrsFhp1T9mSquomYBqAiDQC2/GSQ3wCuF5V\nr02lhUbdk1Z3fwbwR1V9IaXtGUY/aUk6B1gRer9QRNaLyHIROTqlfRh1SmJJRWQ4cC5wl190I3Ai\n3lBgJ3BdzPcOZ9Xba1n1jHjSiKRnA0+p6i4AVd2lqr2q2gf8AC+B2SBUdZmqTlfV6WPH2CKDEU8a\ndnQQ6uqDbHo+5+ElMDOMskl0t6iIHAG8D1gQKv6miEzDS667LeczwyiZpAnLXgPG5pR9NFGLDCOH\nmhwMzt18YbWbUDJr/6+1/2GUhhvJIUrgPb+6jPZx+waIetuU26vYovyYlMmpyUhq1Bc1EUnf86vL\n8n4+d/OFNIhy6+QVeetVmqgouvinHTx2np0xLgWnJY2Ts+uBNhBoObOzv6xPhbmbL6x61x/XvS/+\naUeFWzJ0cFbSQtET9WUFWt5/WNZgrFppWU3O7HBK0oJixpBPVshe2LhuPYqrz3ZrSFILiDqQcrH5\nxFZt+49Li67fPm4fcFjOXMKyhklT1lIiZ66Y72renlo7ao229j89GfoN2qKw2b3hPE5196USjpjh\nqBp+nTsESBpNSx17WveenJqUtOuBtkFdevA+dwiQW7fcsWpactoSVOnUpKQQHy1b3t8ZKWpuPShu\nJSCNSZHN8JNRs5KGyY2W5QwDAgJhk0yM8tU1SseJ2f2pb2rS1avHFb0E1T5uX8kz+1LqLzj+54PK\nio2exdSz2b3N7o0hhlPd/c//4btAcYv6hbr0cidWYdIYe9rsPjlOdfe5xMkaLObnEtWll9P9b91w\nXORnpY49o+rXc1cP5XX3TksaUIqsaYxVD7Qdvns1DTHB5AwYspKGiRI2qax9Krz84OHZfCBplHCL\nfzYHVAaVV1vOeW+Z1f/6pqfuLVj/nasW8cuPVH69ti4khXSGARAtbNeDbXz5kh9F1i9lzFnJyHnJ\njDnQIBw63vs37Gtq4Labvx1Z952rFg0qe+Qj19KUaQsPY7N7Y0hSVCQVkeXAOUCXqv6tXzYGL6ve\nBLxbl2er6p9FRIBvAx8AXgM+rqpP5dt+qZE0II2IOu7M7TTIwH+D8Dqp65OiS047H5pHoM3DeXWK\nl9Go6y3DmHD/fn549/cG1I2KomEq0f2XE0mLXYK6GbgBuDVUthhYo6pXi8hi//3n8DKaTPYfp+Gl\n3TmtlEYVS7BkBQOFfenl0f2vw8JGnTINxqK5XX+tTIy0uxsZ5v0Zm3e/DkDbIz1IjzeuLiRmmKBu\nNcaq+Sh6TCoiE4CfhCLpJuB0Vd3pZy15VFWnisj3/dcrcuvFbbvcSJpLWmPV8Ow+wDU5w8x787lI\nczMM90aW2jSMTf96TCrbTlvYLCNpFMcG4vmitvjlrcBLoXqdflmspGkRdzIgiKy5ssYt8Ae4LGYY\nOXIkHOqGnl4ANi8cX+AbxVOtVYAwWZxxGrw+46XcGVhJZD4wH6C1Nd35W3gYsKN3OB2/uQTIPwwI\nCIStFUEB/nPtipK69VKp9jAgiR27guRk/nOXX94JtIfqtQE7cr9sWfWMYkkyJr0G2BOaOI1R1c+K\nyD8BC/Fm96cB31HVyPSPAWmNSQuxYOv5bNzZMqAsarwadRWUixEUvCg39eot3ps+728pwxrZ+NkJ\nme633Kia2WK+iKwATgfGAbuAfwd+DKwEjgdeBC5Q1b3+EtQNwFl4S1CfUNV1+bZfKUlzOf3Xl6E6\nWNRAUpfFDDjpm9v6J0wHJ3v/Afe+cQR//au/8NzcUZm2oxxRM5s4qWrc1btnRNRV4PJSGlEtHn3H\n4CWs9nH7nJVzxj2LkJyFB+3rQwA9orn/s7/a2oP0Zn8msVJjVacu1asm4cmWi7xz1aLoGelrB+FQ\nN9LTS/OrB72yEU30jR5Z0bYFZCGsSeow53z9SgD6mgROjPldge5uEEFffx0ZMaK/OFjMrzRZRFeT\n1EECOQMaupXRG704uu+kgd249vRAYyNyCFS8VRIZ1givvV6ZxsaQ5vqqrf0YzmOSOkahW2dGbxSa\nuxpo7vL+dNqnoIqqQk+P9zjUjbxyoBLNzct7f/jZVLZj3b0DlJqorXmv+s8C2gd9fSCHp1V66FCq\n7SuVpv3pxj6TtIqUm0VwEA1+VPXllMZGKn0xe9pihjFJq0Q+QUdf4K3T7rurcL79hhEjBkTRABle\nmWvt4+T8Wkf03Q3lYJJWmFKiZyFZx33/19DcjDQ2DvygaRiIMPVrm9i0ZGrZbS1ElKBpyhlgEyfD\neSySVoCkY8+C3f+IEciwRtS/npQGgd5enr/yJCKukkxEKd37khUX8cgnvpl4nyZphpQrZyBjIGdA\nrqwvL3gHx9z0BNIg3oJ+qO6LH/sbet+Q3lmnUseeS1ZclNq+TdKMSGPmHsioDXD0Rw4LG5Z197y3\nDf7eSQpkK2gl5AwwSVMmDTlHX7B9QNcufZ6QhSJrf3nMKdRSKVbOODHTmkTVZHKIWqFcYYPrW+PG\noLmyBsTVL0XWNLr1cN3cyx4tOYQxJLFImjHlRNOoW1rSiKr5ImpaE6Pc+mlEUpO0QpQi66hHRpbc\npUfV//Oq1kFX8sNgWXMFTSpmuH7uElSl77uvOz541ZXc/+VryvpuXLaVOMIyhgUMvw7X2XdXK0ed\n792UG6QNClYEoiZWB46Lus4/nYlR2jN8i6QF+OBVVw4qK1fUXOJkHfVI9K0fUdGy3GFArqTFCleq\nmGlEUpM0hig5o0gqbL6oGiVrGsMAgO2PtaXSrRcrZ0Ams3sRWS4iXSLyTKjsGhHZKCLrReQeERnt\nl08QkYMi8rT/+F78lg2jOApGUhF5N/AqcGsoMcSZwP+oao+IfANAVT+Xm0CiWN70pia9z6FI+uEi\no2iYu1MYAsx8LPpO8FGPHhFZniSqRiXASGPs+WCBc/UTM0wOMYEY+UTkPOB8Vb2oliUtR8woXJc1\nqBuWdMkdF0amWC+ley8kZ0C1JL0fuFNVb/PrbQA2A/uBL6nq2pht9icsO6614a2PPd4SVS1z0pIz\nl6SyxokK0bLmnt8PiIuqn7vi9oJni8IklTOg4pKKyBeB6cCHVVVFZARwpKruEZG34qXiOUVV9+fb\nfjUiaVZy5pJlZIVoYYuJrFFLUJGRMybKlipnQEUlFZGLgUuBM1T1tZjvPQosKpQLqpKSVkrOXFwb\nBoQlLTZ6litmmIpJKiJnAd8C3qOqu0P1jgH2qmqviEwC1gJ/p6p7822/EpJWS84oshoKlCJr1MQJ\n0uvW4yhH0oJnnMIZ9USkEy+j3ueBEcBDXhI9HlfVS4F3A18TkR6gF7i0kKCGUQgnFvOzjKQuRdAw\naXT/F2+6iO2h7NVhoqLqUefv6D9lmhtJs46gAZl191mTtqSuihlFGrJC9BAgX/e/4PifV0zMMCYp\ntSVoLmkJCwOljZI1anafpZwBmYxJa4ValjMgOIY0ZH14xtL+1zPJLyxURtByGRKSznzsctq2HmL/\nxOHVbkoimg5k06uFhf3D28byqSfm0LB5pNNihrHbRwznqdlIGjVROGqrl7Cr1iJqVhE0ipOH7/Ei\n64yK7TIxNSdpvlOEAYGs4LawlZSzlqkJSYsRc2uHMHHF4D/6UQ6OVfPJOXb+CxVsSW3gvKTFCBqw\ntcNbVsmV1YVhgIlZPs5KWoqcueSLqgGVFDZOUJOzOGx2bziPU5E0SfTMJej6YXD3D5UZAlgETQcn\nIunmAy2pCprL1g4ZIG2Y8BAgDZoOaP8jChO0dJyKpFmztUP6c8pOvOOwRGmMVW1ilB1ORNIpI7sG\nnLrLFPEe+SJrqdE1X9Q0QZPjVCQNRM2y6w8Tt2QFhddXs+rO9yw7Aa5OtIkhhxOR1DDy4VQkDSgn\nogbRMK4bz0fcSkDUWDXLseeeZSck+v5QxUlJAyota//3dODECjxhD7ZE/4BXEjlNzMI4LWnAgAt4\nixQ2kawSf9YqwKJm5ajJ20fyidp2U/T/u3Ija8DEFcrBlqZM5bzz6nR+H95lMrnHSUSWA+cAXaH7\n7r8CfBII7rn/gqqu9j/7PDAP75bmT6nqA4UaUe49TnGyxokKyWQ95cToZAvFECdnPYgZJqt7nG4G\nbgBuzSm/XlUH/AuLyMnAHOAU4DjgYRGZoqq9pTSqWOKGAZ3zevpf5wob7sKTRtdiMDmTU3AJSlV/\nARSb4GEWcIeqvq6qW4HngbcnaJ9hJFonXegn0V0uIkf7Za3AS6E6nX7ZIERkvoisE5F1e/Ym//W2\nh2csjTxr1TmvZ0BkDZNvYpSUPctOsCiaEuXO7m8ErsI7E34VcB3wL0BU/xlpgqouA5aBNyYtsx2D\neHjG0sixaiBqXPefRtdf75OirChLUlXdFbwWkR8AP/HfdgLtoaptwI6yW1cm+ZasCskK5QlrUTM7\nypJURMar6k7/7XlAkE//PuB2EfkW3sRpMvDbxK1MQNwJgThZwRO2WFFNzuwpN6ve6SIyDa8r3wYs\nAFDVDSKyEvgD0ANcntXMvlQenrGUtQdP4KtPnTOgvJxhgHXrlaWgpKraEVF8U576Xwe+nqRRhhGm\nJs84pcWnt53HM9uPG1CmKrQvb4ysf8SXdlj3nhDLqpeA3DFr1Fg16gITk7M06jqrXlJy11iDTHRR\nspqYlcUkjaFfWj9n0szHLmfs/U0maBUwSYuk1pJ8DSXs9hHDeUxSw3lMUsN5TFLDeUxSw3lMUsN5\nTFLDeUxSw3lMUsN5TFLDeUxSw3lMUsN5TFLDeUxSw3lqStILP3MFF37mimo3w6gwxdwtGpWw7E5g\nql9lNLBPVaeJyATgWWCT/9njqnpp0kZ2+3e43H79dezuHU63QlP2aZwMRygmkt4MnBUuUNV/VtVp\nqjoNWAXcHfr4j8FnaQgK0LHkSjqWXAlAk/Qx9/OL0tisUSMUc0vzL/wIOQgREWA28I/pNmsgvc3e\nc8cVXlffEJ25xxiiJL195F3ALlV9LlQ2UUT+F9gPfElV1ybcB/d88ZqkmzBqmKSSdgArQu93Aser\n6h4ReSvwYxE5RVX3535RROYD8wGOa62p+ZtRYcq2Q0SGAR8G7gzK/Lyke/zXTwJ/BKZEfV9Vl6nq\ndFWdPnaMSWrEk8SOmcBGVe0MCkTkGBFp9F9PwktYtiVZE416p6CkfsKyXwNTRaRTROb5H81hYFcP\n8G5gvYj8Dvhv4FJVLTZLtGFEUm7CMlT14xFlq/CWpAwjNWwwaDiPSWo4j0lqOI9JajiPE/lJRWQ3\ncAB4udptqRDjqJ9jhYHHe4KqHlPKl52QFEBE1pWaXLVWqadjheTHa9294TwmqeE8Lkm6rNoNqCD1\ndKyQ8HidGZMaRhwuRVLDiKTqkorIWSKySUSeF5HF1W5PFojINhH5vYg8LSLr/LIxIvKQiDznPx9d\naDsu4v9Kd5eIPBMqizw28fiO/7deLyJvKWYfVZXUv6xvKXA2cDLQISInV7NNGfJe/76vYClmMbBG\nVScDa/z3tcjN5NwDR/yxnY13+eZkvAvebyxmB9WOpG8HnlfVLap6CLgDmFXlNlWKWcAt/utbgA9V\nsS1lo6q/AHIvx4w7tlnArerxODBaRMYX2ke1JW0FXgq97/TLhhoKPCgiT/q3zQAcG/zStf/cUrXW\npU/csZX196727zhF3T0/FJcbZqjqDhFpAR4SkY3VblCVKOvvXe1I2gm0h963ATuq1JbMUNUd/nMX\ncA/eMGdX0NX5z13Va2HqxB1bWX/vakv6BDBZRCaKyHC8W1Luq3KbUkVERorIqOA1cCbwDN5xXuxX\nuxi4tzotzIS4Y7sP+Jg/y/974C/BsCAvqlrVB/ABYDPenaVfrHZ7Mji+ScDv/MeG4BiBsXgz3+f8\n5zHVbmuZx7cC71b2brxIOS/u2PC6+6X+3/r3wPRi9mFnnAznqXZ3bxgFMUkN5zFJDecxSQ3nMUkN\n5zFJDecxSQ3nMUkN5/l/RRWNm1EJddgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f85d5ebed30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "im = plt.imshow(train_x[8200,:,:,:].reshape(183,103))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "swipe_x1, swipe_y1, swipe_x2, swipe_y2 = 320, 1000, 320, 1000\n",
    "mistrust = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img():\n",
    "    os.system('adb shell screencap -p /sdcard/1.png')\n",
    "    os.system('adb pull /sdcard/1.png .')\n",
    "    img = cv2.imread('1.png')\n",
    "    img = img[::7,::7,1].reshape(1,183,103,1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKkAAAD8CAYAAAAMloRrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+X9+SLmqh0EX0wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f85d5ee8c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(183, 103, 1)\n",
      "(183, 103)\n"
     ]
    }
   ],
   "source": [
    "img = get_img()\n",
    "im = plt.imshow(img.reshape(183,103))\n",
    "plt.show()\n",
    "input_shape = img.shape[1:]\n",
    "img_dim = img.shape[1:3]\n",
    "print(input_shape)\n",
    "print(img_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (183,103,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[247],\n",
       "         [247],\n",
       "         [247],\n",
       "         ..., \n",
       "         [247],\n",
       "         [247],\n",
       "         [247]],\n",
       "\n",
       "        [[247],\n",
       "         [247],\n",
       "         [247],\n",
       "         ..., \n",
       "         [247],\n",
       "         [247],\n",
       "         [247]],\n",
       "\n",
       "        [[247],\n",
       "         [247],\n",
       "         [247],\n",
       "         ..., \n",
       "         [247],\n",
       "         [247],\n",
       "         [247]],\n",
       "\n",
       "        ..., \n",
       "        [[245],\n",
       "         [245],\n",
       "         [245],\n",
       "         ..., \n",
       "         [245],\n",
       "         [245],\n",
       "         [245]],\n",
       "\n",
       "        [[245],\n",
       "         [245],\n",
       "         [245],\n",
       "         ..., \n",
       "         [245],\n",
       "         [245],\n",
       "         [245]],\n",
       "\n",
       "        [[245],\n",
       "         [245],\n",
       "         [245],\n",
       "         ..., \n",
       "         [245],\n",
       "         [245],\n",
       "         [245]]]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.amax(img[:50,:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jump(press_time):\n",
    "    cmd = 'adb shell input swipe {} {} {} {} {}'.format(swipe_x1, swipe_y1, swipe_x2, swipe_y2, math.ceil(max(press_time,200)))\n",
    "    os.system(cmd)\n",
    "    print(press_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def success(img_new,img):\n",
    "    if np.amax(np.absolute(img_new.reshape(img_dim)[:25,:25]-img.reshape(img_dim)[:25,:25]))>50:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fail(img_new):\n",
    "    if np.amax(img_new.reshape(img_dim)[:25,:25])>50:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=keras.optimizers.Adadelta())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=keras.optimizers.Nadam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network(model,img,confidence):\n",
    "    if rd.uniform(0,1)<confidence:\n",
    "        return model.predict(img)\n",
    "    else:\n",
    "        return np.array(rd.randint(40,90)).reshape(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(rd.randint(20,120)).reshape(1,1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mistrust = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,img,press_time):\n",
    "    model.fit(img,np.array([press_time]).reshape(1,1),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    img = get_img()\n",
    "    while(True):\n",
    "        press_time = network(model,img,1)[0][0]\n",
    "        jump(press_time*10)\n",
    "        time.sleep(2.3+press_time/200)\n",
    "        img_new = get_img()\n",
    "        if fail(img_new):\n",
    "            jump(2)\n",
    "            time.sleep(0.8)\n",
    "            img_new = get_img()\n",
    "        img = img_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.load(\"train_x.npy\")\n",
    "train_y = np.load(\"train_y.npy\")\n",
    "n_sample = train_x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "561.977920532\n",
      "496.441726685\n",
      "537.21660614\n",
      "565.479507446\n",
      "534.708786011\n",
      "532.336959839\n",
      "2\n",
      "534.773406982\n",
      "2\n",
      "570.860939026\n",
      "505.284347534\n",
      "606.732406616\n",
      "2\n",
      "572.868537903\n",
      "1\n",
      "Epoch 1/1\n",
      "2432/2432 [==============================] - 8s 3ms/step - loss: 196.1244\n",
      "680\n",
      "670\n",
      "2\n",
      "700\n",
      "490\n",
      "2\n",
      "560\n",
      "590\n",
      "880\n",
      "2\n",
      "600\n",
      "660\n",
      "440\n",
      "2\n",
      "510\n",
      "2\n",
      "650\n",
      "570\n",
      "440\n",
      "2\n",
      "810\n",
      "660\n",
      "2\n",
      "630\n",
      "860\n",
      "2\n",
      "850\n",
      "552.56439209\n",
      "850\n",
      "2\n",
      "520\n",
      "2\n",
      "591.102867126\n",
      "870\n",
      "2\n",
      "700\n",
      "450\n",
      "2\n",
      "400\n",
      "2\n",
      "760\n",
      "540\n",
      "2\n",
      "640\n",
      "480\n",
      "604.461021423\n",
      "2\n",
      "450\n",
      "2\n",
      "570\n",
      "470\n",
      "2\n",
      "595.936660767\n",
      "600\n",
      "2\n",
      "510\n",
      "2\n",
      "690\n",
      "570\n",
      "810\n",
      "560\n",
      "638.537940979\n",
      "880\n",
      "2\n",
      "820\n",
      "540\n",
      "626.992263794\n",
      "2\n",
      "582.399559021\n",
      "420\n",
      "2\n",
      "510\n",
      "2\n",
      "800\n",
      "554.128303528\n",
      "2\n",
      "608.67603302\n",
      "790\n",
      "890\n",
      "880\n",
      "2\n",
      "880\n",
      "670\n",
      "540\n",
      "820\n",
      "2\n",
      "590\n",
      "589.078369141\n",
      "2\n",
      "569.823608398\n",
      "549.119529724\n",
      "2\n",
      "720\n",
      "527.97454834\n",
      "690\n",
      "582.043609619\n",
      "2\n",
      "670\n",
      "539.744300842\n",
      "2\n",
      "573.479537964\n",
      "670\n",
      "2\n",
      "620\n",
      "535.15171051\n",
      "589.204139709\n",
      "602.420310974\n",
      "790\n",
      "2\n",
      "700\n",
      "567.752952576\n",
      "2\n",
      "573.479537964\n",
      "780\n",
      "550\n",
      "500\n",
      "2\n",
      "570\n",
      "516.60774231\n",
      "490\n",
      "592.855072021\n",
      "590\n",
      "680\n",
      "2\n",
      "604.697036743\n",
      "740\n",
      "531.304626465\n",
      "610\n",
      "586.280784607\n",
      "2\n",
      "830\n",
      "900\n",
      "2\n",
      "420\n",
      "2\n",
      "568.633575439\n",
      "622.595214844\n",
      "2\n",
      "750\n",
      "570\n",
      "602.650718689\n",
      "2\n",
      "595.874633789\n",
      "563.473396301\n",
      "450\n",
      "2\n",
      "595.410041809\n",
      "585.807418823\n",
      "2\n",
      "480\n",
      "2\n",
      "605.838775635\n",
      "589.638938904\n",
      "494.741096497\n",
      "550.713005066\n",
      "600.640144348\n",
      "2\n",
      "599.897956848\n",
      "890\n",
      "2\n",
      "600.108413696\n",
      "577.277374268\n",
      "556.612052917\n",
      "520\n",
      "2\n",
      "585.360221863\n",
      "602.729148865\n",
      "2\n",
      "594.634132385\n",
      "603.74294281\n",
      "2\n",
      "569.823608398\n",
      "710\n",
      "2\n",
      "571.55002594\n",
      "577.975120544\n",
      "2\n",
      "890\n",
      "2\n",
      "720\n",
      "582.258605957\n",
      "2\n",
      "605.838775635\n",
      "580\n",
      "580\n",
      "2\n",
      "575.550842285\n",
      "549.121131897\n",
      "2\n",
      "602.159042358\n",
      "594.233894348\n",
      "2\n",
      "560\n",
      "553.72428894\n",
      "2\n",
      "599.539031982\n",
      "573.597564697\n",
      "2\n",
      "595.410041809\n",
      "500\n",
      "625.595855713\n",
      "2\n",
      "601.683349609\n",
      "595.171203613\n",
      "2\n",
      "520\n",
      "2\n",
      "590\n",
      "541.174316406\n",
      "620.636138916\n",
      "2\n",
      "581.623954773\n",
      "503.469543457\n",
      "512.308807373\n",
      "591.704902649\n",
      "2\n",
      "596.678009033\n",
      "576.095199585\n",
      "2\n",
      "582.399559021\n",
      "588.549118042\n",
      "547.417945862\n",
      "2\n",
      "575.958900452\n",
      "497.51209259\n",
      "569.03175354\n",
      "2\n",
      "589.689483643\n",
      "610.975646973\n",
      "2\n",
      "604.697036743\n",
      "609.251327515\n",
      "2\n",
      "576.264152527\n",
      "580\n",
      "562.182159424\n",
      "517.356491089\n",
      "611.029701233\n",
      "820\n",
      "2\n",
      "680\n",
      "548.06728363\n",
      "582.245903015\n",
      "2\n",
      "600.34236908\n",
      "582.713317871\n",
      "2\n",
      "594.606742859\n",
      "450\n",
      "2\n",
      "400\n",
      "2\n",
      "595.86479187\n",
      "570.11592865\n",
      "586.959686279\n",
      "2\n",
      "599.539031982\n",
      "556.568412781\n",
      "570.027427673\n",
      "2\n",
      "670\n",
      "541.002082825\n",
      "2\n",
      "593.830718994\n",
      "420\n",
      "2\n",
      "581.686172485\n",
      "601.406440735\n",
      "598.706855774\n",
      "2\n",
      "605.838775635\n",
      "519.95475769\n",
      "583.938217163\n",
      "591.005630493\n",
      "2\n",
      "561.882324219\n",
      "2\n",
      "594.606742859\n",
      "539.440040588\n",
      "543.188934326\n",
      "577.536010742\n",
      "2\n",
      "575.958900452\n",
      "620\n",
      "2\n",
      "596.678009033\n",
      "556.494216919\n",
      "577.240905762\n",
      "2\n",
      "602.174415588\n",
      "890\n",
      "528.143463135\n",
      "584.093170166\n",
      "575.177497864\n",
      "561.064796448\n",
      "561.978416443\n",
      "2\n",
      "599.539031982\n",
      "573.340377808\n",
      "2\n",
      "595.372009277\n",
      "564.963264465\n",
      "2\n",
      "594.606742859\n",
      "470\n",
      "2\n",
      "600.34236908\n",
      "613.652687073\n",
      "2\n",
      "591.102867126\n",
      "565.564079285\n",
      "2\n",
      "593.830718994\n",
      "583.882446289\n",
      "1\n",
      "Epoch 1/1\n",
      "2560/2560 [==============================] - 8s 3ms/step - loss: 212.4503\n",
      "650\n",
      "2\n",
      "430\n",
      "2\n",
      "890\n",
      "2\n",
      "750\n",
      "500\n",
      "2\n",
      "590\n",
      "900\n",
      "850\n",
      "2\n",
      "621.068000793\n",
      "410\n",
      "2\n",
      "480\n",
      "2\n",
      "640\n",
      "810\n",
      "2\n",
      "530\n",
      "2\n",
      "710\n",
      "670\n",
      "2\n",
      "730\n",
      "710\n",
      "830\n",
      "619.570922852\n",
      "2\n",
      "490\n",
      "2\n",
      "710\n",
      "730\n",
      "2\n",
      "630.382881165\n",
      "645.563049316\n",
      "860\n",
      "2\n",
      "616.014328003\n",
      "605.224304199\n",
      "580\n",
      "2\n",
      "641.398620605\n",
      "640\n",
      "2\n",
      "580\n",
      "410\n",
      "2\n",
      "720\n",
      "605.070228577\n",
      "580\n",
      "480\n",
      "440\n",
      "643.823471069\n",
      "2\n",
      "770\n",
      "870\n",
      "2\n",
      "700\n",
      "610\n",
      "730\n",
      "720\n",
      "790\n",
      "566.745300293\n",
      "430\n",
      "2\n",
      "760\n",
      "596.977920532\n",
      "2\n",
      "647.024154663\n",
      "581.098937988\n",
      "890\n",
      "2\n",
      "600\n",
      "586.632003784\n",
      "599.75730896\n",
      "628.265914917\n",
      "520\n",
      "589.898147583\n",
      "2\n",
      "600\n",
      "611.939659119\n",
      "652.937393188\n",
      "840\n",
      "2\n",
      "810\n",
      "594.493942261\n",
      "612.208786011\n",
      "710\n",
      "2\n",
      "580\n",
      "850\n",
      "584.248695374\n",
      "619.577903748\n",
      "577.238044739\n",
      "2\n",
      "635.615348816\n",
      "440\n",
      "2\n",
      "470\n",
      "2\n",
      "840\n",
      "604.712791443\n",
      "637.140045166\n",
      "2\n",
      "648.653640747\n",
      "680\n",
      "631.587333679\n",
      "635.446281433\n",
      "500\n",
      "693.44367981\n",
      "2\n",
      "632.999725342\n",
      "450\n",
      "2\n",
      "420\n",
      "2\n",
      "629.92401123\n",
      "690\n",
      "2\n",
      "633.459510803\n",
      "770\n",
      "2\n",
      "632.358703613\n",
      "634.020614624\n",
      "530\n",
      "600\n",
      "584.306907654\n",
      "2\n",
      "635.219535828\n",
      "574.266242981\n",
      "569.194068909\n",
      "602.517814636\n",
      "642.767410278\n",
      "2\n",
      "660\n",
      "540.796966553\n",
      "608.772506714\n",
      "2\n",
      "630\n",
      "632.436447144\n",
      "2\n",
      "650\n",
      "613.433952332\n",
      "2\n",
      "629.92401123\n",
      "640\n",
      "624.110794067\n",
      "2\n",
      "890\n",
      "2\n",
      "647.244033813\n",
      "520\n",
      "599.785766602\n",
      "595.708503723\n",
      "2\n",
      "430\n",
      "2\n",
      "644.082717896\n",
      "656.209716797\n",
      "623.019332886\n",
      "600.929260254\n",
      "614.872283936\n",
      "2\n",
      "615.664978027\n",
      "549.856948853\n",
      "2\n",
      "625.335159302\n",
      "820\n",
      "2\n",
      "633.459510803\n",
      "500\n",
      "555.097045898\n",
      "674.580307007\n",
      "659.141616821\n",
      "2\n",
      "658.467941284\n",
      "616.559371948\n",
      "613.2654953\n",
      "612.200546265\n",
      "2\n",
      "605.303421021\n",
      "652.562026978\n",
      "2\n",
      "617.1900177\n",
      "602.414283752\n",
      "601.284179688\n",
      "576.343650818\n",
      "618.18271637\n",
      "590.587310791\n",
      "634.488868713\n",
      "640\n",
      "660\n",
      "571.162452698\n",
      "649.589157104\n",
      "657.937240601\n",
      "2\n",
      "626.036262512\n",
      "820\n",
      "2\n",
      "611.688232422\n",
      "606.717643738\n",
      "2\n",
      "600\n",
      "577.766494751\n",
      "2\n",
      "622.062721252\n",
      "549.641418457\n",
      "555.44670105\n",
      "584.264030457\n",
      "2\n",
      "602.013969421\n",
      "410\n",
      "2\n",
      "629.92401123\n",
      "660\n",
      "2\n",
      "440\n",
      "2\n",
      "644.082717896\n",
      "618.236961365\n",
      "632.158317566\n",
      "687.695846558\n",
      "562.12600708\n",
      "2\n",
      "627.403106689\n",
      "860\n",
      "604.407844543\n",
      "646.522064209\n",
      "712.056274414\n",
      "2\n",
      "627.403106689\n",
      "627.672042847\n",
      "2\n",
      "637.867355347\n",
      "625.89263916\n",
      "830\n",
      "2\n",
      "611.164321899\n",
      "653.230895996\n",
      "2\n",
      "617.121658325\n",
      "644.345703125\n",
      "2\n",
      "629.92401123\n",
      "830\n",
      "633.933372498\n",
      "571.868247986\n",
      "2\n",
      "617.1900177\n",
      "655.059814453\n",
      "2\n",
      "658.467941284\n",
      "591.039733887\n",
      "606.326904297\n",
      "2\n",
      "618.062057495\n",
      "510\n",
      "2\n",
      "639.301681519\n",
      "595.780601501\n",
      "592.525596619\n",
      "2\n",
      "616.612281799\n",
      "569.189987183\n",
      "2\n",
      "617.1900177\n",
      "568.11958313\n",
      "2\n",
      "639.301681519\n",
      "549.809646606\n",
      "601.066360474\n",
      "2\n",
      "600\n",
      "598.775672913\n",
      "586.486473083\n",
      "605.962791443\n",
      "2\n",
      "648.955917358\n",
      "563.452377319\n",
      "625.715065002\n",
      "2\n",
      "638.783073425\n",
      "860\n",
      "645.031661987\n",
      "666.800994873\n",
      "2\n",
      "627.403106689\n",
      "608.641624451\n",
      "640.21522522\n",
      "1\n",
      "Epoch 1/1\n",
      "2688/2688 [==============================] - 8s 3ms/step - loss: 213.5345\n",
      "820\n",
      "720\n",
      "2\n",
      "540\n",
      "2\n",
      "900\n",
      "2\n",
      "410\n",
      "2\n",
      "730\n",
      "601.973304749\n",
      "2\n",
      "637.110557556\n",
      "800\n",
      "610\n",
      "2\n",
      "640\n",
      "470\n",
      "780\n",
      "880\n",
      "2\n",
      "550\n",
      "640\n",
      "700\n",
      "750\n",
      "600\n",
      "2\n",
      "720\n",
      "510\n",
      "620\n",
      "760\n",
      "2\n",
      "820\n",
      "570\n",
      "2\n",
      "590\n",
      "690\n",
      "770\n",
      "900\n",
      "750\n",
      "2\n",
      "500\n",
      "2\n",
      "596.316299438\n",
      "555.673370361\n",
      "840\n",
      "2\n",
      "608.199653625\n",
      "622.691879272\n",
      "2\n",
      "680\n",
      "601.752090454\n",
      "572.440605164\n",
      "540\n",
      "2\n",
      "634.023017883\n",
      "590\n",
      "670\n",
      "611.262741089\n",
      "430\n",
      "450\n",
      "2\n",
      "900\n",
      "2\n",
      "615.289993286\n",
      "490\n",
      "2\n",
      "633.390007019\n",
      "622.137451172\n",
      "2\n",
      "800\n",
      "810\n",
      "590\n",
      "780\n",
      "860\n",
      "657.771606445\n",
      "2\n",
      "890\n",
      "2\n",
      "641.194534302\n",
      "840\n",
      "2\n",
      "615.309944153\n",
      "649.239578247\n",
      "2\n",
      "589.235038757\n",
      "590.650482178\n",
      "850\n",
      "2\n",
      "637.110557556\n",
      "410\n",
      "2\n",
      "594.133338928\n",
      "592.113418579\n",
      "581.36390686\n",
      "633.480567932\n",
      "550\n",
      "620.945396423\n",
      "600.372924805\n",
      "770\n",
      "730\n",
      "870\n",
      "2\n",
      "618.854637146\n",
      "730\n",
      "624.078712463\n",
      "600\n",
      "592.890777588\n",
      "678.503646851\n",
      "2\n",
      "770\n",
      "600.61630249\n",
      "2\n",
      "614.143333435\n",
      "633.433494568\n",
      "634.264984131\n",
      "577.581481934\n",
      "2\n",
      "640\n",
      "590\n",
      "2\n",
      "700\n",
      "566.956596375\n",
      "570.443649292\n",
      "2\n",
      "603.508529663\n",
      "626.606559753\n",
      "2\n",
      "613.807754517\n",
      "614.729881287\n",
      "2\n",
      "720\n",
      "587.380943298\n",
      "578.779067993\n",
      "2\n",
      "780\n",
      "670\n",
      "2\n",
      "629.451713562\n",
      "661.901702881\n",
      "2\n",
      "600\n",
      "490\n",
      "2\n",
      "595.53401947\n",
      "632.133789062\n",
      "2\n",
      "607.42023468\n",
      "820\n",
      "820\n",
      "633.151016235\n",
      "624.325447083\n",
      "609.001960754\n",
      "2\n",
      "860\n",
      "572.738037109\n",
      "559.439086914\n",
      "800\n",
      "571.017112732\n",
      "605.773620605\n",
      "580\n",
      "560\n",
      "608.388977051\n",
      "2\n",
      "440\n",
      "2\n",
      "618.529548645\n",
      "562.113876343\n",
      "2\n",
      "638.066101074\n",
      "608.344116211\n",
      "631.978225708\n",
      "2\n",
      "800\n",
      "586.461906433\n",
      "2\n",
      "611.955413818\n",
      "519.719696045\n",
      "586.09413147\n",
      "610.647125244\n",
      "740\n",
      "2\n",
      "597.176818848\n",
      "664.781112671\n",
      "2\n",
      "614.974327087\n",
      "480\n",
      "410\n",
      "607.474327087\n",
      "600.083198547\n",
      "2\n",
      "618.854637146\n",
      "662.27432251\n",
      "2\n",
      "608.231925964\n",
      "400\n",
      "2\n",
      "619.324302673\n",
      "400\n",
      "2\n",
      "611.955413818\n",
      "520.160217285\n",
      "598.45954895\n",
      "2\n",
      "592.799720764\n",
      "571.459884644\n",
      "2\n",
      "632.698402405\n",
      "680\n",
      "578.567237854\n",
      "2\n",
      "611.955413818\n",
      "596.313323975\n",
      "637.884902954\n",
      "2\n",
      "638.066101074\n",
      "613.156814575\n",
      "688.41835022\n",
      "2\n",
      "621.503868103\n",
      "700\n",
      "639.294815063\n",
      "621.975975037\n",
      "2\n",
      "615.289993286\n",
      "545.400733948\n",
      "650.983352661\n",
      "634.693527222\n",
      "2\n",
      "618.343009949\n",
      "632.566566467\n",
      "597.977867126\n",
      "2\n",
      "615.289993286\n",
      "582.22984314\n",
      "2\n",
      "629.451713562\n",
      "480\n",
      "2\n",
      "606.447906494\n",
      "565.634384155\n",
      "2\n",
      "608.586883545\n",
      "626.065750122\n",
      "600.986747742\n",
      "2\n",
      "638.066101074\n",
      "628.30997467\n",
      "2\n",
      "628.022155762\n",
      "576.287956238\n",
      "602.62588501\n",
      "2\n",
      "632.698402405\n",
      "563.964767456\n",
      "622.915534973\n",
      "460\n",
      "2\n",
      "613.120689392\n",
      "598.607330322\n",
      "2\n",
      "636.518325806\n",
      "630\n",
      "2\n",
      "615.289993286\n",
      "550.169639587\n",
      "750\n",
      "2\n",
      "633.390007019\n",
      "574.258499146\n",
      "575.522499084\n",
      "770\n",
      "650.271835327\n",
      "530\n",
      "2\n",
      "613.807754517\n",
      "600.401992798\n",
      "1\n",
      "Epoch 1/1\n",
      "2816/2816 [==============================] - 9s 3ms/step - loss: 218.2801\n",
      "750\n",
      "610\n",
      "890\n",
      "585.909576416\n",
      "2\n",
      "800\n",
      "400\n",
      "520\n",
      "2\n",
      "820\n",
      "420\n",
      "2\n",
      "520\n",
      "2\n",
      "595.960159302\n",
      "430\n",
      "560\n",
      "621.87210083\n",
      "460\n",
      "2\n",
      "500\n",
      "2\n",
      "480\n",
      "2\n",
      "606.359176636\n",
      "560.17414093\n",
      "470\n",
      "790\n",
      "2\n",
      "550\n",
      "2\n",
      "850\n",
      "430\n",
      "565.996170044\n",
      "550\n",
      "603.988113403\n",
      "830\n",
      "562.308692932\n",
      "557.64503479\n",
      "2\n",
      "790\n",
      "880\n",
      "2\n",
      "510\n",
      "2\n",
      "490\n",
      "2\n",
      "616.839294434\n",
      "440\n",
      "2\n",
      "600.105934143\n",
      "610.767784119\n",
      "2\n",
      "440\n",
      "2\n",
      "620.288467407\n",
      "600\n",
      "2\n",
      "620.288467407\n",
      "550.454330444\n",
      "600\n",
      "810\n",
      "900\n",
      "557.814788818\n",
      "2\n",
      "780\n",
      "520\n",
      "2\n",
      "680\n",
      "450\n",
      "900\n",
      "2\n",
      "760\n",
      "598.072624207\n",
      "2\n",
      "606.258621216\n",
      "570.9815979\n",
      "560\n",
      "591.073188782\n",
      "480\n",
      "430\n",
      "870\n",
      "2\n",
      "613.250617981\n",
      "595.98526001\n",
      "620\n",
      "780\n",
      "2\n",
      "410\n",
      "2\n",
      "609.346694946\n",
      "593.046112061\n",
      "2\n",
      "410\n",
      "2\n",
      "577.171173096\n",
      "530\n",
      "2\n",
      "614.955978394\n",
      "610.871353149\n",
      "582.25933075\n",
      "630\n",
      "596.290359497\n",
      "2\n",
      "650\n",
      "450\n",
      "2\n",
      "609.672889709\n",
      "636.94065094\n",
      "596.983947754\n",
      "611.21723175\n",
      "2\n",
      "614.645576477\n",
      "610.303268433\n",
      "585.704498291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "610.707168579\n",
      "560.015296936\n",
      "608.151016235\n",
      "2\n",
      "598.312110901\n",
      "529.471130371\n",
      "610\n",
      "2\n",
      "500\n",
      "2\n",
      "599.153747559\n",
      "840\n",
      "2\n",
      "880\n",
      "599.297027588\n",
      "633.768959045\n",
      "2\n",
      "616.64680481\n",
      "589.946632385\n",
      "530.402412415\n",
      "584.336013794\n",
      "606.471862793\n",
      "577.2996521\n",
      "2\n",
      "760\n",
      "571.298522949\n",
      "2\n",
      "615.251922607\n",
      "596.968002319\n",
      "2\n",
      "589.164810181\n",
      "620.721054077\n",
      "580.526008606\n",
      "850\n",
      "2\n",
      "616.64680481\n",
      "633.417625427\n",
      "619.466056824\n",
      "2\n",
      "680\n",
      "582.328529358\n",
      "583.421592712\n",
      "595.67199707\n",
      "2\n",
      "591.891441345\n",
      "572.664070129\n",
      "2\n",
      "710\n",
      "542.392959595\n",
      "460\n",
      "2\n",
      "610\n",
      "553.348846436\n",
      "830\n",
      "2\n",
      "430\n",
      "2\n",
      "582.587356567\n",
      "680\n",
      "621.097946167\n",
      "2\n",
      "595.960159302\n",
      "556.952667236\n",
      "760\n",
      "584.345626831\n",
      "607.555809021\n",
      "615.375785828\n",
      "2\n",
      "592.961120605\n",
      "564.504890442\n",
      "2\n",
      "770\n",
      "800\n",
      "2\n",
      "595.960159302\n",
      "579.143371582\n",
      "548.529815674\n",
      "611.132354736\n",
      "599.740486145\n",
      "609.671630859\n",
      "2\n",
      "609.716377258\n",
      "593.874206543\n",
      "589.255409241\n",
      "606.042785645\n",
      "2\n",
      "607.87902832\n",
      "596.609725952\n",
      "598.359527588\n",
      "420\n",
      "2\n",
      "579.86076355\n",
      "740\n",
      "2\n",
      "618.287124634\n",
      "564.904251099\n",
      "592.351417542\n",
      "606.509017944\n",
      "619.600982666\n",
      "613.287506104\n",
      "586.66557312\n",
      "581.79599762\n",
      "2\n",
      "616.64680481\n",
      "730\n",
      "770\n",
      "2\n",
      "611.286468506\n",
      "400\n",
      "2\n",
      "800\n",
      "587.908744812\n",
      "646.835784912\n",
      "602.665557861\n",
      "592.190933228\n",
      "605.618400574\n",
      "2\n",
      "613.250617981\n",
      "530\n",
      "631.803092957\n",
      "2\n",
      "611.243019104\n",
      "613.0701828\n",
      "820\n",
      "2\n",
      "615.10974884\n",
      "607.806739807\n",
      "611.138076782\n",
      "619.115142822\n",
      "2\n",
      "589.164810181\n",
      "579.718513489\n",
      "609.719924927\n",
      "840\n",
      "593.82938385\n",
      "550.607337952\n",
      "2\n",
      "550\n",
      "637.89855957\n",
      "2\n",
      "810\n",
      "579.262504578\n",
      "562.499656677\n",
      "612.002372742\n",
      "2\n",
      "582.193870544\n",
      "571.521759033\n",
      "2\n",
      "606.810455322\n",
      "604.401283264\n",
      "2\n",
      "592.119064331\n",
      "591.239280701\n",
      "2\n",
      "591.891441345\n",
      "568.755912781\n",
      "2\n",
      "582.193870544\n",
      "576.399459839\n",
      "533.303794861\n",
      "2\n",
      "610.651855469\n",
      "625.122261047\n",
      "2\n",
      "574.243965149\n",
      "551.229362488\n",
      "2\n",
      "580\n",
      "597.57019043\n",
      "2\n",
      "593.243141174\n",
      "619.218521118\n",
      "2\n",
      "600\n",
      "1\n",
      "Epoch 1/1\n",
      "2944/2944 [==============================] - 9s 3ms/step - loss: 206.9501\n",
      "900\n",
      "2\n",
      "440\n",
      "2\n",
      "510\n",
      "2\n",
      "590\n",
      "490\n",
      "820\n",
      "420\n",
      "2\n",
      "820\n",
      "770\n",
      "2\n",
      "450\n",
      "2\n",
      "720\n",
      "630\n",
      "2\n",
      "490\n",
      "2\n",
      "620\n",
      "515.688591003\n",
      "810\n",
      "2\n",
      "640.280990601\n",
      "690\n",
      "880\n",
      "540\n",
      "790\n",
      "490\n",
      "550\n",
      "2\n",
      "627.117080688\n",
      "570\n",
      "2\n",
      "820\n",
      "670\n",
      "595.95703125\n",
      "607.840232849\n",
      "2\n",
      "440\n",
      "2\n",
      "540\n",
      "2\n",
      "570\n",
      "609.49634552\n",
      "670\n",
      "840\n",
      "620\n",
      "410\n",
      "2\n",
      "480\n",
      "2\n",
      "410\n",
      "2\n",
      "630\n",
      "850\n",
      "2\n",
      "631.103286743\n",
      "570\n",
      "2\n",
      "609.248657227\n",
      "510\n",
      "598.046531677\n",
      "585.24230957\n",
      "2\n",
      "620\n",
      "850\n",
      "2\n",
      "820\n",
      "622.831459045\n",
      "2\n",
      "630\n",
      "540\n",
      "760\n",
      "820\n",
      "2\n",
      "606.067504883\n",
      "510\n",
      "820\n",
      "440\n",
      "557.687187195\n",
      "530\n",
      "530\n",
      "2\n",
      "580\n",
      "661.407470703\n",
      "2\n",
      "620.861206055\n",
      "720\n",
      "740\n",
      "820\n",
      "660\n",
      "2\n",
      "628.674163818\n",
      "770\n",
      "740\n",
      "638.274688721\n",
      "2\n",
      "656.131210327\n",
      "566.212387085\n",
      "2\n",
      "622.992668152\n",
      "550\n",
      "520\n",
      "617.365150452\n",
      "880\n",
      "2\n",
      "651.98928833\n",
      "750\n",
      "2\n",
      "640.280990601\n",
      "420\n",
      "530\n",
      "574.478988647\n",
      "2\n",
      "490\n",
      "2\n",
      "624.165534973\n",
      "850\n",
      "594.172859192\n",
      "551.054725647\n",
      "740\n",
      "2\n",
      "628.356781006\n",
      "594.479103088\n",
      "639.454154968\n",
      "669.613571167\n",
      "654.881744385\n",
      "680\n",
      "610\n",
      "2\n",
      "622.992668152\n",
      "598.820838928\n",
      "670\n",
      "760\n",
      "2\n",
      "632.174339294\n",
      "623.508415222\n",
      "500\n",
      "590.796585083\n",
      "588.631324768\n",
      "2\n",
      "638.825149536\n",
      "750\n",
      "640\n",
      "2\n",
      "638.561172485\n",
      "650.396499634\n",
      "2\n",
      "600\n",
      "720\n",
      "677.950210571\n",
      "2\n",
      "642.502212524\n",
      "531.757736206\n",
      "578.418731689\n",
      "590.16002655\n",
      "2\n",
      "670\n",
      "507.602081299\n",
      "558.781852722\n",
      "597.153816223\n",
      "660\n",
      "2\n",
      "666.35635376\n",
      "529.740562439\n",
      "550\n",
      "2\n",
      "659.356307983\n",
      "630.589599609\n",
      "2\n",
      "480\n",
      "2\n",
      "646.780395508\n",
      "631.904678345\n",
      "2\n",
      "637.823410034\n",
      "544.453086853\n",
      "569.949455261\n",
      "672.107315063\n",
      "615.463256836\n",
      "599.379730225\n",
      "2\n",
      "629.578285217\n",
      "594.439048767\n",
      "2\n",
      "470\n",
      "2\n",
      "606.41368866\n",
      "502.911643982\n",
      "480\n",
      "608.892478943\n",
      "2\n",
      "647.518081665\n",
      "547.020683289\n",
      "570\n",
      "810\n",
      "529.460487366\n",
      "561.421699524\n",
      "599.932479858\n",
      "2\n",
      "632.946014404\n",
      "509.319190979\n",
      "583.169937134\n",
      "520\n",
      "2\n",
      "644.834747314\n",
      "600.311431885\n",
      "656.294555664\n",
      "603.429145813\n",
      "2\n",
      "638.825149536\n",
      "530.408058167\n",
      "2\n",
      "596.050949097\n",
      "505.720787048\n",
      "708.909835815\n",
      "2\n",
      "635.892524719\n",
      "568.507614136\n",
      "2\n",
      "638.561172485\n",
      "511.787872314\n",
      "608.95866394\n",
      "604.294586182\n",
      "2\n",
      "631.103286743\n",
      "496.286964417\n",
      "620\n",
      "579.95388031\n",
      "2\n",
      "637.823410034\n",
      "607.311553955\n",
      "602.592735291\n",
      "586.651229858\n",
      "2\n",
      "720\n",
      "641.995925903\n",
      "2\n",
      "659.364700317\n",
      "603.263206482\n",
      "666.262512207\n",
      "2\n",
      "615.274963379\n",
      "610.563011169\n",
      "2\n",
      "750\n",
      "606.530227661\n",
      "730\n",
      "602.722473145\n",
      "570.114173889\n",
      "2\n",
      "631.103286743\n",
      "545.712280273\n",
      "2\n",
      "619.179039001\n",
      "750\n",
      "556.378860474\n",
      "2\n",
      "581.257209778\n",
      "450\n",
      "2\n",
      "606.41368866\n",
      "760\n",
      "2\n",
      "629.034347534\n",
      "628.565444946\n",
      "2\n",
      "652.465057373\n",
      "608.193740845\n",
      "622.930793762\n",
      "609.696044922\n",
      "2\n",
      "621.571273804\n",
      "680\n",
      "601.009750366\n",
      "860\n",
      "558.193359375\n",
      "629.51625824\n",
      "564.162445068\n",
      "626.910667419\n",
      "639.610710144\n",
      "2\n",
      "609.743461609\n",
      "850\n",
      "2\n",
      "608.937034607\n",
      "568.751792908\n",
      "588.901977539\n",
      "527.127380371\n",
      "2\n",
      "638.561172485\n",
      "1\n",
      "Epoch 1/1\n",
      "3072/3072 [==============================] - 10s 3ms/step - loss: 201.8143\n",
      "890\n",
      "2\n",
      "400\n",
      "2\n",
      "680\n",
      "840\n",
      "2\n",
      "720\n",
      "570\n",
      "830\n",
      "2\n",
      "600.149993896\n",
      "800\n",
      "880\n",
      "2\n",
      "410\n",
      "2\n",
      "520\n",
      "2\n",
      "560\n",
      "550\n",
      "2\n",
      "609.471549988\n",
      "900\n",
      "2\n",
      "750\n",
      "550\n",
      "500\n",
      "2\n",
      "500\n",
      "2\n",
      "612.004203796\n",
      "490\n",
      "2\n",
      "440\n",
      "2\n",
      "750\n",
      "550\n",
      "580\n",
      "2\n",
      "850\n",
      "770\n",
      "2\n",
      "609.632530212\n",
      "620\n",
      "2\n",
      "634.844245911\n",
      "760\n",
      "410\n",
      "2\n",
      "860\n",
      "553.829917908\n",
      "750\n",
      "860\n",
      "900\n",
      "2\n",
      "750\n",
      "700\n",
      "850\n",
      "2\n",
      "620\n",
      "440\n",
      "2\n",
      "628.256149292\n",
      "610\n",
      "626.226997375\n",
      "450\n",
      "2\n",
      "460\n",
      "2\n",
      "840\n",
      "870\n",
      "700\n",
      "680\n",
      "2\n",
      "608.058776855\n",
      "760\n",
      "587.940979004\n",
      "570\n",
      "840\n",
      "2\n",
      "810\n",
      "630\n",
      "2\n",
      "730\n",
      "562.474975586\n",
      "646.498794556\n",
      "2\n",
      "617.501449585\n",
      "609.356079102\n",
      "2\n",
      "690\n",
      "780\n",
      "2\n",
      "450\n",
      "2\n",
      "598.412704468\n",
      "770\n",
      "2\n",
      "584.45690155\n",
      "583.360939026\n",
      "2\n",
      "625.172996521\n",
      "600\n",
      "630\n",
      "2\n",
      "590\n",
      "561.921386719\n",
      "603.250579834\n",
      "2\n",
      "440\n",
      "2\n",
      "540\n",
      "780\n",
      "580.495567322\n",
      "460\n",
      "2\n",
      "585.597572327\n",
      "566.685523987\n",
      "644.248580933\n",
      "2\n",
      "610.054473877\n",
      "626.057090759\n",
      "520\n",
      "2\n",
      "625.401649475\n",
      "420\n",
      "2\n",
      "610\n",
      "581.887626648\n",
      "597.488136292\n",
      "890\n",
      "2\n",
      "900\n",
      "2\n",
      "602.861633301\n",
      "670\n",
      "2\n",
      "490\n",
      "2\n",
      "607.473258972\n",
      "586.33972168\n",
      "2\n",
      "900\n",
      "2\n",
      "609.632530212\n",
      "567.146110535\n",
      "569.046554565\n",
      "2\n",
      "620.520133972\n",
      "517.742843628\n",
      "587.683029175\n",
      "2\n",
      "617.501449585\n",
      "690\n",
      "2\n",
      "630.439186096\n",
      "551.534614563\n",
      "650\n",
      "2\n",
      "601.289367676\n",
      "579.458885193\n",
      "2\n",
      "607.967605591\n",
      "533.02532196\n",
      "553.890419006\n",
      "605.650138855\n",
      "2\n",
      "840\n",
      "610\n",
      "590.973930359\n",
      "640\n",
      "605.427284241\n",
      "520\n",
      "624.86114502\n",
      "563.443183899\n",
      "656.886444092\n",
      "591.967887878\n",
      "2\n",
      "617.414131165\n",
      "587.153282166\n",
      "650.830154419\n",
      "659.831390381\n",
      "2\n",
      "584.511795044\n",
      "600\n",
      "592.623329163\n",
      "2\n",
      "460\n",
      "2\n",
      "600.149993896\n",
      "640\n",
      "700\n",
      "622.728919983\n",
      "534.718017578\n",
      "2\n",
      "596.224060059\n",
      "533.306999207\n",
      "560.470046997\n",
      "637.222862244\n",
      "603.44783783\n",
      "623.44833374\n",
      "2\n",
      "880\n",
      "585.502204895\n",
      "2\n",
      "604.557189941\n",
      "840\n",
      "608.337936401\n",
      "535.698280334\n",
      "661.780090332\n",
      "2\n",
      "582.005729675\n",
      "530.130767822\n",
      "527.844924927\n",
      "460\n",
      "590\n",
      "559.10369873\n",
      "571.173591614\n",
      "2\n",
      "595.463066101\n",
      "578.775787354\n",
      "2\n",
      "589.83959198\n",
      "628.276367188\n",
      "654.050140381\n",
      "2\n",
      "580.059204102\n",
      "563.601837158\n",
      "2\n",
      "584.511795044\n",
      "580.998077393\n",
      "2\n",
      "614.87361908\n",
      "639.856872559\n",
      "2\n",
      "600.149993896\n",
      "616.361045837\n",
      "2\n",
      "600.149993896\n",
      "521.680488586\n",
      "550.441360474\n",
      "648.679504395\n",
      "2\n",
      "616.917419434\n",
      "585.492782593\n",
      "710\n",
      "2\n",
      "601.289367676\n",
      "631.683349609\n",
      "2\n",
      "820\n",
      "810\n",
      "2\n",
      "600.149993896\n",
      "631.201095581\n",
      "2\n",
      "627.108154297\n",
      "602.358283997\n",
      "2\n",
      "604.557189941\n",
      "547.315406799\n",
      "574.657554626\n",
      "2\n",
      "628.256149292\n",
      "603.087730408\n",
      "635.561294556\n",
      "2\n",
      "630.439186096\n",
      "641.110992432\n",
      "2\n",
      "400\n",
      "2\n",
      "440\n",
      "2\n",
      "615.707626343\n",
      "509.804153442\n",
      "546.164779663\n",
      "651.031646729\n",
      "2\n",
      "420\n",
      "2\n",
      "598.021736145\n",
      "644.906997681\n",
      "2\n",
      "600.149993896\n",
      "556.169281006\n",
      "537.771911621\n",
      "480\n",
      "2\n",
      "609.765472412\n",
      "569.315071106\n",
      "810\n",
      "621.60282135\n",
      "400\n",
      "2\n",
      "600.149993896\n",
      "637.455711365\n",
      "2\n",
      "830\n",
      "564.183578491\n",
      "566.832466125\n",
      "594.110374451\n",
      "514.253311157\n",
      "651.723175049\n",
      "639.171524048\n",
      "636.271438599\n",
      "598.833732605\n",
      "588.504600525\n",
      "2\n",
      "820\n",
      "1\n",
      "Epoch 1/1\n",
      "3200/3200 [==============================] - 10s 3ms/step - loss: 221.4506\n",
      "840\n",
      "500\n",
      "800\n",
      "2\n",
      "420\n",
      "2\n",
      "510\n",
      "2\n",
      "630\n",
      "600\n",
      "2\n",
      "470\n",
      "2\n",
      "740\n",
      "440\n",
      "2\n",
      "500\n",
      "2\n",
      "440\n",
      "2\n",
      "890\n",
      "2\n",
      "880\n",
      "710\n",
      "730\n",
      "690\n",
      "690\n",
      "720\n",
      "890\n",
      "2\n",
      "640\n",
      "550\n",
      "2\n",
      "530\n",
      "2\n",
      "420\n",
      "2\n",
      "617.572021484\n",
      "680\n",
      "450\n",
      "640\n",
      "680\n",
      "770\n",
      "2\n",
      "790\n",
      "790\n",
      "900\n",
      "2\n",
      "880\n",
      "2\n",
      "593.615379333\n",
      "560.827674866\n",
      "555.657539368\n",
      "520\n",
      "500\n",
      "2\n",
      "605.83896637\n",
      "860\n",
      "780\n",
      "595.264816284\n",
      "2\n",
      "615.977973938\n",
      "560\n",
      "633.261070251\n",
      "2\n",
      "582.620353699\n",
      "600\n",
      "2\n",
      "592.383995056\n",
      "490\n",
      "400\n",
      "580\n",
      "2\n",
      "588.996009827\n",
      "622.656326294\n",
      "2\n",
      "590.911369324\n",
      "571.860771179\n",
      "550\n",
      "820\n",
      "2\n",
      "450.669059753\n",
      "2\n",
      "860\n",
      "730\n",
      "830\n",
      "770\n",
      "680\n",
      "2\n",
      "650\n",
      "780\n",
      "2\n",
      "420\n",
      "2\n",
      "870\n",
      "605.876541138\n",
      "900\n",
      "557.963485718\n",
      "820\n",
      "2\n",
      "603.00907135\n",
      "574.736061096\n",
      "2\n",
      "850\n",
      "710\n",
      "2\n",
      "596.1353302\n",
      "606.057853699\n",
      "2\n",
      "577.667655945\n",
      "880\n",
      "576.614494324\n",
      "800\n",
      "2\n",
      "589.98008728\n",
      "550.300102234\n",
      "643.080368042\n",
      "2\n",
      "589.987945557\n",
      "610\n",
      "2\n",
      "591.539802551\n",
      "581.469154358\n",
      "2\n",
      "587.733955383\n",
      "548.082885742\n",
      "583.415565491\n",
      "2\n",
      "568.778419495\n",
      "770\n",
      "582.819595337\n",
      "595.262298584\n",
      "2\n",
      "592.691955566\n",
      "564.091377258\n",
      "579.894523621\n",
      "2\n",
      "570\n",
      "680\n",
      "2\n",
      "591.539802551\n",
      "620\n",
      "2\n",
      "740\n",
      "524.034690857\n",
      "568.649787903\n",
      "2\n",
      "601.809921265\n",
      "860\n",
      "2\n",
      "593.30745697\n",
      "660\n",
      "557.335968018\n",
      "577.864265442\n",
      "538.105964661\n",
      "560\n",
      "2\n",
      "850\n",
      "559.493217468\n",
      "551.321868896\n",
      "591.014404297\n",
      "2\n",
      "579.095535278\n",
      "730\n",
      "590.442428589\n",
      "551.751785278\n",
      "2\n",
      "617.572021484\n",
      "640\n",
      "2\n",
      "480\n",
      "2\n",
      "610.725975037\n",
      "544.50881958\n",
      "586.306991577\n",
      "2\n",
      "602.542037964\n",
      "558.044967651\n",
      "500\n",
      "561.272544861\n",
      "2\n",
      "530\n",
      "2\n",
      "574.340629578\n",
      "531.512260437\n",
      "640\n",
      "580\n",
      "2\n",
      "597.593727112\n",
      "563.280487061\n",
      "563.987197876\n",
      "740\n",
      "2\n",
      "572.780914307\n",
      "810\n",
      "590.599937439\n",
      "575.203857422\n",
      "2\n",
      "569.701881409\n",
      "524.132080078\n",
      "564.536476135\n",
      "568.019142151\n",
      "2\n",
      "572.780914307\n",
      "573.316955566\n",
      "2\n",
      "593.169708252\n",
      "720\n",
      "2\n",
      "587.340545654\n",
      "568.326034546\n",
      "2\n",
      "610.740585327\n",
      "632.323074341\n",
      "2\n",
      "760\n",
      "539.352645874\n",
      "2\n",
      "601.809921265\n",
      "579.191017151\n",
      "620\n",
      "2\n",
      "582.847290039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499.926452637\n",
      "670\n",
      "2\n",
      "630\n",
      "650\n",
      "583.954048157\n",
      "602.637138367\n",
      "565.632209778\n",
      "562.828330994\n",
      "575.174713135\n",
      "2\n",
      "593.169708252\n",
      "599.949455261\n",
      "2\n",
      "406.693000793\n",
      "2\n",
      "602.542037964\n",
      "522.329483032\n",
      "569.380950928\n",
      "2\n",
      "596.1353302\n",
      "598.141136169\n",
      "2\n",
      "579.227294922\n",
      "571.376304626\n",
      "540.315742493\n",
      "520\n",
      "850\n",
      "529.647102356\n",
      "612.397422791\n",
      "2\n",
      "617.572021484\n",
      "598.441162109\n",
      "603.700332642\n",
      "2\n",
      "586.812477112\n",
      "573.627548218\n",
      "548.887481689\n",
      "552.269210815\n",
      "2\n",
      "433.764419556\n",
      "2\n",
      "593.615379333\n",
      "601.284980774\n",
      "2\n",
      "750\n",
      "576.436500549\n",
      "590.97984314\n",
      "641.708297729\n",
      "579.014129639\n",
      "592.831306458\n",
      "2\n",
      "572.780914307\n",
      "608.88217926\n",
      "608.92250061\n",
      "2\n",
      "610.740585327\n",
      "510\n",
      "572.944221497\n",
      "561.370697021\n",
      "664.84703064\n",
      "2\n",
      "593.148384094\n",
      "598.855476379\n",
      "2\n",
      "582.852630615\n",
      "574.574699402\n",
      "2\n",
      "580.492134094\n",
      "585.210762024\n",
      "2\n",
      "510\n",
      "2\n",
      "400\n",
      "2\n",
      "603.00907135\n",
      "860\n",
      "2\n",
      "605.83896637\n",
      "623.94695282\n",
      "2\n",
      "610.740585327\n",
      "596.166687012\n",
      "2\n",
      "407.952156067\n",
      "2\n",
      "595.802574158\n",
      "535.886268616\n",
      "2\n",
      "570.917243958\n",
      "1\n",
      "Epoch 1/1\n",
      "3328/3328 [==============================] - 10s 3ms/step - loss: 210.8313\n",
      "760\n",
      "510\n",
      "840\n",
      "420\n",
      "750\n",
      "2\n",
      "641.283416748\n",
      "830\n",
      "410\n",
      "2\n",
      "630\n",
      "420\n",
      "2\n",
      "597.288208008\n",
      "616.916542053\n",
      "2\n",
      "650\n",
      "610\n",
      "2\n",
      "400\n",
      "2\n",
      "800\n",
      "740\n",
      "2\n",
      "640\n",
      "530\n",
      "670\n",
      "2\n",
      "470\n",
      "2\n",
      "830\n",
      "581.303062439\n",
      "420\n",
      "633.991203308\n",
      "629.637107849\n",
      "810\n",
      "620\n",
      "2\n",
      "641.283416748\n",
      "578.713989258\n",
      "2\n",
      "860\n",
      "820\n",
      "2\n",
      "850\n",
      "530\n",
      "2\n",
      "780\n",
      "540\n",
      "540\n",
      "2\n",
      "430\n",
      "2\n",
      "551.143836975\n",
      "580\n",
      "760\n",
      "500\n",
      "600\n",
      "2\n",
      "612.440986633\n",
      "572.536621094\n",
      "760\n",
      "591.046676636\n",
      "590\n",
      "602.62550354\n",
      "850\n",
      "460\n",
      "581.849975586\n",
      "2\n",
      "594.416770935\n",
      "740\n",
      "2\n",
      "740\n",
      "639.089927673\n",
      "490\n",
      "740\n",
      "2\n",
      "583.6743927\n",
      "850\n",
      "597.555885315\n",
      "610\n",
      "640\n",
      "2\n",
      "581.258850098\n",
      "544.509239197\n",
      "568.012542725\n",
      "710\n",
      "2\n",
      "680\n",
      "591.924514771\n",
      "480\n",
      "2\n",
      "637.281761169\n",
      "600\n",
      "730\n",
      "616.398696899\n",
      "2\n",
      "800\n",
      "577.696685791\n",
      "730\n",
      "720\n",
      "2\n",
      "660\n",
      "565.201797485\n",
      "480\n",
      "2\n",
      "599.416046143\n",
      "629.969673157\n",
      "2\n",
      "830\n",
      "592.015304565\n",
      "2\n",
      "603.032264709\n",
      "610\n",
      "562.268333435\n",
      "582.35042572\n",
      "710\n",
      "553.705673218\n",
      "586.337127686\n",
      "2\n",
      "670\n",
      "450\n",
      "600\n",
      "700\n",
      "605.500640869\n",
      "578.498153687\n",
      "611.402816772\n",
      "2\n",
      "641.283416748\n",
      "603.363647461\n",
      "2\n",
      "790\n",
      "570.685386658\n",
      "680\n",
      "570.220031738\n",
      "624.468421936\n",
      "556.699066162\n",
      "2\n",
      "602.101783752\n",
      "760\n",
      "2\n",
      "610.550384521\n",
      "577.337875366\n",
      "599.258880615\n",
      "594.323959351\n",
      "2\n",
      "760\n",
      "580\n",
      "568.447189331\n",
      "608.910369873\n",
      "2\n",
      "602.54360199\n",
      "630\n",
      "2\n",
      "597.288208008\n",
      "470\n",
      "2\n",
      "597.234764099\n",
      "600.861778259\n",
      "620.12928009\n",
      "2\n",
      "622.016487122\n",
      "680\n",
      "606.917762756\n",
      "609.243888855\n",
      "569.723892212\n",
      "595.028915405\n",
      "572.799339294\n",
      "2\n",
      "627.076721191\n",
      "600.101470947\n",
      "618.30871582\n",
      "547.982292175\n",
      "670.380249023\n",
      "599.771957397\n",
      "2\n",
      "551.527252197\n",
      "537.455253601\n",
      "594.888725281\n",
      "562.790145874\n",
      "579.918899536\n",
      "2\n",
      "470\n",
      "2\n",
      "637.281761169\n",
      "646.386260986\n",
      "2\n",
      "605.850830078\n",
      "614.38331604\n",
      "660\n",
      "582.492103577\n",
      "539.018287659\n",
      "602.410850525\n",
      "520\n",
      "632.27180481\n",
      "583.958625793\n",
      "623.293914795\n",
      "657.829818726\n",
      "2\n",
      "621.073760986\n",
      "555.822792053\n",
      "584.266395569\n",
      "700.03288269\n",
      "2\n",
      "576.479110718\n",
      "610.624542236\n",
      "620.879554749\n",
      "750\n",
      "2\n",
      "890\n",
      "450\n",
      "521.262779236\n",
      "596.666793823\n",
      "2\n",
      "594.416770935\n",
      "657.88734436\n",
      "2\n",
      "621.073760986\n",
      "535.856704712\n",
      "565.189590454\n",
      "583.909835815\n",
      "667.776947021\n",
      "2\n",
      "626.758270264\n",
      "633.549079895\n",
      "2\n",
      "516.21181488\n",
      "2\n",
      "582.352180481\n",
      "639.204978943\n",
      "2\n",
      "603.032264709\n",
      "561.577339172\n",
      "564.513587952\n",
      "599.591407776\n",
      "649.162979126\n",
      "2\n",
      "629.408226013\n",
      "530.163803101\n",
      "589.948883057\n",
      "603.767089844\n",
      "654.162979126\n",
      "2\n",
      "630.760002136\n",
      "593.68976593\n",
      "650.473937988\n",
      "2\n",
      "603.722839355\n",
      "750\n",
      "610.606803894\n",
      "570.898628235\n",
      "586.644172668\n",
      "609.015312195\n",
      "2\n",
      "614.775276184\n",
      "657.938690186\n",
      "2\n",
      "600.17742157\n",
      "590.091323853\n",
      "2\n",
      "610.868835449\n",
      "1\n",
      "Epoch 1/1\n",
      "3456/3456 [==============================] - 11s 3ms/step - loss: 204.5290\n",
      "450\n",
      "2\n",
      "710\n",
      "740\n",
      "2\n",
      "640\n",
      "770\n",
      "615.038909912\n",
      "2\n",
      "780\n",
      "860\n",
      "2\n",
      "650\n",
      "450\n",
      "420\n",
      "760\n",
      "660\n",
      "700.807800293\n",
      "570\n",
      "2\n",
      "860\n",
      "750\n",
      "840\n",
      "2\n",
      "611.952095032\n",
      "570\n",
      "870\n",
      "2\n",
      "540\n",
      "610\n",
      "2\n",
      "600\n",
      "550\n",
      "2\n",
      "500\n",
      "2\n",
      "860\n",
      "660\n",
      "601.974372864\n",
      "500\n",
      "2\n",
      "440\n",
      "2\n",
      "676.649856567\n"
     ]
    }
   ],
   "source": [
    "img = get_img()\n",
    "while(True):\n",
    "    mistrust = mistrust*0.99\n",
    "    press_time = network(model,img,1-mistrust)[0][0]\n",
    "    jump(press_time*10)\n",
    "    time.sleep(2.3+press_time/200)\n",
    "    img_new = get_img()\n",
    "    if fail(img_new):\n",
    "        jump(2)\n",
    "        time.sleep(0.8)\n",
    "        img_new = get_img()\n",
    "    elif success(img_new,img):\n",
    "        if n_sample == 0:\n",
    "            train_x = img\n",
    "            train_y = press_time.reshape(1,1)\n",
    "        else:\n",
    "            train_x = np.concatenate((train_x,img),axis=0)\n",
    "            train_y = np.concatenate((train_y,press_time.reshape(1,1)),axis=0)\n",
    "        n_sample+=1\n",
    "        if n_sample%128==0:\n",
    "            mistrust = 1\n",
    "            print(mistrust)\n",
    "            model.fit(train_x,train_y)\n",
    "            np.save('train_x',train_x)\n",
    "            np.save('train_y',train_y)\n",
    "    img = img_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-c26724e924ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    train(model,img,70)\n",
    "    print(network(model,img,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model-50.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('my_model-50.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network(model,img,1-mistrust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jump(math.ceil(400.1123))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.save('train_x',train_x)\n",
    "np.save('train_y',train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 181, 101, 8)       80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 45, 25, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 43, 23, 8)         584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 10, 5, 8)          0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 10, 5, 8)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 128)               51328     \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 52,121\n",
      "Trainable params: 52,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6656 samples, validate on 1664 samples\n",
      "Epoch 1/1\n",
      "6656/6656 [==============================] - 2s 288us/step - loss: 4159.0802 - val_loss: 4348.3201\n",
      "Train on 6656 samples, validate on 1664 samples\n",
      "Epoch 1/1\n",
      "6656/6656 [==============================] - 2s 251us/step - loss: 4140.9028 - val_loss: 4348.3201\n",
      "Train on 6656 samples, validate on 1664 samples\n",
      "Epoch 1/1\n",
      "6656/6656 [==============================] - 2s 247us/step - loss: 4140.9028 - val_loss: 4348.3201\n",
      "Train on 6656 samples, validate on 1664 samples\n",
      "Epoch 1/1\n",
      "6656/6656 [==============================] - 2s 255us/step - loss: 4140.9028 - val_loss: 4348.3201\n",
      "Train on 6656 samples, validate on 1664 samples\n",
      "Epoch 1/1\n",
      "1312/6656 [====>.........................] - ETA: 1s - loss: 4145.0962"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-46b7eddc1a36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    model.fit(train_x,train_y,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6656 samples, validate on 1664 samples\n",
      "Epoch 1/300\n",
      "6656/6656 [==============================] - 2s 317us/step - loss: 477.4919 - val_loss: 162.4638\n",
      "Epoch 2/300\n",
      "6656/6656 [==============================] - 2s 252us/step - loss: 181.9958 - val_loss: 249.9112\n",
      "Epoch 3/300\n",
      "6656/6656 [==============================] - 2s 261us/step - loss: 159.8648 - val_loss: 239.4574\n",
      "Epoch 4/300\n",
      "6656/6656 [==============================] - 2s 257us/step - loss: 154.5732 - val_loss: 127.9332\n",
      "Epoch 5/300\n",
      "6656/6656 [==============================] - 2s 255us/step - loss: 144.1473 - val_loss: 79.8146\n",
      "Epoch 6/300\n",
      "6656/6656 [==============================] - 2s 284us/step - loss: 148.4117 - val_loss: 115.3470\n",
      "Epoch 7/300\n",
      "6656/6656 [==============================] - 2s 308us/step - loss: 135.7729 - val_loss: 114.9308\n",
      "Epoch 8/300\n",
      "6656/6656 [==============================] - 2s 280us/step - loss: 147.0888 - val_loss: 98.0207\n",
      "Epoch 9/300\n",
      "6656/6656 [==============================] - 2s 265us/step - loss: 128.7862 - val_loss: 105.9872\n",
      "Epoch 10/300\n",
      "6656/6656 [==============================] - 2s 305us/step - loss: 135.1842 - val_loss: 149.0867\n",
      "Epoch 11/300\n",
      "6656/6656 [==============================] - 2s 305us/step - loss: 131.5680 - val_loss: 82.3193\n",
      "Epoch 12/300\n",
      "6656/6656 [==============================] - 2s 273us/step - loss: 127.8143 - val_loss: 62.6480\n",
      "Epoch 13/300\n",
      "6656/6656 [==============================] - 2s 307us/step - loss: 129.0611 - val_loss: 77.3378\n",
      "Epoch 14/300\n",
      "6656/6656 [==============================] - 2s 268us/step - loss: 130.3275 - val_loss: 85.9920\n",
      "Epoch 15/300\n",
      "6656/6656 [==============================] - 2s 260us/step - loss: 122.9507 - val_loss: 75.4097\n",
      "Epoch 16/300\n",
      "6656/6656 [==============================] - 2s 277us/step - loss: 127.7169 - val_loss: 73.2948\n",
      "Epoch 17/300\n",
      "6656/6656 [==============================] - 2s 291us/step - loss: 117.8603 - val_loss: 65.3104\n",
      "Epoch 18/300\n",
      "6656/6656 [==============================] - 2s 321us/step - loss: 117.9210 - val_loss: 72.8534\n",
      "Epoch 19/300\n",
      "6656/6656 [==============================] - 2s 301us/step - loss: 120.8359 - val_loss: 107.8506\n",
      "Epoch 20/300\n",
      "6656/6656 [==============================] - 2s 316us/step - loss: 112.7366 - val_loss: 71.4165\n",
      "Epoch 21/300\n",
      "6656/6656 [==============================] - 2s 316us/step - loss: 121.4938 - val_loss: 68.1001\n",
      "Epoch 22/300\n",
      "6656/6656 [==============================] - 2s 311us/step - loss: 115.1709 - val_loss: 109.5807\n",
      "Epoch 23/300\n",
      "6656/6656 [==============================] - 2s 263us/step - loss: 116.4066 - val_loss: 70.2267\n",
      "Epoch 24/300\n",
      "6656/6656 [==============================] - 2s 296us/step - loss: 115.7600 - val_loss: 57.8145\n",
      "Epoch 25/300\n",
      "6656/6656 [==============================] - 2s 250us/step - loss: 113.2820 - val_loss: 62.7434\n",
      "Epoch 26/300\n",
      "6656/6656 [==============================] - 2s 252us/step - loss: 111.4823 - val_loss: 58.1070\n",
      "Epoch 27/300\n",
      "6656/6656 [==============================] - 2s 266us/step - loss: 111.6269 - val_loss: 59.0441\n",
      "Epoch 28/300\n",
      "6656/6656 [==============================] - 2s 278us/step - loss: 107.5802 - val_loss: 62.6699\n",
      "Epoch 29/300\n",
      "6656/6656 [==============================] - 2s 309us/step - loss: 110.5567 - val_loss: 79.1980\n",
      "Epoch 30/300\n",
      "6656/6656 [==============================] - 2s 310us/step - loss: 112.6720 - val_loss: 64.6156\n",
      "Epoch 31/300\n",
      "6656/6656 [==============================] - 2s 290us/step - loss: 106.2899 - val_loss: 59.1297\n",
      "Epoch 32/300\n",
      "6656/6656 [==============================] - 2s 249us/step - loss: 110.9391 - val_loss: 60.5848\n",
      "Epoch 33/300\n",
      "6656/6656 [==============================] - 2s 279us/step - loss: 103.5757 - val_loss: 59.2874\n",
      "Epoch 34/300\n",
      "6656/6656 [==============================] - 2s 297us/step - loss: 108.3127 - val_loss: 78.2110\n",
      "Epoch 35/300\n",
      "6656/6656 [==============================] - 2s 255us/step - loss: 103.6321 - val_loss: 56.8569\n",
      "Epoch 36/300\n",
      "6656/6656 [==============================] - 2s 298us/step - loss: 103.9792 - val_loss: 58.0531\n",
      "Epoch 37/300\n",
      "6656/6656 [==============================] - 2s 316us/step - loss: 104.6674 - val_loss: 58.9068\n",
      "Epoch 38/300\n",
      "6656/6656 [==============================] - 2s 322us/step - loss: 103.1738 - val_loss: 59.8792\n",
      "Epoch 39/300\n",
      "6656/6656 [==============================] - 2s 297us/step - loss: 104.5172 - val_loss: 57.6901\n",
      "Epoch 40/300\n",
      "6656/6656 [==============================] - 2s 298us/step - loss: 104.6362 - val_loss: 67.0792\n",
      "Epoch 41/300\n",
      "6656/6656 [==============================] - 2s 251us/step - loss: 105.3212 - val_loss: 60.0779\n",
      "Epoch 42/300\n",
      "6656/6656 [==============================] - 2s 297us/step - loss: 101.1193 - val_loss: 54.5832\n",
      "Epoch 43/300\n",
      "6656/6656 [==============================] - 2s 300us/step - loss: 101.4295 - val_loss: 66.7540\n",
      "Epoch 44/300\n",
      "6656/6656 [==============================] - 2s 287us/step - loss: 99.0394 - val_loss: 59.3463\n",
      "Epoch 45/300\n",
      "6656/6656 [==============================] - 2s 272us/step - loss: 99.1240 - val_loss: 58.2472\n",
      "Epoch 46/300\n",
      "6656/6656 [==============================] - 2s 314us/step - loss: 103.4118 - val_loss: 65.0277\n",
      "Epoch 47/300\n",
      "6656/6656 [==============================] - 2s 323us/step - loss: 101.8818 - val_loss: 76.0500\n",
      "Epoch 48/300\n",
      "6656/6656 [==============================] - 2s 266us/step - loss: 101.1078 - val_loss: 71.3545\n",
      "Epoch 49/300\n",
      "6656/6656 [==============================] - 2s 240us/step - loss: 98.9528 - val_loss: 70.0066\n",
      "Epoch 50/300\n",
      "6656/6656 [==============================] - 2s 269us/step - loss: 99.6953 - val_loss: 67.5798\n",
      "Epoch 51/300\n",
      "6656/6656 [==============================] - 2s 291us/step - loss: 97.9869 - val_loss: 74.4028\n",
      "Epoch 52/300\n",
      "6656/6656 [==============================] - 2s 279us/step - loss: 96.3445 - val_loss: 70.8138\n",
      "Epoch 53/300\n",
      "6656/6656 [==============================] - 2s 278us/step - loss: 96.4024 - val_loss: 82.9559\n",
      "Epoch 54/300\n",
      "6656/6656 [==============================] - 2s 273us/step - loss: 98.3241 - val_loss: 67.1339\n",
      "Epoch 55/300\n",
      "6656/6656 [==============================] - 2s 275us/step - loss: 97.0078 - val_loss: 93.7106\n",
      "Epoch 56/300\n",
      "6656/6656 [==============================] - 2s 290us/step - loss: 95.5647 - val_loss: 73.4328\n",
      "Epoch 57/300\n",
      "6656/6656 [==============================] - 2s 305us/step - loss: 97.8577 - val_loss: 79.9080\n",
      "Epoch 58/300\n",
      "6656/6656 [==============================] - 2s 242us/step - loss: 95.3622 - val_loss: 74.2006\n",
      "Epoch 59/300\n",
      "6656/6656 [==============================] - 2s 244us/step - loss: 98.5241 - val_loss: 75.4737\n",
      "Epoch 60/300\n",
      "6656/6656 [==============================] - 2s 253us/step - loss: 93.1987 - val_loss: 83.2030\n",
      "Epoch 61/300\n",
      "6656/6656 [==============================] - 2s 282us/step - loss: 99.3869 - val_loss: 65.4499\n",
      "Epoch 62/300\n",
      "6656/6656 [==============================] - 2s 274us/step - loss: 97.7750 - val_loss: 67.0691\n",
      "Epoch 63/300\n",
      "6656/6656 [==============================] - 2s 251us/step - loss: 100.2422 - val_loss: 71.2554\n",
      "Epoch 64/300\n",
      "6656/6656 [==============================] - 2s 256us/step - loss: 95.3504 - val_loss: 120.5425\n",
      "Epoch 65/300\n",
      "6656/6656 [==============================] - 2s 299us/step - loss: 94.2133 - val_loss: 70.1345\n",
      "Epoch 66/300\n",
      "6656/6656 [==============================] - 2s 271us/step - loss: 93.9562 - val_loss: 68.2428\n",
      "Epoch 67/300\n",
      "6656/6656 [==============================] - 2s 243us/step - loss: 96.4906 - val_loss: 76.4365\n",
      "Epoch 68/300\n",
      "6656/6656 [==============================] - 2s 254us/step - loss: 97.3363 - val_loss: 108.4108\n",
      "Epoch 69/300\n",
      "6656/6656 [==============================] - 2s 261us/step - loss: 99.9419 - val_loss: 70.7673\n",
      "Epoch 70/300\n",
      "6656/6656 [==============================] - 2s 246us/step - loss: 95.1856 - val_loss: 84.7634\n",
      "Epoch 71/300\n",
      "6656/6656 [==============================] - 2s 255us/step - loss: 97.1744 - val_loss: 77.9576\n",
      "Epoch 72/300\n",
      "6656/6656 [==============================] - 2s 250us/step - loss: 91.3267 - val_loss: 65.9477\n",
      "Epoch 73/300\n",
      "6656/6656 [==============================] - 2s 253us/step - loss: 96.9145 - val_loss: 72.4868\n",
      "Epoch 74/300\n",
      "6656/6656 [==============================] - 2s 259us/step - loss: 93.7453 - val_loss: 85.4176\n",
      "Epoch 75/300\n",
      "6656/6656 [==============================] - 2s 253us/step - loss: 98.0464 - val_loss: 75.7980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/300\n",
      "6656/6656 [==============================] - 2s 290us/step - loss: 96.0218 - val_loss: 88.4746\n",
      "Epoch 77/300\n",
      "6656/6656 [==============================] - 2s 306us/step - loss: 97.2360 - val_loss: 86.8281\n",
      "Epoch 78/300\n",
      "6656/6656 [==============================] - 2s 258us/step - loss: 90.7953 - val_loss: 81.7492\n",
      "Epoch 79/300\n",
      "6656/6656 [==============================] - 2s 274us/step - loss: 89.5471 - val_loss: 84.4658\n",
      "Epoch 80/300\n",
      "6656/6656 [==============================] - 2s 247us/step - loss: 93.4343 - val_loss: 85.6195\n",
      "Epoch 81/300\n",
      "6656/6656 [==============================] - 2s 250us/step - loss: 91.9656 - val_loss: 77.3469\n",
      "Epoch 82/300\n",
      "6656/6656 [==============================] - 2s 316us/step - loss: 96.2306 - val_loss: 81.5419\n",
      "Epoch 83/300\n",
      "6656/6656 [==============================] - 2s 296us/step - loss: 94.0766 - val_loss: 91.3626\n",
      "Epoch 84/300\n",
      "6656/6656 [==============================] - 2s 304us/step - loss: 94.4767 - val_loss: 104.6445\n",
      "Epoch 85/300\n",
      "6656/6656 [==============================] - 2s 305us/step - loss: 95.8289 - val_loss: 88.7488\n",
      "Epoch 86/300\n",
      "6656/6656 [==============================] - 2s 305us/step - loss: 91.2165 - val_loss: 91.7638\n",
      "Epoch 87/300\n",
      "6656/6656 [==============================] - 2s 293us/step - loss: 90.1132 - val_loss: 97.0108\n",
      "Epoch 88/300\n",
      "6656/6656 [==============================] - 2s 289us/step - loss: 95.8660 - val_loss: 102.4086\n",
      "Epoch 89/300\n",
      "6656/6656 [==============================] - 2s 255us/step - loss: 90.0723 - val_loss: 83.2871\n",
      "Epoch 90/300\n",
      "6656/6656 [==============================] - 2s 286us/step - loss: 93.8007 - val_loss: 94.5469\n",
      "Epoch 91/300\n",
      "6656/6656 [==============================] - 2s 254us/step - loss: 90.2001 - val_loss: 103.0772\n",
      "Epoch 92/300\n",
      "6656/6656 [==============================] - 2s 263us/step - loss: 87.5846 - val_loss: 89.0998\n",
      "Epoch 93/300\n",
      "6656/6656 [==============================] - 2s 242us/step - loss: 89.7215 - val_loss: 88.7034\n",
      "Epoch 94/300\n",
      "6656/6656 [==============================] - 2s 309us/step - loss: 92.0871 - val_loss: 89.8402\n",
      "Epoch 95/300\n",
      "6656/6656 [==============================] - 2s 252us/step - loss: 90.2058 - val_loss: 85.1924\n",
      "Epoch 96/300\n",
      "6656/6656 [==============================] - 2s 263us/step - loss: 92.6038 - val_loss: 81.4751\n",
      "Epoch 97/300\n",
      "6656/6656 [==============================] - 2s 248us/step - loss: 91.7619 - val_loss: 87.6579\n",
      "Epoch 98/300\n",
      "6656/6656 [==============================] - 2s 273us/step - loss: 92.1866 - val_loss: 83.1647\n",
      "Epoch 99/300\n",
      "6656/6656 [==============================] - 2s 252us/step - loss: 92.1438 - val_loss: 93.2471\n",
      "Epoch 100/300\n",
      "6656/6656 [==============================] - 2s 236us/step - loss: 91.0504 - val_loss: 93.7590\n",
      "Epoch 101/300\n",
      "6656/6656 [==============================] - 2s 281us/step - loss: 90.3072 - val_loss: 83.0353\n",
      "Epoch 102/300\n",
      "6656/6656 [==============================] - 2s 281us/step - loss: 89.6241 - val_loss: 76.7880\n",
      "Epoch 103/300\n",
      "6656/6656 [==============================] - 2s 313us/step - loss: 91.3856 - val_loss: 94.8113\n",
      "Epoch 104/300\n",
      "6656/6656 [==============================] - 2s 247us/step - loss: 93.0225 - val_loss: 97.2171\n",
      "Epoch 105/300\n",
      "6656/6656 [==============================] - 2s 251us/step - loss: 88.7344 - val_loss: 89.9500\n",
      "Epoch 106/300\n",
      "6656/6656 [==============================] - 2s 303us/step - loss: 89.5242 - val_loss: 83.5814\n",
      "Epoch 107/300\n",
      "6656/6656 [==============================] - 2s 259us/step - loss: 88.6232 - val_loss: 89.4308\n",
      "Epoch 108/300\n",
      "6656/6656 [==============================] - 2s 266us/step - loss: 89.9239 - val_loss: 90.1634\n",
      "Epoch 109/300\n",
      "6656/6656 [==============================] - 2s 257us/step - loss: 88.2777 - val_loss: 102.6374\n",
      "Epoch 110/300\n",
      "6656/6656 [==============================] - 2s 286us/step - loss: 86.9751 - val_loss: 112.8879\n",
      "Epoch 111/300\n",
      "6656/6656 [==============================] - 2s 255us/step - loss: 89.9488 - val_loss: 76.2812\n",
      "Epoch 112/300\n",
      "6656/6656 [==============================] - 2s 261us/step - loss: 87.9948 - val_loss: 84.5725\n",
      "Epoch 113/300\n",
      "6656/6656 [==============================] - 2s 258us/step - loss: 87.1488 - val_loss: 97.0378\n",
      "Epoch 114/300\n",
      "6656/6656 [==============================] - 2s 255us/step - loss: 85.4179 - val_loss: 83.1067\n",
      "Epoch 115/300\n",
      "6656/6656 [==============================] - 2s 257us/step - loss: 88.3478 - val_loss: 76.5691\n",
      "Epoch 116/300\n",
      "6656/6656 [==============================] - 2s 256us/step - loss: 93.2660 - val_loss: 70.8618\n",
      "Epoch 117/300\n",
      "4256/6656 [==================>...........] - ETA: 0s - loss: 87.9712"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-271c2bf78261>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# list all data in history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# summarize history for accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x,train_y,validation_split=0.2, epochs=300)\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "631.843948364\n",
      "580.133323669\n",
      "535.719070435\n",
      "684.543151855\n",
      "698.9503479\n",
      "594.44770813\n",
      "2\n",
      "631.245422363\n",
      "651.517333984\n",
      "557.036132812\n",
      "542.810783386\n",
      "2\n",
      "634.764480591\n",
      "684.115142822\n",
      "757.023620605\n",
      "659.632263184\n",
      "2\n",
      "632.855987549\n",
      "520.300521851\n",
      "522.57232666\n",
      "774.607696533\n",
      "546.162872314\n",
      "531.461715698\n",
      "527.614593506\n",
      "726.272125244\n",
      "497.8150177\n",
      "566.695404053\n",
      "495.495376587\n",
      "564.062080383\n",
      "557.483940125\n",
      "600.501861572\n",
      "573.302993774\n",
      "686.749420166\n",
      "725.03944397\n",
      "2\n",
      "637.204284668\n",
      "732.727813721\n",
      "696.338500977\n",
      "668.386535645\n",
      "2\n",
      "638.598976135\n",
      "581.755599976\n",
      "594.005012512\n",
      "632.764205933\n",
      "581.378250122\n",
      "646.018295288\n",
      "558.065032959\n",
      "651.577911377\n",
      "550.907287598\n",
      "659.777603149\n",
      "619.163589478\n",
      "706.444473267\n",
      "734.324264526\n",
      "538.168258667\n",
      "666.038894653\n",
      "534.352035522\n",
      "630.702667236\n",
      "545.222740173\n",
      "634.856872559\n",
      "2\n",
      "636.936988831\n",
      "639.842300415\n",
      "572.308235168\n",
      "520.784225464\n",
      "638.283653259\n",
      "573.167724609\n",
      "733.525543213\n",
      "2\n",
      "636.936988831\n",
      "645.775909424\n",
      "673.063354492\n",
      "607.708969116\n",
      "544.463996887\n",
      "566.782569885\n",
      "558.89465332\n",
      "569.40158844\n",
      "567.771148682\n",
      "537.45010376\n",
      "656.018447876\n",
      "537.504081726\n",
      "556.981468201\n",
      "551.610946655\n",
      "563.771286011\n",
      "630.736999512\n",
      "563.245735168\n",
      "619.063148499\n",
      "795.395126343\n",
      "559.855117798\n",
      "2\n",
      "648.371734619\n",
      "544.621887207\n",
      "533.456726074\n",
      "809.222564697\n",
      "548.383865356\n",
      "664.309234619\n",
      "559.840927124\n",
      "554.780502319\n",
      "617.468833923\n",
      "538.074035645\n",
      "627.629699707\n",
      "744.323577881\n",
      "684.515838623\n",
      "2\n",
      "660.096359253\n",
      "519.041137695\n",
      "534.107055664\n",
      "609.905433655\n",
      "540.235366821\n",
      "549.342384338\n",
      "2\n",
      "622.600708008\n",
      "617.829170227\n",
      "636.31072998\n",
      "563.036193848\n",
      "670.105133057\n",
      "2\n",
      "660.096359253\n",
      "607.457885742\n",
      "572.535705566\n",
      "552.330207825\n",
      "2\n",
      "626.163482666\n",
      "755.974655151\n",
      "790.494689941\n",
      "590.603752136\n",
      "554.259643555\n",
      "770.782318115\n",
      "2\n",
      "620.612945557\n",
      "732.317276001\n",
      "686.118774414\n",
      "666.386184692\n",
      "567.393722534\n",
      "612.022171021\n",
      "584.061203003\n",
      "654.281311035\n",
      "768.565216064\n",
      "2\n",
      "625.086784363\n",
      "512.564964294\n",
      "548.351211548\n",
      "611.60194397\n",
      "609.400100708\n",
      "591.928405762\n",
      "562.219429016\n",
      "605.885391235\n",
      "549.879989624\n",
      "560.293655396\n",
      "2\n",
      "622.600708008\n",
      "633.037452698\n",
      "665.462188721\n",
      "697.308883667\n",
      "708.365707397\n",
      "580.191001892\n",
      "744.332351685\n",
      "727.756500244\n",
      "2\n",
      "620.612945557\n",
      "732.288970947\n",
      "630.197296143\n",
      "797.618179321\n",
      "2\n",
      "639.910583496\n",
      "789.846038818\n",
      "2\n",
      "620.612945557\n",
      "628.460769653\n",
      "561.043510437\n",
      "586.066398621\n",
      "547.048454285\n",
      "569.252624512\n",
      "562.326545715\n",
      "564.310112\n",
      "629.658508301\n",
      "643.197784424\n",
      "2\n",
      "626.163482666\n",
      "550.156402588\n",
      "575.206375122\n",
      "554.221725464\n",
      "551.620101929\n",
      "554.042015076\n",
      "2\n",
      "660.096359253\n",
      "578.753318787\n",
      "616.915893555\n",
      "723.427734375\n",
      "595.545501709\n",
      "757.956924438\n",
      "644.679946899\n",
      "548.385467529\n",
      "540.13458252\n",
      "613.69430542\n",
      "718.7890625\n",
      "582.128753662\n",
      "588.368682861\n",
      "732.84942627\n",
      "529.689712524\n",
      "571.706619263\n",
      "621.680221558\n",
      "661.210250854\n",
      "706.968841553\n",
      "2\n",
      "632.855987549\n",
      "824.41986084\n",
      "809.371185303\n",
      "558.778305054\n",
      "649.067306519\n",
      "573.888473511\n",
      "559.548225403\n",
      "566.070404053\n",
      "645.087966919\n",
      "636.045532227\n",
      "2\n",
      "640.515594482\n",
      "741.131744385\n",
      "568.138961792\n",
      "648.517532349\n",
      "2\n",
      "634.764480591\n",
      "774.754104614\n",
      "582.019882202\n",
      "543.235740662\n",
      "626.657600403\n",
      "551.407203674\n",
      "632.545814514\n",
      "564.851303101\n",
      "690.7862854\n",
      "564.717903137\n",
      "676.673126221\n",
      "594.279022217\n",
      "668.456420898\n",
      "742.867889404\n",
      "2\n",
      "632.855987549\n",
      "598.31325531\n",
      "633.203620911\n",
      "589.272842407\n",
      "674.723815918\n",
      "2\n",
      "632.855987549\n",
      "507.122650146\n",
      "744.033432007\n",
      "554.301185608\n",
      "659.014129639\n",
      "2\n",
      "631.448974609\n",
      "591.156158447\n",
      "526.109619141\n",
      "625.060043335\n",
      "797.20664978\n",
      "2\n",
      "631.448974609\n",
      "867.270355225\n",
      "514.244117737\n",
      "591.587905884\n",
      "657.282409668\n",
      "672.972564697\n",
      "770.663146973\n",
      "2\n",
      "632.855987549\n",
      "623.183822632\n",
      "617.298812866\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "model.add(Conv2D(8, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(8, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "model.add(Conv2D(8, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=keras.optimizers.Adam())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
